{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "Data Processing and Deep Learning .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SadEp8r4pUzI",
        "colab_type": "text"
      },
      "source": [
        "# Initialisation et import des librairies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FeK0-Osamoj",
        "colab_type": "code",
        "outputId": "5b163aac-4462-430b-d626-ab6dc3ecc794",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import numpy    \n",
        "!pip install sklearn\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "!pip install GEOparse\n",
        "import GEOparse\n",
        "import pandas\n",
        "from keras.models import Sequential\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Dense\n",
        "!pip install h5py pyyaml\n",
        "import tensorflow as tf\n",
        "import keras.backend\n",
        "config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 56} ) \n",
        "sess = tf.Session(config=config) \n",
        "keras.backend.set_session(sess) \n",
        "\n",
        "import os\n",
        "if not os.path.isfile(\"./gdrive/My Drive/GSE13204_family.soft.gz\"):\n",
        "  !wget -O \"./gdrive/My Drive/GSE13204_family.soft.gz\" \"ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE13nnn/GSE13204/soft/GSE13204_family.soft.gz\" \n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.22.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.17.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.14.1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting GEOparse\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/8d/6d9860b9aa1194b371318c2b0ebf1722a1297c7124517eee120d0a8cd7b6/GEOparse-2.0.1.tar.gz (276kB)\n",
            "\r\u001b[K     |█▏                              | 10kB 6.6MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20kB 1.4MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30kB 2.1MB/s eta 0:00:01\r\u001b[K     |████▊                           | 40kB 1.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 51kB 1.9MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 71kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 81kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 92kB 2.3MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 102kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 112kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 122kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 133kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 143kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 153kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 163kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 174kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 184kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 194kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 204kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 215kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 225kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 235kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 245kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 256kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 266kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 276kB 2.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from GEOparse) (1.17.5)\n",
            "Requirement already satisfied: pandas>=0.17 in /usr/local/lib/python3.6/dist-packages (from GEOparse) (0.25.3)\n",
            "Requirement already satisfied: requests>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from GEOparse) (2.21.0)\n",
            "Collecting tqdm>=4.31.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/47/55/fd9170ba08a1a64a18a7f8a18f088037316f2a41be04d2fe6ece5a653e8f/tqdm-4.43.0-py2.py3-none-any.whl (59kB)\n",
            "\r\u001b[K     |█████▌                          | 10kB 28.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 20kB 36.4MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 30kB 43.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 40kB 41.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 51kB 43.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17->GEOparse) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17->GEOparse) (2.6.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.21.0->GEOparse) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.21.0->GEOparse) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.21.0->GEOparse) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.21.0->GEOparse) (2019.11.28)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.17->GEOparse) (1.12.0)\n",
            "Building wheels for collected packages: GEOparse\n",
            "  Building wheel for GEOparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GEOparse: filename=GEOparse-2.0.1-cp36-none-any.whl size=28695 sha256=08e0a1674bd05116db63471769b733fd3bff78f9a468494a84545b6f718444c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/52/4c/44df5b0f3b97bf8172881065941a6b6e1c46408290b02daf7f\n",
            "Successfully built GEOparse\n",
            "Installing collected packages: tqdm, GEOparse\n",
            "  Found existing installation: tqdm 4.28.1\n",
            "    Uninstalling tqdm-4.28.1:\n",
            "      Successfully uninstalled tqdm-4.28.1\n",
            "Successfully installed GEOparse-2.0.1 tqdm-4.43.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py) (1.17.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIaz8Cucakkf",
        "colab_type": "text"
      },
      "source": [
        "# Traitement des données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zggScznDaklA",
        "colab_type": "code",
        "outputId": "e4678ca7-b388-4b6d-9f3c-30a783a37c43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Soft file\n",
        "\n",
        "gse = GEOparse.get_GEO(filepath=\"./gdrive/My Drive/GSE13204_family.soft.gz\", silent = True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/GEOparse/GEOparse.py:104: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return parse_GSE(filepath)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-Cyc7VyaklG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c106af5a-cf82-4afc-cb85-373a9fcce025"
      },
      "source": [
        "gsms = gse.gsms\n",
        "print(list(gsms.keys())[:10])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['GSM329407', 'GSM329408', 'GSM329409', 'GSM329410', 'GSM329411', 'GSM329412', 'GSM329413', 'GSM329414', 'GSM329415', 'GSM329416']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2YeahVDaklM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "97e745b7-0688-452e-e96f-0d0474c89de2"
      },
      "source": [
        "print(gsms['GSM329411'].table)\n",
        "print(gsms['GSM329407'].columns)\n",
        "print(gsms['GSM329407'].metadata)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               ID_REF    VALUE_DS ABS_CALL  DETECTION P-VALUE     VALUE\n",
            "0      AFFX-BioB-5_at   5614.9300        P           0.000127       NaN\n",
            "1      AFFX-BioB-M_at   9707.9000        P           0.000044       NaN\n",
            "2      AFFX-BioB-3_at   5331.4200        P           0.000044       NaN\n",
            "3      AFFX-BioC-5_at  17928.6000        P           0.000044       NaN\n",
            "4      AFFX-BioC-3_at  18722.0000        P           0.000044       NaN\n",
            "...               ...         ...      ...                ...       ...\n",
            "54670      1570644_at     57.2892        A           0.870361  0.058415\n",
            "54671      1570645_at    127.5280        A           0.398926  0.158527\n",
            "54672      1570650_at    214.8240        A           0.601074  0.247337\n",
            "54673      1570651_at    488.8230        P           0.046143  0.416758\n",
            "54674      1570653_at    122.2930        A           0.466064  0.152232\n",
            "\n",
            "[54675 rows x 5 columns]\n",
            "                                                         description\n",
            "ID_REF                                                              \n",
            "VALUE_DS           The signal used was DS, see Liu, W.-m., R. Li,...\n",
            "ABS_CALL                                                            \n",
            "DETECTION P-VALUE                                                   \n",
            "VALUE              The signal used was DQN3, i.e., DQN signal nor...\n",
            "{'title': ['MILES stage 1 data N1_0001'], 'geo_accession': ['GSM329407'], 'status': ['Public on Sep 30 2009'], 'submission_date': ['Oct 10 2008'], 'last_update_date': ['Nov 14 2018'], 'type': ['RNA'], 'channel_count': ['1'], 'source_name_ch1': ['Leukemia patient sample'], 'organism_ch1': ['Homo sapiens'], 'taxid_ch1': ['9606'], 'characteristics_ch1': ['sample type: bone marrow', 'leukemia class: mature B-ALL with t(8;14)'], 'treatment_protocol_ch1': ['Samples are from untreated patients.'], 'growth_protocol_ch1': ['not applicable'], 'molecule_ch1': ['total RNA'], 'extract_protocol_ch1': ['The total RNA was purified either with Qiagen RNeasy Mini kits (Qiagen, Hilden, Germany) or with TRIzol-based protocols'], 'label_ch1': ['biotin'], 'label_protocol_ch1': ['For each sample preparation, total RNA was converted into double-stranded cDNA by reverse transcription using a cDNA Synthesis System kit including an oligo(dT)24 – T7 primer (Roche Applied Science, Mannheim, Germany) and Poly-A control transcripts (Affymetrix, Santa Clara, CA, USA). The generated cRNA was purified using the GeneChip Sample Cleanup Module (Affymetrix) and quantified using the NanoDrop ND-1000 spectrophotometer (NanoDrop Technologies, Wilmington, DE, USA). The incubation steps during the cDNA synthesis, in vitro transcription reaction, and target fragmentation were performed using the Hybex Microarray Incubation System (SciGene, Sunnyvale, CA, USA) and Eppendorf ThermoStat plus instruments (Eppendorf, Hamburg, Germany).'], 'hyb_protocol': ['Hybridization, washing, and staining protocols, respectively, were performed on Affymetrix GeneChip instruments (Hybridization Oven 640, Fluidics Station FS450) as recommended by the manufacturer.'], 'scan_protocol': ['Scanning was performed on Affymetrix GeneChip Scanner GCS3000 instruments as recommended by the manufacturer using default settings. The software used was GCOS 1.2 or higher.'], 'data_processing': ['Data pre-processing included a summarization and quantile normalization step to generate probe set level signal intensities for each microarray experiment and was performed as previously published by Liu WM et al. PQN and DQN: algorithms for expression microarrays. J.Theor.Biol. 2006;243:273-278.'], 'platform_id': ['GPL570'], 'contact_name': ['Wei-Min,,Liu'], 'contact_email': ['wei-min.liu@roche.com'], 'contact_phone': ['9257308446'], 'contact_institute': ['Roche Molecular Systems'], 'contact_address': ['4300 Hacienda Drive'], 'contact_city': ['Pleasanton'], 'contact_state': ['CA'], 'contact_zip/postal_code': ['94588'], 'contact_country': ['USA'], 'supplementary_file': ['ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM329nnn/GSM329407/suppl/GSM329407.CEL.gz'], 'relation': ['Reanalyzed by: GSE122511'], 'series_id': ['GSE13159', 'GSE13204'], 'data_row_count': ['54675']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndlonuq5aklR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "97639fa3-6119-44fb-d52c-de55f57a0c1e"
      },
      "source": [
        "# Label\n",
        "lise = []\n",
        "alignments = {}\n",
        "for i in gsms.keys():\n",
        "    lab = gsms[i].metadata['characteristics_ch1'][1]\n",
        "    lise.append(lab)\n",
        "    alignments[i] = lab \n",
        "for i in list(set(lise)):\n",
        "    print(i)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "leukemia class: CML\n",
            "leukemia class: Pro-B-ALL with t(11q23)/MLL\n",
            "leukemia class: T-ALL\n",
            "leukemia class: AML with normal karyotype + other abnormalities\n",
            "leukemia class: c-ALL/Pre-B-ALL with t(9;22)\n",
            "leukemia class: c-ALL/Pre-B-ALL without t(9;22)\n",
            "leukemia class: ALL with t(1;19)\n",
            "leukemia class: AML with t(8;21)\n",
            "leukemia class: AML with t(15;17)\n",
            "leukemia class: AML complex aberrant karyotype\n",
            "leukemia class: AML with inv(16)/t(16;16)\n",
            "leukemia class: AML with t(11q23)/MLL\n",
            "leukemia class: CLL\n",
            "leukemia class: MDS\n",
            "leukemia class: ALL with t(12;21)\n",
            "leukemia class: Non-leukemia and healthy bone marrow\n",
            "leukemia class: mature B-ALL with t(8;14)\n",
            "leukemia class: ALL with hyperdiploid karyotype\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpDzE8lXaklV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "1417d2c4-70d0-4164-8528-40572407265b"
      },
      "source": [
        "# Assigning CEL files with their labels\n",
        "\n",
        "pandas.set_option('display.max_rows', 10)\n",
        "print(\"Number of patients : \"+str(len(gsms.keys())))\n",
        "gpls = gse.gpls\n",
        "print(gpls.keys())\n",
        "print(gpls['GPL570'].columns)\n",
        "print(gpls['GPL570'].table)\n",
        "#print(gpls.table)\n",
        "count_list = []\n",
        "print(\"Count of genes :\")\n",
        "df = gsms['GSM329411'].table.dropna()\n",
        "print(len(df))\n",
        "\n",
        "equivalents = {\n",
        "\"leukemia class: ALL with t(12;21)\":0,  # ALL\n",
        "\"leukemia class: c-ALL/Pre-B-ALL with t(9;22)\":0, # ALL\n",
        "\"leukemia class: AML with normal karyotype + other abnormalities\":1, # AML\n",
        "\"leukemia class: ALL with t(1;19)\":0, # ALL\n",
        "\"leukemia class: CLL\":2, # CLL\n",
        "\"leukemia class: AML with t(15;17)\":1, # AML\n",
        "\"leukemia class: Non-leukemia and healthy bone marrow\":5, # Non-Leukemia\n",
        "\"leukemia class: Pro-B-ALL with t(11q23)/MLL\":0, # ALL\n",
        "\"leukemia class: ALL with hyperdiploid karyotype\":0, # ALL\n",
        "\"leukemia class: T-ALL\":0, # ALL\n",
        "\"leukemia class: AML with t(8;21)\":1, # AML\n",
        "\"leukemia class: AML with inv(16)/t(16;16)\":1, # AML\n",
        "\"leukemia class: MDS\":4, # MDS\n",
        "\"leukemia class: mature B-ALL with t(8;14)\":0, # ALL\n",
        "\"leukemia class: c-ALL/Pre-B-ALL without t(9;22)\":0, # ALL\n",
        "\"leukemia class: AML with t(11q23)/MLL\":1, # AML\n",
        "\"leukemia class: CML\":3, # CML\n",
        "\"leukemia class: AML complex aberrant karyotype\":1, # AML\n",
        "}\n",
        "import numpy\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "count54 = 0\n",
        "count14 = 0\n",
        "all_labels = []\n",
        "for i in gsms:\n",
        "  j = gsms[i].table.dropna()\n",
        "  if len(j[\"VALUE_DS\"]) == 54630: \n",
        "    Y.append(numpy.array(equivalents[gsms[i].metadata['characteristics_ch1'][1]]))\n",
        "    all_labels.append(int(equivalents[gsms[i].metadata['characteristics_ch1'][1]]))\n",
        "    r = j[\"VALUE_DS\"].to_numpy()\n",
        "    X.append(r)\n",
        "    count54 += 1\n",
        "  else:\n",
        "    count14 +=1\n",
        "\n",
        "\n",
        "print(\"STAGE 1 DATA :\"+str(count54))   \n",
        "print(\"STAGE 2 DATA :\"+str(count14))\n",
        " "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of patients : 3248\n",
            "dict_keys(['GPL570', 'GPL7473'])\n",
            "                                                                        description\n",
            "ID                                Affymetrix Probe Set ID LINK_PRE:\"https://www....\n",
            "GB_ACC                            GenBank Accession Number LINK_PRE:\"http://www....\n",
            "SPOT_ID                                                         identifies controls\n",
            "Species Scientific Name           The genus and species of the organism represen...\n",
            "Annotation Date                   The date that the annotations for this probe a...\n",
            "...                                                                             ...\n",
            "ENTREZ_GENE_ID                    Entrez Gene Database UID LINK_PRE:\"http://www....\n",
            "RefSeq Transcript ID              References to multiple sequences in RefSeq. Th...\n",
            "Gene Ontology Biological Process  Gene Ontology Consortium Biological Process de...\n",
            "Gene Ontology Cellular Component  Gene Ontology Consortium Cellular Component de...\n",
            "Gene Ontology Molecular Function  Gene Ontology Consortium Molecular Function de...\n",
            "\n",
            "[16 rows x 1 columns]\n",
            "                    ID  ...                   Gene Ontology Molecular Function\n",
            "0            1007_s_at  ...  0000166 // nucleotide binding // inferred from...\n",
            "1              1053_at  ...  0000166 // nucleotide binding // inferred from...\n",
            "2               117_at  ...  0000166 // nucleotide binding // inferred from...\n",
            "3               121_at  ...  0000979 // RNA polymerase II core promoter seq...\n",
            "4            1255_g_at  ...  0005509 // calcium ion binding // inferred fro...\n",
            "...                ...  ...                                                ...\n",
            "54670   AFFX-ThrX-5_at  ...                                                NaN\n",
            "54671   AFFX-ThrX-M_at  ...                                                NaN\n",
            "54672  AFFX-TrpnX-3_at  ...                                                NaN\n",
            "54673  AFFX-TrpnX-5_at  ...                                                NaN\n",
            "54674  AFFX-TrpnX-M_at  ...                                                NaN\n",
            "\n",
            "[54675 rows x 16 columns]\n",
            "Count of genes :\n",
            "54630\n",
            "STAGE 1 DATA :2096\n",
            "STAGE 2 DATA :1152\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WT0yiHxJaklb",
        "colab_type": "text"
      },
      "source": [
        "# Creation des models et apprentissage\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYoErPPiakld",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8fae63e1-41c4-4e1a-c72e-ef3110b8631d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from keras import optimizers\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
        "def train_fit_test(model, train_x, train_y, test_x, test_y, classWeight):\n",
        "    opt = optimizers.SGD(lr=1e-2)\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "    model.fit(train_x, train_y, epochs=100, verbose=2, batch_size=32, class_weight=classWeight)\n",
        "    y_pred = model.predict(test_x)\n",
        "    y_pred_formated = numpy.argmax(y_pred, axis=1)\n",
        "    test_y_formated = numpy.argmax(test_y, axis=1)\n",
        "    precision = precision_score(test_y_formated, y_pred_formated, average=\"macro\")  \n",
        "    conf = confusion_matrix(test_y_formated, y_pred_formated)\n",
        "    print(str(conf))\n",
        "    return precision, conf\n",
        "\n",
        "def create_model(num_layers, num_neurons):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(64, input_dim=54630))\n",
        "    for i in range(num_layers):\n",
        "      model.add(Dense(units=num_neurons, activation='relu'))\n",
        "    model.add(Dense(units=6, activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "def hamming_score(y_true, y_pred, normalize=True, sample_weight=None):\n",
        "    import numpy as np\n",
        "\n",
        "    acc_list = []\n",
        "    for i in range(y_true.shape[0]):\n",
        "        set_true = set( np.where(y_true[i])[0] )\n",
        "        set_pred = set( np.where(y_pred[i])[0] )\n",
        "        #print('\\nset_true: {0}'.format(set_true))\n",
        "        #print('set_pred: {0}'.format(set_pred))\n",
        "        tmp_a = None\n",
        "        if len(set_true) == 0 and len(set_pred) == 0:\n",
        "            tmp_a = 1\n",
        "        else:\n",
        "            tmp_a = len(set_true.intersection(set_pred))/\\\n",
        "                    float( len(set_true.union(set_pred)) )\n",
        "        #print('tmp_a: {0}'.format(tmp_a))\n",
        "        acc_list.append(tmp_a)\n",
        "    return np.mean(acc_list)\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "Y_step = numpy.copy(Y)\n",
        "Y_step2 = numpy.array(Y_step).reshape(-1, 1)\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "classWeight = compute_class_weight('balanced', [0,1,2,3,4,5], all_labels) \n",
        "classWeight = dict(enumerate(classWeight))\n",
        "print(\"Class weight : \"+str(classWeight))\n",
        "from keras.utils import to_categorical\n",
        "Y_step2 = to_categorical(Y_step2)\n",
        "classes_weight = {}\n",
        "print(\" Distribution of classes : \"+str(classWeight))\n",
        "print(\"Y[:5] : \"+str(Y_step2[:5]))\n",
        "print(\"Y[0] type : \"+str(type(Y[0])))\n",
        "\n",
        "\n",
        "Y_step2 = numpy.array(Y_step2)\n",
        "X_step = numpy.array(X)\n",
        "#X_step = numpy.nan_to_num(X_step)\n",
        "print(\"X[0] shape : \"+str(X[0].shape))\n",
        "best_mean = -999999\n",
        "best_model = []\n",
        "layers = [50, 100, 1000, 1500, 2000]\n",
        "train_x, test_x, train_y, test_y = train_test_split(X_step, Y_step2, test_size=0.33, random_state=42)\n",
        "import pickle\n",
        "with open('/content/drive/My Drive/train_x.pickle', 'wb') as handle:\n",
        "    pickle.dump(train_x, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('/content/drive/My Drive/train_y.pickle', 'wb') as handle2:\n",
        "    pickle.dump(train_y, handle2, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('/content/drive/My Drive/test_x.pickle', 'wb') as handle3:\n",
        "    pickle.dump(test_x, handle3, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('/content/drive/My Drive/test_y.pickle', 'wb') as handle4:\n",
        "    pickle.dump(test_y, handle4, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "from sklearn.utils import compute_class_weight\n",
        "#train_x = numpy.nan_to_num(train_x)\n",
        "#test_x = numpy.nan_to_num(test_x)\n",
        "for x in range(5): # Number of Retrain\n",
        "  for i in  range(5, 7): # Maximum number of hidden layers\n",
        "      for j in layers: # Maximum number of neurons per layer\n",
        "        model = create_model(i, j)\n",
        "        model.summary()\n",
        "        print(\"Training...\")\n",
        "        precision, confusion = train_fit_test(model, train_x, train_y, test_x, test_y, classWeight)\n",
        "        print(\"\\n\")\n",
        "        print(type(model))\n",
        "        print(\"||||| Accuracy : \"+str(precision)+\" |||||\")\n",
        "        print(\"\\n\")\n",
        "        with open(\"/content/drive/My Drive/infos.txt\",'a+') as fh:\n",
        "          model.summary(print_fn=lambda x: fh.write(x + '\\n'))\n",
        "          fh.write(str(confusion)+\"\\n\")\n",
        "          fh.write(\"\\n Precision : \"+str(precision)+\"\\n\")\n",
        "          fh.close()\n",
        "        try:\n",
        "          v = open(\"/content/drive/My Drive/best_mod.txt\",\"r\")\n",
        "          best_mean = float(v.read())\n",
        "          print(\"Best actual accuracy : \"+str(best_mean))\n",
        "          v.close()\n",
        "        except:\n",
        "          v = open(\"/content/drive/My Drive/best_mod.txt\",\"w\")\n",
        "          v.write(str(precision))\n",
        "          v.close()\n",
        "        if (precision > best_mean):\n",
        "          print(\"\\n\\n\")\n",
        "          print(\" BEST MODEL ! \")\n",
        "          print(\"Saving... \")\n",
        "          print(\"\\n\\n\")\n",
        "          v = open(\"/content/drive/My Drive/best_mod.txt\",\"w\")\n",
        "          v.write(str(precision))\n",
        "          v.close()\n",
        "          model.save('/content/drive/My Drive/model.h5')\n",
        "          best_mean = precision\n",
        "          best_model = model\n",
        "    "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Class weight : {0: 0.4657777777777778, 1: 0.6445264452644527, 2: 0.7797619047619048, 3: 4.5964912280701755, 4: 1.6957928802588997, 5: 4.7207207207207205}\n",
            " Distribution of classes : {0: 0.4657777777777778, 1: 0.6445264452644527, 2: 0.7797619047619048, 3: 4.5964912280701755, 4: 1.6957928802588997, 5: 4.7207207207207205}\n",
            "Y[:5] : [[1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]]\n",
            "Y[0] type : <class 'numpy.ndarray'>\n",
            "X[0] shape : (54630,)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 64)                3496384   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 50)                3250      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 6)                 306       \n",
            "=================================================================\n",
            "Total params: 3,510,140\n",
            "Trainable params: 3,510,140\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Training...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            " - 9s - loss: 13.8769 - acc: 0.2044\n",
            "Epoch 2/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 3/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 4/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 5/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 6/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 7/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 8/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 9/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 10/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 11/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 12/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 13/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 14/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 15/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 16/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 17/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 18/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 19/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 20/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 21/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 22/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 23/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 24/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 25/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 26/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 27/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 28/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 29/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 30/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 31/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 32/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 33/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 34/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 35/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 36/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 37/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 38/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 39/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 40/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 41/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 42/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 43/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 44/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 45/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 46/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 47/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 48/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 49/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 50/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 51/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 52/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 53/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 54/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 55/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 56/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 57/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 58/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 59/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 60/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 61/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 62/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 63/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 64/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 65/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 66/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 67/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 68/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 69/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 70/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 71/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 72/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 73/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 74/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 75/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 76/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 77/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 78/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 79/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 80/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 81/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 82/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 83/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 84/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 85/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 86/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 87/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 88/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 89/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 90/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 91/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 92/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 93/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 94/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 95/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 96/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 97/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 98/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 99/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n",
            "Epoch 100/100\n",
            " - 1s - loss: 13.9594 - acc: 0.2066\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[  0   0 254   0   0   0]\n",
            " [  0   0 172   0   0   0]\n",
            " [  0   0 158   0   0   0]\n",
            " [  0   0  21   0   0   0]\n",
            " [  0   0  68   0   0   0]\n",
            " [  0   0  19   0   0   0]]\n",
            "\n",
            "\n",
            "<class 'keras.engine.sequential.Sequential'>\n",
            "||||| Accuracy : 0.038053949903660886 |||||\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " BEST MODEL ! \n",
            "Saving... \n",
            "\n",
            "\n",
            "\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_8 (Dense)              (None, 64)                3496384   \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 100)               6500      \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 6)                 606       \n",
            "=================================================================\n",
            "Total params: 3,543,890\n",
            "Trainable params: 3,543,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Training...\n",
            "Epoch 1/100\n",
            " - 1s - loss: 6.5376 - acc: 0.3533\n",
            "Epoch 2/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 3/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 4/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 5/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 6/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 7/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 8/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 9/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 10/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 11/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 12/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 13/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 14/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 15/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 16/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 17/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 18/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 19/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 20/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 21/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 22/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 23/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 24/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 25/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 26/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 27/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 28/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 29/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 30/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 31/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 32/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 33/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 34/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 35/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 36/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 37/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 38/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 39/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 40/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 41/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 42/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 43/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 44/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 45/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 46/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 47/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 48/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 49/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 50/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 51/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 52/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 53/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 54/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 55/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 56/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 57/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 58/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 59/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 60/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 61/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 62/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 63/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 64/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 65/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 66/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 67/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 68/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 69/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 70/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 71/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 72/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 73/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 74/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 75/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 76/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 77/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 78/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 79/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 80/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 81/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 82/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 83/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 84/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 85/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 86/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 87/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 88/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 89/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 90/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 91/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 92/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 93/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 94/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 95/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 96/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 97/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 98/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 99/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "Epoch 100/100\n",
            " - 1s - loss: 6.6037 - acc: 0.3533\n",
            "[[254   0   0   0   0   0]\n",
            " [172   0   0   0   0   0]\n",
            " [158   0   0   0   0   0]\n",
            " [ 21   0   0   0   0   0]\n",
            " [ 68   0   0   0   0   0]\n",
            " [ 19   0   0   0   0   0]]\n",
            "\n",
            "\n",
            "<class 'keras.engine.sequential.Sequential'>\n",
            "||||| Accuracy : 0.06117533718689788 |||||\n",
            "\n",
            "\n",
            "Best actual accuracy : 0.038053949903660886\n",
            "\n",
            "\n",
            "\n",
            " BEST MODEL ! \n",
            "Saving... \n",
            "\n",
            "\n",
            "\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_15 (Dense)             (None, 64)                3496384   \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 1000)              65000     \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 1000)              1001000   \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 1000)              1001000   \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 1000)              1001000   \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 1000)              1001000   \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 6)                 6006      \n",
            "=================================================================\n",
            "Total params: 7,571,390\n",
            "Trainable params: 7,571,390\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Training...\n",
            "Epoch 1/100\n",
            " - 1s - loss: 4.3474 - acc: 0.3519\n",
            "Epoch 2/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 3/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 4/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 5/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 6/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 7/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 8/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 9/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 10/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 11/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 12/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 13/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 14/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 15/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 16/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 17/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 18/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 19/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 20/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 21/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 22/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 23/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 24/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 25/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 26/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 27/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 28/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 29/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 30/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 31/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 32/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 33/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 34/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 35/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 36/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 37/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 38/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 39/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 40/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 41/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 42/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 43/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 44/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 45/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 46/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 47/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 48/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 49/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 50/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 51/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 52/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 53/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 54/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 55/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 56/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 57/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 58/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 59/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 60/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 61/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 62/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 63/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 64/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 65/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 66/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 67/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 68/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 69/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 70/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 71/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 72/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 73/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 74/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 75/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 76/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 77/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 78/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 79/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 80/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 81/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 82/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 83/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 84/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 85/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 86/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 87/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 88/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 89/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 90/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 91/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 92/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 93/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 94/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 95/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 96/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 97/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 98/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 99/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "Epoch 100/100\n",
            " - 1s - loss: 4.2656 - acc: 0.3533\n",
            "[[254   0   0   0   0   0]\n",
            " [172   0   0   0   0   0]\n",
            " [158   0   0   0   0   0]\n",
            " [ 21   0   0   0   0   0]\n",
            " [ 68   0   0   0   0   0]\n",
            " [ 19   0   0   0   0   0]]\n",
            "\n",
            "\n",
            "<class 'keras.engine.sequential.Sequential'>\n",
            "||||| Accuracy : 0.06117533718689788 |||||\n",
            "\n",
            "\n",
            "Best actual accuracy : 0.06117533718689788\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_22 (Dense)             (None, 64)                3496384   \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 1500)              97500     \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 1500)              2251500   \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 1500)              2251500   \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 1500)              2251500   \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 1500)              2251500   \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 6)                 9006      \n",
            "=================================================================\n",
            "Total params: 12,608,890\n",
            "Trainable params: 12,608,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Training...\n",
            "Epoch 1/100\n",
            " - 2s - loss: 8.9252 - acc: 0.3526\n",
            "Epoch 2/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 3/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 4/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 5/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 6/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 7/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 8/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 9/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 10/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 11/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 12/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 13/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 14/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 15/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 16/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 17/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 18/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 19/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 20/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 21/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 22/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 23/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 24/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 25/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 26/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 27/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 28/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 29/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 30/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 31/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 32/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 33/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 34/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 35/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 36/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 37/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 38/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 39/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 40/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 41/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 42/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 43/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 44/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 45/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 46/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 47/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 48/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 49/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 50/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 51/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 52/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 53/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 54/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 55/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 56/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 57/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 58/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 59/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 60/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 61/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 62/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 63/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 64/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 65/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 66/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 67/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 68/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 69/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 70/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 71/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 72/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 73/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 74/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 75/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 76/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 77/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 78/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 79/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 80/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 81/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 82/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 83/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 84/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 85/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 86/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 87/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 88/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 89/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 90/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 91/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 92/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 93/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 94/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 95/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 96/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 97/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 98/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 99/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "Epoch 100/100\n",
            " - 1s - loss: 8.9605 - acc: 0.3533\n",
            "[[254   0   0   0   0   0]\n",
            " [172   0   0   0   0   0]\n",
            " [158   0   0   0   0   0]\n",
            " [ 21   0   0   0   0   0]\n",
            " [ 68   0   0   0   0   0]\n",
            " [ 19   0   0   0   0   0]]\n",
            "\n",
            "\n",
            "<class 'keras.engine.sequential.Sequential'>\n",
            "||||| Accuracy : 0.06117533718689788 |||||\n",
            "\n",
            "\n",
            "Best actual accuracy : 0.06117533718689788\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_29 (Dense)             (None, 64)                3496384   \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 2000)              130000    \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 2000)              4002000   \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 2000)              4002000   \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 2000)              4002000   \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 2000)              4002000   \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 6)                 12006     \n",
            "=================================================================\n",
            "Total params: 19,646,390\n",
            "Trainable params: 19,646,390\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Training...\n",
            "Epoch 1/100\n",
            " - 2s - loss: 11.3765 - acc: 0.2657\n",
            "Epoch 2/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 3/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 4/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 5/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 6/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 7/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 8/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 9/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 10/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 11/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 12/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 13/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 14/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 15/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 16/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 17/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 18/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 19/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 20/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 21/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 22/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 23/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 24/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 25/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 26/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 27/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 28/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 29/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 30/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 31/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 32/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 33/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 34/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 35/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 36/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 37/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 38/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 39/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 40/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 41/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 42/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 43/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 44/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 45/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 46/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 47/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 48/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 49/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 50/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 51/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 52/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 53/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 54/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 55/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 56/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 57/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 58/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 59/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 60/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 61/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 62/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 63/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 64/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 65/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 66/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 67/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 68/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 69/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 70/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 71/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 72/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 73/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 74/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 75/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 76/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 77/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 78/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 79/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 80/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 81/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 82/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 83/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 84/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 85/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 86/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 87/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 88/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 89/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 90/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 91/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 92/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 93/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 94/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 95/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 96/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 97/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 98/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 99/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "Epoch 100/100\n",
            " - 1s - loss: 11.4511 - acc: 0.2635\n",
            "[[  0 254   0   0   0   0]\n",
            " [  0 172   0   0   0   0]\n",
            " [  0 158   0   0   0   0]\n",
            " [  0  21   0   0   0   0]\n",
            " [  0  68   0   0   0   0]\n",
            " [  0  19   0   0   0   0]]\n",
            "\n",
            "\n",
            "<class 'keras.engine.sequential.Sequential'>\n",
            "||||| Accuracy : 0.04142581888246628 |||||\n",
            "\n",
            "\n",
            "Best actual accuracy : 0.06117533718689788\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_36 (Dense)             (None, 64)                3496384   \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 50)                3250      \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_42 (Dense)             (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 6)                 306       \n",
            "=================================================================\n",
            "Total params: 3,512,690\n",
            "Trainable params: 3,512,690\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Training...\n",
            "Epoch 1/100\n",
            " - 1s - loss: 9.1614 - acc: 0.3526\n",
            "Epoch 2/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 3/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 4/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 5/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 6/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 7/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 8/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 9/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 10/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 11/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 12/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 13/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 14/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 15/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 16/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 17/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 18/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 19/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 20/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 21/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 22/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 23/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 24/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 25/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 26/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 27/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 28/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 29/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 30/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 31/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 32/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 33/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 34/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 35/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 36/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 37/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 38/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 39/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 40/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 41/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 42/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 43/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 44/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 45/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 46/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 47/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 48/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 49/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 50/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 51/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 52/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 53/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 54/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 55/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 56/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 57/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 58/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 59/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 60/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 61/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 62/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 63/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 64/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 65/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 66/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 67/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 68/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 69/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 70/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 71/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 72/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 73/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 74/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 75/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 76/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 77/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 78/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 79/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 80/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 81/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 82/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 83/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 84/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 85/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 86/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 87/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 88/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 89/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 90/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 91/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 92/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 93/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 94/100\n",
            " - 1s - loss: 9.0295 - acc: 0.3533\n",
            "Epoch 95/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-50d3d5f9b6ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fit_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassWeight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-50d3d5f9b6ba>\u001b[0m in \u001b[0;36mtrain_fit_test\u001b[0;34m(model, train_x, train_y, test_x, test_y, classWeight)\u001b[0m\n\u001b[1;32m      9\u001b[0m               \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m               metrics=['accuracy'])\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclassWeight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0my_pred_formated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}