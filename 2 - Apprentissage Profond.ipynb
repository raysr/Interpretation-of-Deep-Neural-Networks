{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boucle d'Apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rayansamyramoul/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 64)                3496384   \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 50)                3250      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 6)                 306       \n",
      "=================================================================\n",
      "Total params: 3,505,040\n",
      "Trainable params: 3,505,040\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training...\n",
      "Epoch 1/200\n",
      " - 2s - loss: 1.8200 - acc: 0.1852\n",
      "Epoch 2/200\n",
      " - 2s - loss: 1.7897 - acc: 0.1517\n",
      "Epoch 3/200\n",
      " - 2s - loss: 1.7395 - acc: 0.1930\n",
      "Epoch 4/200\n",
      " - 2s - loss: 1.6170 - acc: 0.2664\n",
      "Epoch 5/200\n",
      " - 2s - loss: 1.4501 - acc: 0.3326\n",
      "Epoch 6/200\n",
      " - 2s - loss: 1.4332 - acc: 0.3561\n",
      "Epoch 7/200\n",
      " - 2s - loss: 1.2866 - acc: 0.4031\n",
      "Epoch 8/200\n",
      " - 2s - loss: 1.3009 - acc: 0.4131\n",
      "Epoch 9/200\n",
      " - 2s - loss: 1.2028 - acc: 0.4808\n",
      "Epoch 10/200\n",
      " - 2s - loss: 1.2557 - acc: 0.4708\n",
      "Epoch 11/200\n",
      " - 2s - loss: 1.1513 - acc: 0.5548\n",
      "Epoch 12/200\n",
      " - 2s - loss: 1.0736 - acc: 0.6075\n",
      "Epoch 13/200\n",
      " - 2s - loss: 1.0207 - acc: 0.6467\n",
      "Epoch 14/200\n",
      " - 2s - loss: 0.9885 - acc: 0.6937\n",
      "Epoch 15/200\n",
      " - 2s - loss: 0.9499 - acc: 0.6873\n",
      "Epoch 16/200\n",
      " - 2s - loss: 0.9198 - acc: 0.7158\n",
      "Epoch 17/200\n",
      " - 2s - loss: 1.0674 - acc: 0.6709\n",
      "Epoch 18/200\n",
      " - 2s - loss: 0.9321 - acc: 0.7208\n",
      "Epoch 19/200\n",
      " - 2s - loss: 0.8810 - acc: 0.7593\n",
      "Epoch 20/200\n",
      " - 2s - loss: 0.8415 - acc: 0.7828\n",
      "Epoch 21/200\n",
      " - 2s - loss: 0.8341 - acc: 0.7778\n",
      "Epoch 22/200\n",
      " - 2s - loss: 0.8255 - acc: 0.7778\n",
      "Epoch 23/200\n",
      " - 2s - loss: 0.7888 - acc: 0.8063\n",
      "Epoch 24/200\n",
      " - 2s - loss: 0.8014 - acc: 0.8020\n",
      "Epoch 25/200\n",
      " - 2s - loss: 0.7494 - acc: 0.8248\n",
      "Epoch 26/200\n",
      " - 2s - loss: 0.7955 - acc: 0.8091\n",
      "Epoch 27/200\n",
      " - 2s - loss: 0.7758 - acc: 0.8091\n",
      "Epoch 28/200\n",
      " - 2s - loss: 0.7644 - acc: 0.8205\n",
      "Epoch 29/200\n",
      " - 2s - loss: 0.7507 - acc: 0.8298\n",
      "Epoch 30/200\n",
      " - 2s - loss: 0.7405 - acc: 0.8148\n",
      "Epoch 31/200\n",
      " - 2s - loss: 0.7693 - acc: 0.8241\n",
      "Epoch 32/200\n",
      " - 2s - loss: 0.8473 - acc: 0.8120\n",
      "Epoch 33/200\n",
      " - 2s - loss: 0.8031 - acc: 0.8170\n",
      "Epoch 34/200\n",
      " - 2s - loss: 0.7083 - acc: 0.8511\n",
      "Epoch 35/200\n",
      " - 2s - loss: 0.8082 - acc: 0.8098\n",
      "Epoch 36/200\n",
      " - 2s - loss: 0.6927 - acc: 0.8568\n",
      "Epoch 37/200\n",
      " - 2s - loss: 0.6838 - acc: 0.8462\n",
      "Epoch 38/200\n",
      " - 2s - loss: 0.7046 - acc: 0.8419\n",
      "Epoch 39/200\n",
      " - 2s - loss: 0.6749 - acc: 0.8611\n",
      "Epoch 40/200\n",
      " - 2s - loss: 0.8410 - acc: 0.8120\n",
      "Epoch 41/200\n",
      " - 2s - loss: 0.7056 - acc: 0.8454\n",
      "Epoch 42/200\n",
      " - 2s - loss: 0.6843 - acc: 0.8640\n",
      "Epoch 43/200\n",
      " - 2s - loss: 0.6691 - acc: 0.8711\n",
      "Epoch 44/200\n",
      " - 2s - loss: 0.7096 - acc: 0.8476\n",
      "Epoch 45/200\n",
      " - 2s - loss: 0.6821 - acc: 0.8640\n",
      "Epoch 46/200\n",
      " - 2s - loss: 0.6906 - acc: 0.8647\n",
      "Epoch 47/200\n",
      " - 3s - loss: 1.1725 - acc: 0.7692\n",
      "Epoch 48/200\n",
      " - 2s - loss: 0.6758 - acc: 0.8561\n",
      "Epoch 49/200\n",
      " - 2s - loss: 0.6652 - acc: 0.8718\n",
      "Epoch 50/200\n",
      " - 2s - loss: 0.6458 - acc: 0.8811\n",
      "Epoch 51/200\n",
      " - 2s - loss: 0.6988 - acc: 0.8632\n",
      "Epoch 52/200\n",
      " - 2s - loss: 0.6568 - acc: 0.8761\n",
      "Epoch 53/200\n",
      " - 2s - loss: 0.6404 - acc: 0.8711\n",
      "Epoch 54/200\n",
      " - 2s - loss: 0.6577 - acc: 0.8725\n",
      "Epoch 55/200\n",
      " - 2s - loss: 0.6560 - acc: 0.8604\n",
      "Epoch 56/200\n",
      " - 2s - loss: 0.6499 - acc: 0.8618\n",
      "Epoch 57/200\n",
      " - 2s - loss: 0.7346 - acc: 0.8397\n",
      "Epoch 58/200\n",
      " - 2s - loss: 0.7672 - acc: 0.8319\n",
      "Epoch 59/200\n",
      " - 2s - loss: 0.7242 - acc: 0.8390\n",
      "Epoch 60/200\n",
      " - 2s - loss: 0.6659 - acc: 0.8540\n",
      "Epoch 61/200\n",
      " - 2s - loss: 0.6435 - acc: 0.8789\n",
      "Epoch 62/200\n",
      " - 2s - loss: 0.6530 - acc: 0.8704\n",
      "Epoch 63/200\n",
      " - 2s - loss: 0.6157 - acc: 0.8796\n",
      "Epoch 64/200\n",
      " - 2s - loss: 0.6409 - acc: 0.8789\n",
      "Epoch 65/200\n",
      " - 2s - loss: 0.6220 - acc: 0.8697\n",
      "Epoch 66/200\n",
      " - 2s - loss: 0.6188 - acc: 0.8825\n",
      "Epoch 67/200\n",
      " - 2s - loss: 0.6523 - acc: 0.8718\n",
      "Epoch 68/200\n",
      " - 2s - loss: 0.6805 - acc: 0.8754\n",
      "Epoch 69/200\n",
      " - 2s - loss: 1.0644 - acc: 0.8034\n",
      "Epoch 70/200\n",
      " - 2s - loss: 0.6573 - acc: 0.8732\n",
      "Epoch 71/200\n",
      " - 2s - loss: 0.6460 - acc: 0.8754\n",
      "Epoch 72/200\n",
      " - 2s - loss: 0.6437 - acc: 0.8761\n",
      "Epoch 73/200\n",
      " - 2s - loss: 0.6087 - acc: 0.8889\n",
      "Epoch 74/200\n",
      " - 2s - loss: 0.6225 - acc: 0.8803\n",
      "Epoch 75/200\n",
      " - 2s - loss: 0.6504 - acc: 0.8689\n",
      "Epoch 76/200\n",
      " - 2s - loss: 0.6245 - acc: 0.8782\n",
      "Epoch 77/200\n",
      " - 2s - loss: 0.6011 - acc: 0.8853\n",
      "Epoch 78/200\n",
      " - 2s - loss: 0.6221 - acc: 0.8689\n",
      "Epoch 79/200\n",
      " - 2s - loss: 0.5731 - acc: 0.8925\n",
      "Epoch 80/200\n",
      " - 2s - loss: 0.6366 - acc: 0.8604\n",
      "Epoch 81/200\n",
      " - 2s - loss: 0.5794 - acc: 0.8939\n",
      "Epoch 82/200\n",
      " - 2s - loss: 0.6108 - acc: 0.8811\n",
      "Epoch 83/200\n",
      " - 2s - loss: 0.6566 - acc: 0.8640\n",
      "Epoch 84/200\n",
      " - 2s - loss: 0.6210 - acc: 0.8754\n",
      "Epoch 85/200\n",
      " - 2s - loss: 0.5807 - acc: 0.8910\n",
      "Epoch 86/200\n",
      " - 2s - loss: 0.6769 - acc: 0.8590\n",
      "Epoch 87/200\n",
      " - 2s - loss: 0.5937 - acc: 0.8917\n",
      "Epoch 88/200\n",
      " - 2s - loss: 0.5738 - acc: 0.9017\n",
      "Epoch 89/200\n",
      " - 2s - loss: 0.5780 - acc: 0.8875\n",
      "Epoch 90/200\n",
      " - 2s - loss: 0.5721 - acc: 0.8846\n",
      "Epoch 91/200\n",
      " - 2s - loss: 0.6629 - acc: 0.8476\n",
      "Epoch 92/200\n",
      " - 2s - loss: 0.5677 - acc: 0.8917\n",
      "Epoch 93/200\n",
      " - 2s - loss: 0.5799 - acc: 0.8839\n",
      "Epoch 94/200\n",
      " - 2s - loss: 0.6055 - acc: 0.8811\n",
      "Epoch 95/200\n",
      " - 2s - loss: 0.6126 - acc: 0.8647\n",
      "Epoch 96/200\n",
      " - 2s - loss: 0.5441 - acc: 0.8889\n",
      "Epoch 97/200\n",
      " - 2s - loss: 0.5552 - acc: 0.8967\n",
      "Epoch 98/200\n",
      " - 2s - loss: 0.5488 - acc: 0.8832\n",
      "Epoch 99/200\n",
      " - 2s - loss: 0.5322 - acc: 0.9046\n",
      "Epoch 100/200\n",
      " - 2s - loss: 0.5847 - acc: 0.8860\n",
      "Epoch 101/200\n",
      " - 2s - loss: 0.5239 - acc: 0.8825\n",
      "Epoch 102/200\n",
      " - 2s - loss: 0.5210 - acc: 0.8939\n",
      "Epoch 103/200\n",
      " - 2s - loss: 0.5269 - acc: 0.8825\n",
      "Epoch 104/200\n",
      " - 2s - loss: 0.6873 - acc: 0.8611\n",
      "Epoch 105/200\n",
      " - 2s - loss: 0.6196 - acc: 0.8526\n",
      "Epoch 106/200\n",
      " - 2s - loss: 0.4567 - acc: 0.8981\n",
      "Epoch 107/200\n",
      " - 2s - loss: 0.5755 - acc: 0.8782\n",
      "Epoch 108/200\n",
      " - 2s - loss: 0.5350 - acc: 0.8825\n",
      "Epoch 109/200\n",
      " - 2s - loss: 0.4965 - acc: 0.8925\n",
      "Epoch 110/200\n",
      " - 2s - loss: 0.5209 - acc: 0.9017\n",
      "Epoch 111/200\n",
      " - 2s - loss: 0.4772 - acc: 0.8960\n",
      "Epoch 112/200\n",
      " - 2s - loss: 0.6147 - acc: 0.8689\n",
      "Epoch 113/200\n",
      " - 2s - loss: 0.4926 - acc: 0.8967\n",
      "Epoch 114/200\n",
      " - 2s - loss: 0.4797 - acc: 0.8932\n",
      "Epoch 115/200\n",
      " - 2s - loss: 0.4783 - acc: 0.8981\n",
      "Epoch 116/200\n",
      " - 2s - loss: 0.4344 - acc: 0.9110\n",
      "Epoch 117/200\n",
      " - 2s - loss: 0.5671 - acc: 0.8511\n",
      "Epoch 118/200\n",
      " - 2s - loss: 0.5255 - acc: 0.8704\n",
      "Epoch 119/200\n",
      " - 2s - loss: 0.6328 - acc: 0.8590\n",
      "Epoch 120/200\n",
      " - 2s - loss: 0.4766 - acc: 0.8953\n",
      "Epoch 121/200\n",
      " - 2s - loss: 0.4692 - acc: 0.8896\n",
      "Epoch 122/200\n",
      " - 2s - loss: 0.5391 - acc: 0.8618\n",
      "Epoch 123/200\n",
      " - 2s - loss: 0.5112 - acc: 0.8725\n",
      "Epoch 124/200\n",
      " - 2s - loss: 0.5386 - acc: 0.8604\n",
      "Epoch 125/200\n",
      " - 2s - loss: 0.4603 - acc: 0.9003\n",
      "Epoch 126/200\n",
      " - 2s - loss: 0.4677 - acc: 0.8946\n",
      "Epoch 127/200\n",
      " - 2s - loss: 0.4931 - acc: 0.8853\n",
      "Epoch 128/200\n",
      " - 2s - loss: 0.4307 - acc: 0.8932\n",
      "Epoch 129/200\n",
      " - 2s - loss: 0.4399 - acc: 0.9038\n",
      "Epoch 130/200\n",
      " - 2s - loss: 0.4351 - acc: 0.8981\n",
      "Epoch 131/200\n",
      " - 2s - loss: 0.4815 - acc: 0.9038\n",
      "Epoch 132/200\n",
      " - 2s - loss: 0.9358 - acc: 0.7963\n",
      "Epoch 133/200\n",
      " - 2s - loss: 0.5780 - acc: 0.8689\n",
      "Epoch 134/200\n",
      " - 2s - loss: 0.4976 - acc: 0.9031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/200\n",
      " - 2s - loss: 0.4774 - acc: 0.8989\n",
      "Epoch 136/200\n",
      " - 2s - loss: 0.3931 - acc: 0.9174\n",
      "Epoch 137/200\n",
      " - 2s - loss: 0.4583 - acc: 0.8946\n",
      "Epoch 138/200\n",
      " - 2s - loss: 0.5232 - acc: 0.8889\n",
      "Epoch 139/200\n",
      " - 2s - loss: 0.4179 - acc: 0.8989\n",
      "Epoch 140/200\n",
      " - 2s - loss: 0.4190 - acc: 0.8996\n",
      "Epoch 141/200\n",
      " - 2s - loss: 0.4239 - acc: 0.8960\n",
      "Epoch 142/200\n",
      " - 2s - loss: 0.4410 - acc: 0.9081\n",
      "Epoch 143/200\n",
      " - 2s - loss: 0.3970 - acc: 0.8989\n",
      "Epoch 144/200\n",
      " - 2s - loss: 0.4026 - acc: 0.9167\n",
      "Epoch 145/200\n",
      " - 2s - loss: 0.3510 - acc: 0.9217\n",
      "Epoch 146/200\n",
      " - 2s - loss: 0.4154 - acc: 0.9095\n",
      "Epoch 147/200\n",
      " - 2s - loss: 0.3734 - acc: 0.9238\n",
      "Epoch 148/200\n",
      " - 2s - loss: 0.4005 - acc: 0.9131\n",
      "Epoch 149/200\n",
      " - 2s - loss: 0.3929 - acc: 0.9202\n",
      "Epoch 150/200\n",
      " - 2s - loss: 0.3763 - acc: 0.9245\n",
      "Epoch 151/200\n",
      " - 2s - loss: 0.3572 - acc: 0.9202\n",
      "Epoch 152/200\n",
      " - 2s - loss: 0.3824 - acc: 0.9081\n",
      "Epoch 153/200\n",
      " - 2s - loss: 0.3406 - acc: 0.9231\n",
      "Epoch 154/200\n",
      " - 2s - loss: 0.3442 - acc: 0.9160\n",
      "Epoch 155/200\n",
      " - 2s - loss: 0.3074 - acc: 0.9295\n",
      "Epoch 156/200\n",
      " - 2s - loss: 0.3077 - acc: 0.9366\n",
      "Epoch 157/200\n",
      " - 2s - loss: 0.5147 - acc: 0.9167\n",
      "Epoch 158/200\n",
      " - 2s - loss: 0.4232 - acc: 0.9181\n",
      "Epoch 159/200\n",
      " - 2s - loss: 0.3722 - acc: 0.9359\n",
      "Epoch 160/200\n",
      " - 2s - loss: 0.3736 - acc: 0.9323\n",
      "Epoch 161/200\n",
      " - 2s - loss: 0.2804 - acc: 0.9501\n",
      "Epoch 162/200\n",
      " - 2s - loss: 0.3719 - acc: 0.9330\n",
      "Epoch 163/200\n",
      " - 2s - loss: 0.3305 - acc: 0.9466\n",
      "Epoch 164/200\n",
      " - 2s - loss: 0.5440 - acc: 0.9003\n",
      "Epoch 165/200\n",
      " - 2s - loss: 0.4103 - acc: 0.9088\n",
      "Epoch 166/200\n",
      " - 2s - loss: 0.3322 - acc: 0.9373\n",
      "Epoch 167/200\n",
      " - 2s - loss: 0.3179 - acc: 0.9409\n",
      "Epoch 168/200\n",
      " - 2s - loss: 0.5511 - acc: 0.8903\n",
      "Epoch 169/200\n",
      " - 2s - loss: 0.3047 - acc: 0.9359\n",
      "Epoch 170/200\n",
      " - 2s - loss: 0.3030 - acc: 0.9444\n",
      "Epoch 171/200\n",
      " - 2s - loss: 0.2669 - acc: 0.9573\n",
      "Epoch 172/200\n",
      " - 2s - loss: 0.2753 - acc: 0.9523\n",
      "Epoch 173/200\n",
      " - 2s - loss: 2.1397 - acc: 0.7322\n",
      "Epoch 174/200\n",
      " - 2s - loss: 0.4606 - acc: 0.9259\n",
      "Epoch 175/200\n",
      " - 2s - loss: 0.4109 - acc: 0.9238\n",
      "Epoch 176/200\n",
      " - 2s - loss: 0.2812 - acc: 0.9473\n",
      "Epoch 177/200\n",
      " - 2s - loss: 0.2723 - acc: 0.9444\n",
      "Epoch 178/200\n",
      " - 2s - loss: 0.2158 - acc: 0.9566\n",
      "Epoch 179/200\n",
      " - 2s - loss: 0.2190 - acc: 0.9608\n",
      "Epoch 180/200\n",
      " - 2s - loss: 0.3023 - acc: 0.9501\n",
      "Epoch 181/200\n",
      " - 2s - loss: 0.2415 - acc: 0.9530\n",
      "Epoch 182/200\n",
      " - 2s - loss: 0.3406 - acc: 0.9373\n",
      "Epoch 183/200\n",
      " - 2s - loss: 0.2366 - acc: 0.9509\n",
      "Epoch 184/200\n",
      " - 2s - loss: 0.2242 - acc: 0.9509\n",
      "Epoch 185/200\n",
      " - 2s - loss: 0.4085 - acc: 0.9266\n",
      "Epoch 186/200\n",
      " - 2s - loss: 0.2758 - acc: 0.9466\n",
      "Epoch 187/200\n",
      " - 2s - loss: 0.2752 - acc: 0.9608\n",
      "Epoch 188/200\n",
      " - 2s - loss: 0.3134 - acc: 0.9380\n",
      "Epoch 189/200\n",
      " - 2s - loss: 0.1955 - acc: 0.9580\n",
      "Epoch 190/200\n",
      " - 2s - loss: 0.1573 - acc: 0.9694\n",
      "Epoch 191/200\n",
      " - 2s - loss: 0.1869 - acc: 0.9651\n",
      "Epoch 192/200\n",
      " - 2s - loss: 0.1996 - acc: 0.9587\n",
      "Epoch 193/200\n",
      " - 2s - loss: 0.1604 - acc: 0.9687\n",
      "Epoch 194/200\n",
      " - 2s - loss: 0.4782 - acc: 0.9038\n",
      "Epoch 195/200\n",
      " - 2s - loss: 0.3422 - acc: 0.9551\n",
      "Epoch 196/200\n",
      " - 2s - loss: 0.2393 - acc: 0.9558\n",
      "Epoch 197/200\n",
      " - 2s - loss: 0.1526 - acc: 0.9672\n",
      "Epoch 198/200\n",
      " - 2s - loss: 0.1147 - acc: 0.9779\n",
      "Epoch 199/200\n",
      " - 2s - loss: 0.4077 - acc: 0.9580\n",
      "Epoch 200/200\n",
      " - 2s - loss: 0.2743 - acc: 0.9423\n",
      "[[252   1   0   0   1   0]\n",
      " [  3 161   0   0   8   0]\n",
      " [  0   0 157   0   1   0]\n",
      " [  0   0   0  19   1   1]\n",
      " [  0   1   0   0  56  11]\n",
      " [  0   0   0   0   5  14]]\n",
      "\n",
      "\n",
      "<class 'keras.engine.sequential.Sequential'>\n",
      "||||| Accuracy : 0.8820341119511094 |||||\n",
      "\n",
      "\n",
      "Best actual accuracy : 0.8987347690672499\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_27 (Dense)             (None, 64)                3496384   \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 100)               6500      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 3,523,690\n",
      "Trainable params: 3,523,690\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training...\n",
      "Epoch 1/200\n",
      " - 2s - loss: 1.8561 - acc: 0.1624\n",
      "Epoch 2/200\n",
      " - 2s - loss: 1.8007 - acc: 0.1574\n",
      "Epoch 3/200\n",
      " - 2s - loss: 1.7196 - acc: 0.2165\n",
      "Epoch 4/200\n",
      " - 2s - loss: 1.5558 - acc: 0.3412\n",
      "Epoch 5/200\n",
      " - 2s - loss: 1.4029 - acc: 0.4359\n",
      "Epoch 6/200\n",
      " - 2s - loss: 1.2773 - acc: 0.5142\n",
      "Epoch 7/200\n",
      " - 2s - loss: 1.1485 - acc: 0.5684\n",
      "Epoch 8/200\n",
      " - 2s - loss: 1.1702 - acc: 0.6097\n",
      "Epoch 9/200\n",
      " - 2s - loss: 1.0446 - acc: 0.6517\n",
      "Epoch 10/200\n",
      " - 2s - loss: 1.0695 - acc: 0.6660\n",
      "Epoch 11/200\n",
      " - 2s - loss: 0.9198 - acc: 0.7215\n",
      "Epoch 12/200\n",
      " - 2s - loss: 0.9410 - acc: 0.7051\n",
      "Epoch 13/200\n",
      " - 2s - loss: 0.9263 - acc: 0.7365\n",
      "Epoch 14/200\n",
      " - 2s - loss: 0.8843 - acc: 0.7429\n",
      "Epoch 15/200\n",
      " - 2s - loss: 0.8470 - acc: 0.7756\n",
      "Epoch 16/200\n",
      " - 2s - loss: 0.7875 - acc: 0.8020\n",
      "Epoch 17/200\n",
      " - 2s - loss: 0.8558 - acc: 0.7692\n",
      "Epoch 18/200\n",
      " - 2s - loss: 0.8049 - acc: 0.7913\n",
      "Epoch 19/200\n",
      " - 2s - loss: 0.7577 - acc: 0.8191\n",
      "Epoch 20/200\n",
      " - 2s - loss: 0.7956 - acc: 0.7949\n",
      "Epoch 21/200\n",
      " - 2s - loss: 0.7306 - acc: 0.8369\n",
      "Epoch 22/200\n",
      " - 2s - loss: 0.7284 - acc: 0.8291\n",
      "Epoch 23/200\n",
      " - 2s - loss: 1.4455 - acc: 0.6830\n",
      "Epoch 24/200\n",
      " - 2s - loss: 0.7455 - acc: 0.8198\n",
      "Epoch 25/200\n",
      " - 2s - loss: 0.7169 - acc: 0.8376\n",
      "Epoch 26/200\n",
      " - 2s - loss: 0.7385 - acc: 0.8226\n",
      "Epoch 27/200\n",
      " - 2s - loss: 0.6952 - acc: 0.8540\n",
      "Epoch 28/200\n",
      " - 2s - loss: 0.7155 - acc: 0.8462\n",
      "Epoch 29/200\n",
      " - 2s - loss: 0.6697 - acc: 0.8540\n",
      "Epoch 30/200\n",
      " - 2s - loss: 0.7072 - acc: 0.8561\n",
      "Epoch 31/200\n",
      " - 2s - loss: 0.6973 - acc: 0.8333\n",
      "Epoch 32/200\n",
      " - 2s - loss: 0.6788 - acc: 0.8583\n",
      "Epoch 33/200\n",
      " - 2s - loss: 0.7450 - acc: 0.8454\n",
      "Epoch 34/200\n",
      " - 2s - loss: 0.6981 - acc: 0.8583\n",
      "Epoch 35/200\n",
      " - 3s - loss: 0.6605 - acc: 0.8561\n",
      "Epoch 36/200\n",
      " - 2s - loss: 0.6871 - acc: 0.8454\n",
      "Epoch 37/200\n",
      " - 2s - loss: 0.6258 - acc: 0.8618\n",
      "Epoch 38/200\n",
      " - 2s - loss: 0.7132 - acc: 0.8554\n",
      "Epoch 39/200\n",
      " - 2s - loss: 0.6393 - acc: 0.8604\n",
      "Epoch 40/200\n",
      " - 2s - loss: 0.6437 - acc: 0.8640\n",
      "Epoch 41/200\n",
      " - 2s - loss: 0.6070 - acc: 0.8540\n",
      "Epoch 42/200\n",
      " - 2s - loss: 0.6532 - acc: 0.8504\n",
      "Epoch 43/200\n",
      " - 2s - loss: 0.6554 - acc: 0.8575\n",
      "Epoch 44/200\n",
      " - 2s - loss: 0.5582 - acc: 0.8661\n",
      "Epoch 45/200\n",
      " - 2s - loss: 0.5871 - acc: 0.8825\n",
      "Epoch 46/200\n",
      " - 2s - loss: 0.6016 - acc: 0.8540\n",
      "Epoch 47/200\n",
      " - 2s - loss: 0.5509 - acc: 0.8618\n",
      "Epoch 48/200\n",
      " - 2s - loss: 0.5310 - acc: 0.8675\n",
      "Epoch 49/200\n",
      " - 2s - loss: 0.5955 - acc: 0.8568\n",
      "Epoch 50/200\n",
      " - 2s - loss: 0.4733 - acc: 0.8746\n",
      "Epoch 51/200\n",
      " - 2s - loss: 0.5713 - acc: 0.8825\n",
      "Epoch 52/200\n",
      " - 2s - loss: 0.4651 - acc: 0.9010\n",
      "Epoch 53/200\n",
      " - 2s - loss: 0.5105 - acc: 0.8668\n",
      "Epoch 54/200\n",
      " - 2s - loss: 0.4650 - acc: 0.8732\n",
      "Epoch 55/200\n",
      " - 2s - loss: 0.4366 - acc: 0.8910\n",
      "Epoch 56/200\n",
      " - 2s - loss: 0.4305 - acc: 0.8818\n",
      "Epoch 57/200\n",
      " - 2s - loss: 0.4960 - acc: 0.8932\n",
      "Epoch 58/200\n",
      " - 2s - loss: 0.5143 - acc: 0.8704\n",
      "Epoch 59/200\n",
      " - 2s - loss: 0.3816 - acc: 0.9060\n",
      "Epoch 60/200\n",
      " - 2s - loss: 0.4550 - acc: 0.9010\n",
      "Epoch 61/200\n",
      " - 2s - loss: 0.3962 - acc: 0.9131\n",
      "Epoch 62/200\n",
      " - 2s - loss: 0.3826 - acc: 0.9131\n",
      "Epoch 63/200\n",
      " - 2s - loss: 0.4229 - acc: 0.8967\n",
      "Epoch 64/200\n",
      " - 2s - loss: 0.4882 - acc: 0.8903\n",
      "Epoch 65/200\n",
      " - 2s - loss: 0.3679 - acc: 0.9117\n",
      "Epoch 66/200\n",
      " - 2s - loss: 0.3687 - acc: 0.9074\n",
      "Epoch 67/200\n",
      " - 2s - loss: 0.3616 - acc: 0.9209\n",
      "Epoch 68/200\n",
      " - 2s - loss: 0.4020 - acc: 0.9024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/200\n",
      " - 2s - loss: 0.3123 - acc: 0.9288\n",
      "Epoch 70/200\n",
      " - 2s - loss: 0.3948 - acc: 0.8818\n",
      "Epoch 71/200\n",
      " - 2s - loss: 0.4381 - acc: 0.8974\n",
      "Epoch 72/200\n",
      " - 2s - loss: 0.4146 - acc: 0.9024\n",
      "Epoch 73/200\n",
      " - 2s - loss: 0.4468 - acc: 0.8825\n",
      "Epoch 74/200\n",
      " - 2s - loss: 0.4137 - acc: 0.8775\n",
      "Epoch 75/200\n",
      " - 2s - loss: 0.3095 - acc: 0.9338\n",
      "Epoch 76/200\n",
      " - 2s - loss: 0.3816 - acc: 0.9031\n",
      "Epoch 77/200\n",
      " - 2s - loss: 0.2752 - acc: 0.9338\n",
      "Epoch 78/200\n",
      " - 2s - loss: 0.3015 - acc: 0.9238\n",
      "Epoch 79/200\n",
      " - 2s - loss: 0.2716 - acc: 0.9295\n",
      "Epoch 80/200\n",
      " - 2s - loss: 0.5866 - acc: 0.8910\n",
      "Epoch 81/200\n",
      " - 2s - loss: 0.3041 - acc: 0.9231\n",
      "Epoch 82/200\n",
      " - 2s - loss: 0.2997 - acc: 0.9288\n",
      "Epoch 83/200\n",
      " - 2s - loss: 0.3942 - acc: 0.9095\n",
      "Epoch 84/200\n",
      " - 2s - loss: 0.3048 - acc: 0.9323\n",
      "Epoch 85/200\n",
      " - 2s - loss: 0.3590 - acc: 0.9117\n",
      "Epoch 86/200\n",
      " - 2s - loss: 0.3072 - acc: 0.9217\n",
      "Epoch 87/200\n",
      " - 2s - loss: 0.2998 - acc: 0.9266\n",
      "Epoch 88/200\n",
      " - 2s - loss: 0.2501 - acc: 0.9387\n",
      "Epoch 89/200\n",
      " - 2s - loss: 0.3253 - acc: 0.9145\n",
      "Epoch 90/200\n",
      " - 2s - loss: 0.3047 - acc: 0.9259\n",
      "Epoch 91/200\n",
      " - 2s - loss: 0.2298 - acc: 0.9345\n",
      "Epoch 92/200\n",
      " - 2s - loss: 0.1880 - acc: 0.9487\n",
      "Epoch 93/200\n",
      " - 2s - loss: 0.2922 - acc: 0.9316\n",
      "Epoch 94/200\n",
      " - 2s - loss: 0.2818 - acc: 0.9160\n",
      "Epoch 95/200\n",
      " - 2s - loss: 0.2691 - acc: 0.9295\n",
      "Epoch 96/200\n",
      " - 2s - loss: 0.3016 - acc: 0.9430\n",
      "Epoch 97/200\n",
      " - 2s - loss: 0.2416 - acc: 0.9373\n",
      "Epoch 98/200\n",
      " - 2s - loss: 0.3163 - acc: 0.9302\n",
      "Epoch 99/200\n",
      " - 2s - loss: 0.2515 - acc: 0.9480\n",
      "Epoch 100/200\n",
      " - 2s - loss: 0.1710 - acc: 0.9551\n",
      "Epoch 101/200\n",
      " - 2s - loss: 0.2768 - acc: 0.9544\n",
      "Epoch 102/200\n",
      " - 2s - loss: 0.2460 - acc: 0.9288\n",
      "Epoch 103/200\n",
      " - 2s - loss: 0.1667 - acc: 0.9566\n",
      "Epoch 104/200\n",
      " - 2s - loss: 0.1799 - acc: 0.9544\n",
      "Epoch 105/200\n",
      " - 2s - loss: 0.1689 - acc: 0.9573\n",
      "Epoch 106/200\n",
      " - 2s - loss: 0.1376 - acc: 0.9672\n",
      "Epoch 107/200\n",
      " - 2s - loss: 0.1899 - acc: 0.9509\n",
      "Epoch 108/200\n",
      " - 2s - loss: 0.2221 - acc: 0.9537\n",
      "Epoch 109/200\n",
      " - 2s - loss: 0.1826 - acc: 0.9630\n",
      "Epoch 110/200\n",
      " - 2s - loss: 0.1849 - acc: 0.9558\n",
      "Epoch 111/200\n",
      " - 2s - loss: 0.1509 - acc: 0.9601\n",
      "Epoch 112/200\n",
      " - 2s - loss: 0.1423 - acc: 0.9615\n",
      "Epoch 113/200\n",
      " - 2s - loss: 0.2200 - acc: 0.9473\n",
      "Epoch 114/200\n",
      " - 2s - loss: 0.0983 - acc: 0.9694\n",
      "Epoch 115/200\n",
      " - 2s - loss: 0.1983 - acc: 0.9423\n",
      "Epoch 116/200\n",
      " - 2s - loss: 0.7182 - acc: 0.8796\n",
      "Epoch 117/200\n",
      " - 2s - loss: 0.3408 - acc: 0.9380\n",
      "Epoch 118/200\n",
      " - 2s - loss: 0.1269 - acc: 0.9679\n",
      "Epoch 119/200\n",
      " - 2s - loss: 0.2038 - acc: 0.9544\n",
      "Epoch 120/200\n",
      " - 2s - loss: 0.2165 - acc: 0.9437\n",
      "Epoch 121/200\n",
      " - 2s - loss: 0.1790 - acc: 0.9551\n",
      "Epoch 122/200\n",
      " - 2s - loss: 0.1940 - acc: 0.9487\n",
      "Epoch 123/200\n",
      " - 2s - loss: 0.2242 - acc: 0.9409\n",
      "Epoch 124/200\n",
      " - 2s - loss: 0.1477 - acc: 0.9608\n",
      "Epoch 125/200\n",
      " - 2s - loss: 0.2570 - acc: 0.9509\n",
      "Epoch 126/200\n",
      " - 2s - loss: 0.1431 - acc: 0.9658\n",
      "Epoch 127/200\n",
      " - 2s - loss: 0.1873 - acc: 0.9494\n",
      "Epoch 128/200\n",
      " - 2s - loss: 0.2056 - acc: 0.9501\n",
      "Epoch 129/200\n",
      " - 2s - loss: 0.1323 - acc: 0.9701\n",
      "Epoch 130/200\n",
      " - 2s - loss: 0.2811 - acc: 0.9459\n",
      "Epoch 131/200\n",
      " - 2s - loss: 0.0930 - acc: 0.9779\n",
      "Epoch 132/200\n",
      " - 2s - loss: 0.1614 - acc: 0.9658\n",
      "Epoch 133/200\n",
      " - 2s - loss: 0.0968 - acc: 0.9765\n",
      "Epoch 134/200\n",
      " - 2s - loss: 0.2066 - acc: 0.9658\n",
      "Epoch 135/200\n",
      " - 2s - loss: 0.0979 - acc: 0.9801\n",
      "Epoch 136/200\n",
      " - 2s - loss: 0.1303 - acc: 0.9744\n",
      "Epoch 137/200\n",
      " - 2s - loss: 0.4016 - acc: 0.9181\n",
      "Epoch 138/200\n",
      " - 2s - loss: 0.1210 - acc: 0.9758\n",
      "Epoch 139/200\n",
      " - 2s - loss: 0.1089 - acc: 0.9687\n",
      "Epoch 140/200\n",
      " - 2s - loss: 0.1780 - acc: 0.9637\n",
      "Epoch 141/200\n",
      " - 2s - loss: 0.0899 - acc: 0.9736\n",
      "Epoch 142/200\n",
      " - 2s - loss: 0.1480 - acc: 0.9736\n",
      "Epoch 143/200\n",
      " - 2s - loss: 0.1251 - acc: 0.9687\n",
      "Epoch 144/200\n",
      " - 2s - loss: 0.0472 - acc: 0.9879\n",
      "Epoch 145/200\n",
      " - 2s - loss: 0.1121 - acc: 0.9715\n",
      "Epoch 146/200\n",
      " - 2s - loss: 0.0862 - acc: 0.9765\n",
      "Epoch 147/200\n",
      " - 2s - loss: 0.0712 - acc: 0.9836\n",
      "Epoch 148/200\n",
      " - 2s - loss: 0.1291 - acc: 0.9722\n",
      "Epoch 149/200\n",
      " - 2s - loss: 0.1330 - acc: 0.9665\n",
      "Epoch 150/200\n",
      " - 2s - loss: 0.0710 - acc: 0.9822\n",
      "Epoch 151/200\n",
      " - 2s - loss: 0.1236 - acc: 0.9751\n",
      "Epoch 152/200\n",
      " - 2s - loss: 0.1259 - acc: 0.9779\n",
      "Epoch 153/200\n",
      " - 2s - loss: 0.0598 - acc: 0.9836\n",
      "Epoch 154/200\n",
      " - 2s - loss: 0.3731 - acc: 0.9231\n",
      "Epoch 155/200\n",
      " - 2s - loss: 0.1579 - acc: 0.9651\n",
      "Epoch 156/200\n",
      " - 2s - loss: 0.1363 - acc: 0.9694\n",
      "Epoch 157/200\n",
      " - 2s - loss: 0.1830 - acc: 0.9523\n",
      "Epoch 158/200\n",
      " - 2s - loss: 0.0969 - acc: 0.9779\n",
      "Epoch 159/200\n",
      " - 2s - loss: 0.2538 - acc: 0.9323\n",
      "Epoch 160/200\n",
      " - 2s - loss: 0.1095 - acc: 0.9758\n",
      "Epoch 161/200\n",
      " - 2s - loss: 0.2806 - acc: 0.9323\n",
      "Epoch 162/200\n",
      " - 2s - loss: 0.3349 - acc: 0.9110\n",
      "Epoch 163/200\n",
      " - 2s - loss: 0.1889 - acc: 0.9558\n",
      "Epoch 164/200\n",
      " - 2s - loss: 0.3979 - acc: 0.9181\n",
      "Epoch 165/200\n",
      " - 2s - loss: 0.2094 - acc: 0.9566\n",
      "Epoch 166/200\n",
      " - 2s - loss: 0.2348 - acc: 0.9395\n",
      "Epoch 167/200\n",
      " - 2s - loss: 0.1127 - acc: 0.9758\n",
      "Epoch 168/200\n",
      " - 2s - loss: 0.0868 - acc: 0.9758\n",
      "Epoch 169/200\n",
      " - 2s - loss: 0.0872 - acc: 0.9829\n",
      "Epoch 170/200\n",
      " - 2s - loss: 0.0574 - acc: 0.9843\n",
      "Epoch 171/200\n",
      " - 2s - loss: 0.2697 - acc: 0.9416\n",
      "Epoch 172/200\n",
      " - 2s - loss: 0.0466 - acc: 0.9850\n",
      "Epoch 173/200\n",
      " - 2s - loss: 0.1587 - acc: 0.9701\n",
      "Epoch 174/200\n",
      " - 2s - loss: 0.0540 - acc: 0.9843\n",
      "Epoch 175/200\n",
      " - 2s - loss: 0.0913 - acc: 0.9815\n",
      "Epoch 176/200\n",
      " - 2s - loss: 0.2967 - acc: 0.9487\n",
      "Epoch 177/200\n",
      " - 2s - loss: 0.0916 - acc: 0.9786\n",
      "Epoch 178/200\n",
      " - 2s - loss: 0.1021 - acc: 0.9751\n",
      "Epoch 179/200\n",
      " - 2s - loss: 0.1216 - acc: 0.9744\n",
      "Epoch 180/200\n",
      " - 2s - loss: 0.0801 - acc: 0.9808\n",
      "Epoch 181/200\n",
      " - 2s - loss: 0.0685 - acc: 0.9850\n",
      "Epoch 182/200\n",
      " - 2s - loss: 0.0224 - acc: 0.9922\n",
      "Epoch 183/200\n",
      " - 2s - loss: 0.0156 - acc: 0.9950\n",
      "Epoch 184/200\n",
      " - 2s - loss: 0.0130 - acc: 0.9964\n",
      "Epoch 185/200\n",
      " - 2s - loss: 0.0225 - acc: 0.9915\n",
      "Epoch 186/200\n",
      " - 2s - loss: 0.1626 - acc: 0.9758\n",
      "Epoch 187/200\n",
      " - 2s - loss: 0.1535 - acc: 0.9615\n",
      "Epoch 188/200\n",
      " - 2s - loss: 0.1434 - acc: 0.9736\n",
      "Epoch 189/200\n",
      " - 2s - loss: 0.0621 - acc: 0.9829\n",
      "Epoch 190/200\n",
      " - 2s - loss: 0.0640 - acc: 0.9843\n",
      "Epoch 191/200\n",
      " - 2s - loss: 0.0311 - acc: 0.9936\n",
      "Epoch 192/200\n",
      " - 2s - loss: 0.0173 - acc: 0.9957\n",
      "Epoch 193/200\n",
      " - 2s - loss: 0.0091 - acc: 0.9979\n",
      "Epoch 194/200\n",
      " - 2s - loss: 0.1406 - acc: 0.9729\n",
      "Epoch 195/200\n",
      " - 2s - loss: 0.0292 - acc: 0.9950\n",
      "Epoch 196/200\n",
      " - 2s - loss: 0.1708 - acc: 0.9758\n",
      "Epoch 197/200\n",
      " - 2s - loss: 0.0466 - acc: 0.9872\n",
      "Epoch 198/200\n",
      " - 2s - loss: 0.0346 - acc: 0.9929\n",
      "Epoch 199/200\n",
      " - 2s - loss: 0.1269 - acc: 0.9751\n",
      "Epoch 200/200\n",
      " - 2s - loss: 0.0505 - acc: 0.9872\n",
      "[[249   3   0   0   2   0]\n",
      " [  1 163   0   1   7   0]\n",
      " [  0   1 157   0   0   0]\n",
      " [  0   0   0  20   1   0]\n",
      " [  0   2   0   0  63   3]\n",
      " [  0   0   0   0  10   9]]\n",
      "\n",
      "\n",
      "<class 'keras.engine.sequential.Sequential'>\n",
      "||||| Accuracy : 0.9036523563965639 |||||\n",
      "\n",
      "\n",
      "Best actual accuracy : 0.8987347690672499\n",
      "\n",
      "\n",
      "\n",
      " BEST MODEL ! \n",
      "Saving... \n",
      "\n",
      "\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_32 (Dense)             (None, 64)                3496384   \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1000)              65000     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 6)                 6006      \n",
      "=================================================================\n",
      "Total params: 5,569,390\n",
      "Trainable params: 5,569,390\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training...\n",
      "Epoch 1/200\n",
      " - 3s - loss: 1.7899 - acc: 0.1282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200\n",
      " - 3s - loss: 1.6944 - acc: 0.2707\n",
      "Epoch 3/200\n",
      " - 3s - loss: 1.4316 - acc: 0.4373\n",
      "Epoch 4/200\n",
      " - 3s - loss: 1.2398 - acc: 0.5456\n",
      "Epoch 5/200\n",
      " - 3s - loss: 1.0019 - acc: 0.6588\n",
      "Epoch 6/200\n",
      " - 3s - loss: 0.9384 - acc: 0.7158\n",
      "Epoch 7/200\n",
      " - 3s - loss: 0.8838 - acc: 0.7585\n",
      "Epoch 8/200\n",
      " - 3s - loss: 0.8385 - acc: 0.7877\n",
      "Epoch 9/200\n",
      " - 3s - loss: 0.8242 - acc: 0.7942\n",
      "Epoch 10/200\n",
      " - 3s - loss: 0.7687 - acc: 0.7999\n",
      "Epoch 11/200\n",
      " - 3s - loss: 0.7455 - acc: 0.8091\n",
      "Epoch 12/200\n",
      " - 3s - loss: 0.7127 - acc: 0.8319\n",
      "Epoch 13/200\n",
      " - 3s - loss: 0.6992 - acc: 0.8319\n",
      "Epoch 14/200\n",
      " - 3s - loss: 0.7610 - acc: 0.8127\n",
      "Epoch 15/200\n",
      " - 3s - loss: 0.6620 - acc: 0.8333\n",
      "Epoch 16/200\n",
      " - 3s - loss: 0.6762 - acc: 0.8540\n",
      "Epoch 17/200\n",
      " - 3s - loss: 0.6301 - acc: 0.8440\n",
      "Epoch 18/200\n",
      " - 3s - loss: 0.5585 - acc: 0.8604\n",
      "Epoch 19/200\n",
      " - 3s - loss: 0.5554 - acc: 0.8746\n",
      "Epoch 20/200\n",
      " - 3s - loss: 0.5029 - acc: 0.8860\n",
      "Epoch 21/200\n",
      " - 3s - loss: 0.5778 - acc: 0.8668\n",
      "Epoch 22/200\n",
      " - 3s - loss: 0.4959 - acc: 0.8746\n",
      "Epoch 23/200\n",
      " - 3s - loss: 0.4706 - acc: 0.8853\n",
      "Epoch 24/200\n",
      " - 3s - loss: 0.4993 - acc: 0.8711\n",
      "Epoch 25/200\n",
      " - 3s - loss: 0.4971 - acc: 0.8782\n",
      "Epoch 26/200\n",
      " - 3s - loss: 0.4285 - acc: 0.8981\n",
      "Epoch 27/200\n",
      " - 3s - loss: 0.4282 - acc: 0.8903\n",
      "Epoch 28/200\n",
      " - 3s - loss: 0.4228 - acc: 0.8811\n",
      "Epoch 29/200\n",
      " - 3s - loss: 0.4449 - acc: 0.8996\n",
      "Epoch 30/200\n",
      " - 3s - loss: 0.3738 - acc: 0.9088\n",
      "Epoch 31/200\n",
      " - 3s - loss: 0.4070 - acc: 0.9024\n",
      "Epoch 32/200\n",
      " - 3s - loss: 0.4287 - acc: 0.8832\n",
      "Epoch 33/200\n",
      " - 3s - loss: 0.3483 - acc: 0.9181\n",
      "Epoch 34/200\n",
      " - 3s - loss: 0.3832 - acc: 0.9024\n",
      "Epoch 35/200\n",
      " - 3s - loss: 0.4697 - acc: 0.8889\n",
      "Epoch 36/200\n",
      " - 3s - loss: 0.3609 - acc: 0.9117\n",
      "Epoch 37/200\n",
      " - 3s - loss: 0.3537 - acc: 0.9124\n",
      "Epoch 38/200\n",
      " - 3s - loss: 0.3693 - acc: 0.9081\n",
      "Epoch 39/200\n",
      " - 3s - loss: 0.3383 - acc: 0.9174\n",
      "Epoch 40/200\n",
      " - 3s - loss: 0.4135 - acc: 0.9017\n",
      "Epoch 41/200\n",
      " - 3s - loss: 0.3187 - acc: 0.9131\n",
      "Epoch 42/200\n",
      " - 3s - loss: 0.2599 - acc: 0.9238\n",
      "Epoch 43/200\n",
      " - 3s - loss: 0.3332 - acc: 0.9103\n",
      "Epoch 44/200\n",
      " - 3s - loss: 0.2519 - acc: 0.9323\n",
      "Epoch 45/200\n",
      " - 3s - loss: 0.3860 - acc: 0.8775\n",
      "Epoch 46/200\n",
      " - 3s - loss: 0.4204 - acc: 0.8718\n",
      "Epoch 47/200\n",
      " - 3s - loss: 0.2887 - acc: 0.9288\n",
      "Epoch 48/200\n",
      " - 3s - loss: 0.2586 - acc: 0.9238\n",
      "Epoch 49/200\n",
      " - 3s - loss: 0.2259 - acc: 0.9466\n",
      "Epoch 50/200\n",
      " - 3s - loss: 0.4879 - acc: 0.9046\n",
      "Epoch 51/200\n",
      " - 3s - loss: 0.3025 - acc: 0.9266\n",
      "Epoch 52/200\n",
      " - 3s - loss: 0.2548 - acc: 0.9359\n",
      "Epoch 53/200\n",
      " - 3s - loss: 0.1678 - acc: 0.9594\n",
      "Epoch 54/200\n",
      " - 3s - loss: 0.2589 - acc: 0.9409\n",
      "Epoch 55/200\n",
      " - 3s - loss: 0.2372 - acc: 0.9330\n",
      "Epoch 56/200\n",
      " - 3s - loss: 0.4447 - acc: 0.8739\n",
      "Epoch 57/200\n",
      " - 3s - loss: 0.2446 - acc: 0.9501\n",
      "Epoch 58/200\n",
      " - 3s - loss: 0.2760 - acc: 0.9195\n",
      "Epoch 59/200\n",
      " - 3s - loss: 0.2246 - acc: 0.9330\n",
      "Epoch 60/200\n",
      " - 3s - loss: 0.1534 - acc: 0.9573\n",
      "Epoch 61/200\n",
      " - 3s - loss: 0.3134 - acc: 0.9131\n",
      "Epoch 62/200\n",
      " - 3s - loss: 0.1680 - acc: 0.9551\n",
      "Epoch 63/200\n",
      " - 3s - loss: 0.2020 - acc: 0.9423\n",
      "Epoch 64/200\n",
      " - 3s - loss: 0.1557 - acc: 0.9587\n",
      "Epoch 65/200\n",
      " - 3s - loss: 0.5084 - acc: 0.8946\n",
      "Epoch 66/200\n",
      " - 3s - loss: 0.3167 - acc: 0.9416\n",
      "Epoch 67/200\n",
      " - 3s - loss: 0.2208 - acc: 0.9466\n",
      "Epoch 68/200\n",
      " - 3s - loss: 0.2862 - acc: 0.9359\n",
      "Epoch 69/200\n",
      " - 3s - loss: 0.1772 - acc: 0.9509\n",
      "Epoch 70/200\n",
      " - 3s - loss: 0.1372 - acc: 0.9687\n",
      "Epoch 71/200\n",
      " - 3s - loss: 0.4357 - acc: 0.8704\n",
      "Epoch 72/200\n",
      " - 3s - loss: 0.1035 - acc: 0.9758\n",
      "Epoch 73/200\n",
      " - 3s - loss: 0.1290 - acc: 0.9687\n",
      "Epoch 74/200\n",
      " - 3s - loss: 0.1760 - acc: 0.9523\n",
      "Epoch 75/200\n",
      " - 3s - loss: 0.1216 - acc: 0.9672\n",
      "Epoch 76/200\n",
      " - 3s - loss: 0.1316 - acc: 0.9651\n",
      "Epoch 77/200\n",
      " - 3s - loss: 0.1993 - acc: 0.9573\n",
      "Epoch 78/200\n",
      " - 3s - loss: 0.1063 - acc: 0.9658\n",
      "Epoch 79/200\n",
      " - 3s - loss: 0.1113 - acc: 0.9779\n",
      "Epoch 80/200\n",
      " - 3s - loss: 0.1655 - acc: 0.9623\n",
      "Epoch 81/200\n",
      " - 3s - loss: 0.2991 - acc: 0.9117\n",
      "Epoch 82/200\n",
      " - 3s - loss: 0.2018 - acc: 0.9544\n",
      "Epoch 83/200\n",
      " - 3s - loss: 0.1467 - acc: 0.9615\n",
      "Epoch 84/200\n",
      " - 3s - loss: 0.1041 - acc: 0.9744\n",
      "Epoch 85/200\n",
      " - 3s - loss: 0.0718 - acc: 0.9793\n",
      "Epoch 86/200\n",
      " - 3s - loss: 0.0796 - acc: 0.9779\n",
      "Epoch 87/200\n",
      " - 3s - loss: 0.1578 - acc: 0.9601\n",
      "Epoch 88/200\n",
      " - 3s - loss: 0.0459 - acc: 0.9879\n",
      "Epoch 89/200\n",
      " - 3s - loss: 0.2424 - acc: 0.9274\n",
      "Epoch 90/200\n",
      " - 3s - loss: 0.0701 - acc: 0.9829\n",
      "Epoch 91/200\n",
      " - 3s - loss: 0.1497 - acc: 0.9651\n",
      "Epoch 92/200\n",
      " - 3s - loss: 0.1249 - acc: 0.9701\n",
      "Epoch 93/200\n",
      " - 3s - loss: 0.1116 - acc: 0.9786\n",
      "Epoch 94/200\n",
      " - 3s - loss: 0.1669 - acc: 0.9537\n",
      "Epoch 95/200\n",
      " - 3s - loss: 0.0862 - acc: 0.9779\n",
      "Epoch 96/200\n",
      " - 3s - loss: 0.2780 - acc: 0.9302\n",
      "Epoch 97/200\n",
      " - 3s - loss: 0.1778 - acc: 0.9551\n",
      "Epoch 98/200\n",
      " - 3s - loss: 0.0936 - acc: 0.9779\n",
      "Epoch 99/200\n",
      " - 3s - loss: 0.1055 - acc: 0.9687\n",
      "Epoch 100/200\n",
      " - 3s - loss: 0.0705 - acc: 0.9808\n",
      "Epoch 101/200\n",
      " - 3s - loss: 0.1594 - acc: 0.9601\n",
      "Epoch 102/200\n",
      " - 3s - loss: 0.2442 - acc: 0.9295\n",
      "Epoch 103/200\n",
      " - 3s - loss: 0.1502 - acc: 0.9644\n",
      "Epoch 104/200\n",
      " - 3s - loss: 0.1463 - acc: 0.9558\n",
      "Epoch 105/200\n",
      " - 3s - loss: 0.1759 - acc: 0.9623\n",
      "Epoch 106/200\n",
      " - 3s - loss: 0.0542 - acc: 0.9858\n",
      "Epoch 107/200\n",
      " - 3s - loss: 0.1671 - acc: 0.9630\n",
      "Epoch 108/200\n",
      " - 3s - loss: 0.2154 - acc: 0.9274\n",
      "Epoch 109/200\n",
      " - 3s - loss: 0.2112 - acc: 0.9487\n",
      "Epoch 110/200\n",
      " - 3s - loss: 0.0689 - acc: 0.9865\n",
      "Epoch 111/200\n",
      " - 3s - loss: 0.0375 - acc: 0.9922\n",
      "Epoch 112/200\n",
      " - 3s - loss: 0.1027 - acc: 0.9765\n",
      "Epoch 113/200\n",
      " - 3s - loss: 0.0862 - acc: 0.9836\n",
      "Epoch 114/200\n",
      " - 3s - loss: 0.0460 - acc: 0.9872\n",
      "Epoch 115/200\n",
      " - 3s - loss: 0.1042 - acc: 0.9793\n",
      "Epoch 116/200\n",
      " - 3s - loss: 0.0248 - acc: 0.9922\n",
      "Epoch 117/200\n",
      " - 3s - loss: 0.0916 - acc: 0.9744\n",
      "Epoch 118/200\n",
      " - 3s - loss: 0.0713 - acc: 0.9872\n",
      "Epoch 119/200\n",
      " - 3s - loss: 0.0195 - acc: 0.9972\n",
      "Epoch 120/200\n",
      " - 3s - loss: 0.3007 - acc: 0.9779\n",
      "Epoch 121/200\n",
      " - 3s - loss: 0.0499 - acc: 0.9915\n",
      "Epoch 122/200\n",
      " - 3s - loss: 0.0303 - acc: 0.9900\n",
      "Epoch 123/200\n",
      " - 3s - loss: 0.0130 - acc: 0.9979\n",
      "Epoch 124/200\n",
      " - 3s - loss: 0.0765 - acc: 0.9858\n",
      "Epoch 125/200\n",
      " - 3s - loss: 0.1022 - acc: 0.9793\n",
      "Epoch 126/200\n",
      " - 3s - loss: 0.1399 - acc: 0.9793\n",
      "Epoch 127/200\n",
      " - 3s - loss: 0.0796 - acc: 0.9843\n",
      "Epoch 128/200\n",
      " - 3s - loss: 0.0116 - acc: 0.9979\n",
      "Epoch 129/200\n",
      " - 3s - loss: 0.0542 - acc: 0.9886\n",
      "Epoch 130/200\n",
      " - 3s - loss: 0.1421 - acc: 0.9665\n",
      "Epoch 131/200\n",
      " - 3s - loss: 0.0121 - acc: 0.9972\n",
      "Epoch 132/200\n",
      " - 3s - loss: 0.0060 - acc: 0.9993\n",
      "Epoch 133/200\n",
      " - 3s - loss: 0.0060 - acc: 0.9986\n",
      "Epoch 134/200\n",
      " - 3s - loss: 0.2242 - acc: 0.9701\n",
      "Epoch 135/200\n",
      " - 3s - loss: 0.0145 - acc: 0.9979\n",
      "Epoch 136/200\n",
      " - 3s - loss: 0.0150 - acc: 0.9986\n",
      "Epoch 137/200\n",
      " - 3s - loss: 0.0058 - acc: 0.9993\n",
      "Epoch 138/200\n",
      " - 3s - loss: 0.0037 - acc: 0.9993\n",
      "Epoch 139/200\n",
      " - 3s - loss: 0.0106 - acc: 0.9986\n",
      "Epoch 140/200\n",
      " - 3s - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 141/200\n",
      " - 3s - loss: 0.0315 - acc: 0.9900\n",
      "Epoch 142/200\n",
      " - 3s - loss: 0.0046 - acc: 0.9993\n",
      "Epoch 143/200\n",
      " - 3s - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 144/200\n",
      " - 3s - loss: 0.0020 - acc: 0.9993\n",
      "Epoch 145/200\n",
      " - 3s - loss: 0.1034 - acc: 0.9815\n",
      "Epoch 146/200\n",
      " - 3s - loss: 0.0108 - acc: 0.9986\n",
      "Epoch 147/200\n",
      " - 3s - loss: 0.0040 - acc: 0.9993\n",
      "Epoch 148/200\n",
      " - 3s - loss: 0.0045 - acc: 0.9993\n",
      "Epoch 149/200\n",
      " - 3s - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 150/200\n",
      " - 3s - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 151/200\n",
      " - 3s - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 152/200\n",
      " - 3s - loss: 0.0032 - acc: 0.9986\n",
      "Epoch 153/200\n",
      " - 3s - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 154/200\n",
      " - 3s - loss: 0.0029 - acc: 0.9986\n",
      "Epoch 155/200\n",
      " - 3s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 156/200\n",
      " - 3s - loss: 0.1341 - acc: 0.9765\n",
      "Epoch 157/200\n",
      " - 3s - loss: 0.0100 - acc: 0.9993\n",
      "Epoch 158/200\n",
      " - 3s - loss: 0.0044 - acc: 0.9993\n",
      "Epoch 159/200\n",
      " - 3s - loss: 0.1622 - acc: 0.9793\n",
      "Epoch 160/200\n",
      " - 3s - loss: 0.0083 - acc: 0.9993\n",
      "Epoch 161/200\n",
      " - 3s - loss: 0.0046 - acc: 0.9993\n",
      "Epoch 162/200\n",
      " - 3s - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 163/200\n",
      " - 3s - loss: 0.0042 - acc: 0.9986\n",
      "Epoch 164/200\n",
      " - 3s - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 165/200\n",
      " - 3s - loss: 0.0017 - acc: 0.9993\n",
      "Epoch 166/200\n",
      " - 3s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 167/200\n",
      " - 3s - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 168/200\n",
      " - 3s - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 169/200\n",
      " - 3s - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 170/200\n",
      " - 3s - loss: 0.1335 - acc: 0.9765\n",
      "Epoch 171/200\n",
      " - 3s - loss: 0.1660 - acc: 0.9573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/200\n",
      " - 3s - loss: 0.0399 - acc: 0.9922\n",
      "Epoch 173/200\n",
      " - 3s - loss: 0.0123 - acc: 0.9964\n",
      "Epoch 174/200\n",
      " - 3s - loss: 0.0091 - acc: 0.9979\n",
      "Epoch 175/200\n",
      " - 3s - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 176/200\n",
      " - 3s - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 177/200\n",
      " - 3s - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 178/200\n",
      " - 3s - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 179/200\n",
      " - 3s - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 180/200\n",
      " - 3s - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 181/200\n",
      " - 3s - loss: 0.0212 - acc: 0.9986\n",
      "Epoch 182/200\n",
      " - 3s - loss: 0.2228 - acc: 0.9523\n",
      "Epoch 183/200\n",
      " - 3s - loss: 0.0359 - acc: 0.9943\n",
      "Epoch 184/200\n",
      " - 3s - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 185/200\n",
      " - 3s - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 186/200\n",
      " - 3s - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 187/200\n",
      " - 3s - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 188/200\n",
      " - 3s - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 189/200\n",
      " - 3s - loss: 9.0753e-04 - acc: 1.0000\n",
      "Epoch 190/200\n",
      " - 3s - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 191/200\n",
      " - 3s - loss: 9.3026e-04 - acc: 1.0000\n",
      "Epoch 192/200\n",
      " - 3s - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 193/200\n",
      " - 3s - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 194/200\n",
      " - 3s - loss: 6.5220e-04 - acc: 1.0000\n",
      "Epoch 195/200\n",
      " - 3s - loss: 0.0015 - acc: 0.9993\n",
      "Epoch 196/200\n",
      " - 3s - loss: 4.9167e-04 - acc: 1.0000\n",
      "Epoch 197/200\n",
      " - 3s - loss: 6.0642e-04 - acc: 1.0000\n",
      "Epoch 198/200\n",
      " - 3s - loss: 0.0015 - acc: 0.9993\n",
      "Epoch 199/200\n",
      " - 3s - loss: 0.0013 - acc: 0.9993\n",
      "Epoch 200/200\n",
      " - 3s - loss: 7.0994e-04 - acc: 1.0000\n",
      "[[250   3   0   0   1   0]\n",
      " [  2 162   0   1   7   0]\n",
      " [  0   1 157   0   0   0]\n",
      " [  0   0   0  20   1   0]\n",
      " [  0   1   0   0  64   3]\n",
      " [  1   0   0   0   8  10]]\n",
      "\n",
      "\n",
      "<class 'keras.engine.sequential.Sequential'>\n",
      "||||| Accuracy : 0.9116562251885808 |||||\n",
      "\n",
      "\n",
      "Best actual accuracy : 0.9036523563965639\n",
      "\n",
      "\n",
      "\n",
      " BEST MODEL ! \n",
      "Saving... \n",
      "\n",
      "\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 64)                3496384   \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 1500)              97500     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 1500)              0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1500)              2251500   \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1500)              0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1500)              2251500   \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 1500)              0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 6)                 9006      \n",
      "=================================================================\n",
      "Total params: 8,105,890\n",
      "Trainable params: 8,105,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training...\n",
      "Epoch 1/200\n",
      " - 5s - loss: 1.7940 - acc: 0.1232\n",
      "Epoch 2/200\n",
      " - 4s - loss: 1.7070 - acc: 0.2315\n",
      "Epoch 3/200\n",
      " - 4s - loss: 1.4654 - acc: 0.4174\n",
      "Epoch 4/200\n",
      " - 4s - loss: 1.2014 - acc: 0.5883\n",
      "Epoch 5/200\n",
      " - 5s - loss: 0.9760 - acc: 0.6909\n",
      "Epoch 6/200\n",
      " - 5s - loss: 0.8909 - acc: 0.7336\n",
      "Epoch 7/200\n",
      " - 4s - loss: 0.8361 - acc: 0.7828\n",
      "Epoch 8/200\n",
      " - 5s - loss: 0.8105 - acc: 0.7707\n",
      "Epoch 9/200\n",
      " - 4s - loss: 0.7539 - acc: 0.8098\n",
      "Epoch 10/200\n",
      " - 4s - loss: 0.7723 - acc: 0.7963\n",
      "Epoch 11/200\n",
      " - 4s - loss: 0.7414 - acc: 0.8298\n",
      "Epoch 12/200\n",
      " - 4s - loss: 0.7102 - acc: 0.8369\n",
      "Epoch 13/200\n",
      " - 4s - loss: 0.6765 - acc: 0.8319\n",
      "Epoch 14/200\n",
      " - 4s - loss: 0.6625 - acc: 0.8369\n",
      "Epoch 15/200\n",
      " - 4s - loss: 0.6274 - acc: 0.8433\n",
      "Epoch 16/200\n",
      " - 5s - loss: 0.6672 - acc: 0.8390\n",
      "Epoch 17/200\n",
      " - 4s - loss: 0.5802 - acc: 0.8739\n",
      "Epoch 18/200\n",
      " - 4s - loss: 0.5145 - acc: 0.8654\n",
      "Epoch 19/200\n",
      " - 5s - loss: 0.5772 - acc: 0.8575\n",
      "Epoch 20/200\n",
      " - 5s - loss: 0.5700 - acc: 0.8697\n",
      "Epoch 21/200\n",
      " - 5s - loss: 0.4914 - acc: 0.8818\n",
      "Epoch 22/200\n",
      " - 4s - loss: 0.5230 - acc: 0.8825\n",
      "Epoch 23/200\n",
      " - 5s - loss: 0.4844 - acc: 0.8775\n",
      "Epoch 24/200\n",
      " - 4s - loss: 0.4520 - acc: 0.8960\n",
      "Epoch 25/200\n",
      " - 4s - loss: 0.4559 - acc: 0.8868\n",
      "Epoch 26/200\n",
      " - 5s - loss: 0.4473 - acc: 0.8953\n",
      "Epoch 27/200\n",
      " - 4s - loss: 0.4912 - acc: 0.8725\n",
      "Epoch 28/200\n",
      " - 5s - loss: 0.4319 - acc: 0.8946\n",
      "Epoch 29/200\n",
      " - 4s - loss: 0.3601 - acc: 0.9138\n",
      "Epoch 30/200\n",
      " - 4s - loss: 0.4581 - acc: 0.8875\n",
      "Epoch 31/200\n",
      " - 5s - loss: 0.3868 - acc: 0.8953\n",
      "Epoch 32/200\n",
      " - 4s - loss: 0.4064 - acc: 0.8981\n",
      "Epoch 33/200\n",
      " - 4s - loss: 0.3886 - acc: 0.9031\n",
      "Epoch 34/200\n",
      " - 4s - loss: 0.3637 - acc: 0.9160\n",
      "Epoch 35/200\n",
      " - 5s - loss: 0.3882 - acc: 0.8925\n",
      "Epoch 36/200\n",
      " - 4s - loss: 0.3694 - acc: 0.9053\n",
      "Epoch 37/200\n",
      " - 4s - loss: 0.3372 - acc: 0.9259\n",
      "Epoch 38/200\n",
      " - 4s - loss: 0.3447 - acc: 0.9095\n",
      "Epoch 39/200\n",
      " - 4s - loss: 0.3616 - acc: 0.9095\n",
      "Epoch 40/200\n",
      " - 4s - loss: 0.3987 - acc: 0.8946\n",
      "Epoch 41/200\n",
      " - 4s - loss: 0.4859 - acc: 0.8889\n",
      "Epoch 42/200\n",
      " - 4s - loss: 0.2905 - acc: 0.9302\n",
      "Epoch 43/200\n",
      " - 4s - loss: 0.2977 - acc: 0.9188\n",
      "Epoch 44/200\n",
      " - 4s - loss: 0.3006 - acc: 0.9252\n",
      "Epoch 45/200\n",
      " - 4s - loss: 0.2870 - acc: 0.9281\n",
      "Epoch 46/200\n",
      " - 4s - loss: 0.3146 - acc: 0.9167\n",
      "Epoch 47/200\n",
      " - 4s - loss: 0.2203 - acc: 0.9387\n",
      "Epoch 48/200\n",
      " - 4s - loss: 0.2446 - acc: 0.9316\n",
      "Epoch 49/200\n",
      " - 5s - loss: 0.2613 - acc: 0.9416\n",
      "Epoch 50/200\n",
      " - 4s - loss: 0.4697 - acc: 0.8533\n",
      "Epoch 51/200\n",
      " - 4s - loss: 0.3069 - acc: 0.9231\n",
      "Epoch 52/200\n",
      " - 5s - loss: 0.2351 - acc: 0.9338\n",
      "Epoch 53/200\n",
      " - 5s - loss: 0.3389 - acc: 0.9252\n",
      "Epoch 54/200\n",
      " - 5s - loss: 0.1937 - acc: 0.9530\n",
      "Epoch 55/200\n",
      " - 5s - loss: 0.2542 - acc: 0.9380\n",
      "Epoch 56/200\n",
      " - 5s - loss: 0.2115 - acc: 0.9459\n",
      "Epoch 57/200\n",
      " - 5s - loss: 0.2470 - acc: 0.9523\n",
      "Epoch 58/200\n",
      " - 4s - loss: 0.1789 - acc: 0.9601\n",
      "Epoch 59/200\n",
      " - 5s - loss: 0.2084 - acc: 0.9544\n",
      "Epoch 60/200\n",
      " - 4s - loss: 0.2632 - acc: 0.9281\n",
      "Epoch 61/200\n",
      " - 4s - loss: 0.2557 - acc: 0.9409\n",
      "Epoch 62/200\n",
      " - 5s - loss: 0.3874 - acc: 0.8811\n",
      "Epoch 63/200\n",
      " - 4s - loss: 0.2535 - acc: 0.9281\n",
      "Epoch 64/200\n",
      " - 4s - loss: 0.3125 - acc: 0.9487\n",
      "Epoch 65/200\n",
      " - 4s - loss: 0.1928 - acc: 0.9537\n",
      "Epoch 66/200\n",
      " - 4s - loss: 0.1807 - acc: 0.9551\n",
      "Epoch 67/200\n",
      " - 4s - loss: 0.1868 - acc: 0.9558\n",
      "Epoch 68/200\n",
      " - 4s - loss: 0.0897 - acc: 0.9801\n",
      "Epoch 69/200\n",
      " - 5s - loss: 0.1555 - acc: 0.9608\n",
      "Epoch 70/200\n",
      " - 4s - loss: 0.1755 - acc: 0.9587\n",
      "Epoch 71/200\n",
      " - 4s - loss: 0.2125 - acc: 0.9530\n",
      "Epoch 72/200\n",
      " - 4s - loss: 0.1729 - acc: 0.9551\n",
      "Epoch 73/200\n",
      " - 4s - loss: 0.1394 - acc: 0.9637\n",
      "Epoch 74/200\n",
      " - 4s - loss: 0.2889 - acc: 0.9423\n",
      "Epoch 75/200\n",
      " - 5s - loss: 0.1247 - acc: 0.9715\n",
      "Epoch 76/200\n",
      " - 4s - loss: 0.1152 - acc: 0.9744\n",
      "Epoch 77/200\n",
      " - 5s - loss: 0.2330 - acc: 0.9395\n",
      "Epoch 78/200\n",
      " - 4s - loss: 0.2644 - acc: 0.9530\n",
      "Epoch 79/200\n",
      " - 4s - loss: 0.1821 - acc: 0.9580\n",
      "Epoch 80/200\n",
      " - 4s - loss: 0.3073 - acc: 0.9373\n",
      "Epoch 81/200\n",
      " - 4s - loss: 0.3775 - acc: 0.8846\n",
      "Epoch 82/200\n",
      " - 4s - loss: 0.3601 - acc: 0.9053\n",
      "Epoch 83/200\n",
      " - 4s - loss: 0.1996 - acc: 0.9494\n",
      "Epoch 84/200\n",
      " - 4s - loss: 0.2216 - acc: 0.9380\n",
      "Epoch 85/200\n",
      " - 5s - loss: 0.1777 - acc: 0.9566\n",
      "Epoch 86/200\n",
      " - 4s - loss: 0.0932 - acc: 0.9850\n",
      "Epoch 87/200\n",
      " - 5s - loss: 0.1286 - acc: 0.9744\n",
      "Epoch 88/200\n",
      " - 5s - loss: 0.0833 - acc: 0.9779\n",
      "Epoch 89/200\n",
      " - 4s - loss: 0.1104 - acc: 0.9751\n",
      "Epoch 90/200\n",
      " - 4s - loss: 0.0805 - acc: 0.9801\n",
      "Epoch 91/200\n",
      " - 4s - loss: 0.1588 - acc: 0.9630\n",
      "Epoch 92/200\n",
      " - 5s - loss: 0.1464 - acc: 0.9615\n",
      "Epoch 93/200\n",
      " - 4s - loss: 0.0848 - acc: 0.9829\n",
      "Epoch 94/200\n",
      " - 4s - loss: 0.0430 - acc: 0.9900\n",
      "Epoch 95/200\n",
      " - 4s - loss: 0.0637 - acc: 0.9822\n",
      "Epoch 96/200\n",
      " - 5s - loss: 0.2931 - acc: 0.9387\n",
      "Epoch 97/200\n",
      " - 5s - loss: 0.0709 - acc: 0.9836\n",
      "Epoch 98/200\n",
      " - 5s - loss: 0.1017 - acc: 0.9772\n",
      "Epoch 99/200\n",
      " - 4s - loss: 0.0500 - acc: 0.9900\n",
      "Epoch 100/200\n",
      " - 4s - loss: 0.1209 - acc: 0.9758\n",
      "Epoch 101/200\n",
      " - 4s - loss: 0.2408 - acc: 0.9651\n",
      "Epoch 102/200\n",
      " - 4s - loss: 0.1135 - acc: 0.9779\n",
      "Epoch 103/200\n",
      " - 4s - loss: 0.1601 - acc: 0.9715\n",
      "Epoch 104/200\n",
      " - 4s - loss: 0.1005 - acc: 0.9758\n",
      "Epoch 105/200\n",
      " - 4s - loss: 0.0324 - acc: 0.9929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/200\n",
      " - 4s - loss: 0.2959 - acc: 0.9501\n",
      "Epoch 107/200\n",
      " - 4s - loss: 0.0584 - acc: 0.9829\n",
      "Epoch 108/200\n",
      " - 4s - loss: 0.2491 - acc: 0.9423\n",
      "Epoch 109/200\n",
      " - 4s - loss: 0.2059 - acc: 0.9509\n",
      "Epoch 110/200\n",
      " - 4s - loss: 0.1102 - acc: 0.9736\n",
      "Epoch 111/200\n",
      " - 4s - loss: 0.0835 - acc: 0.9779\n",
      "Epoch 112/200\n",
      " - 4s - loss: 0.0600 - acc: 0.9772\n",
      "Epoch 113/200\n",
      " - 4s - loss: 0.0866 - acc: 0.9793\n",
      "Epoch 114/200\n",
      " - 4s - loss: 0.0498 - acc: 0.9886\n",
      "Epoch 115/200\n",
      " - 4s - loss: 0.0278 - acc: 0.9900\n",
      "Epoch 116/200\n",
      " - 4s - loss: 0.4602 - acc: 0.9487\n",
      "Epoch 117/200\n",
      " - 4s - loss: 0.0646 - acc: 0.9822\n",
      "Epoch 118/200\n",
      " - 4s - loss: 0.0283 - acc: 0.9950\n",
      "Epoch 119/200\n",
      " - 4s - loss: 0.0188 - acc: 0.9950\n",
      "Epoch 120/200\n",
      " - 4s - loss: 0.0175 - acc: 0.9957\n",
      "Epoch 121/200\n",
      " - 4s - loss: 0.0757 - acc: 0.9822\n",
      "Epoch 122/200\n",
      " - 4s - loss: 0.0118 - acc: 0.9979\n",
      "Epoch 123/200\n",
      " - 4s - loss: 1.8083 - acc: 0.7322\n",
      "Epoch 124/200\n",
      " - 4s - loss: 0.0879 - acc: 0.9729\n",
      "Epoch 125/200\n",
      " - 4s - loss: 0.3033 - acc: 0.9615\n",
      "Epoch 126/200\n",
      " - 4s - loss: 0.5016 - acc: 0.8839\n",
      "Epoch 127/200\n",
      " - 4s - loss: 0.2994 - acc: 0.9330\n",
      "Epoch 128/200\n",
      " - 4s - loss: 0.2347 - acc: 0.9437\n",
      "Epoch 129/200\n",
      " - 4s - loss: 0.1815 - acc: 0.9651\n",
      "Epoch 130/200\n",
      " - 4s - loss: 0.0994 - acc: 0.9779\n",
      "Epoch 131/200\n",
      " - 4s - loss: 0.0524 - acc: 0.9900\n",
      "Epoch 132/200\n",
      " - 4s - loss: 0.0477 - acc: 0.9858\n",
      "Epoch 133/200\n",
      " - 4s - loss: 0.1494 - acc: 0.9815\n",
      "Epoch 134/200\n",
      " - 4s - loss: 0.0426 - acc: 0.9907\n",
      "Epoch 135/200\n",
      " - 4s - loss: 0.1979 - acc: 0.9459\n",
      "Epoch 136/200\n",
      " - 4s - loss: 0.1154 - acc: 0.9772\n",
      "Epoch 137/200\n",
      " - 4s - loss: 0.0190 - acc: 0.9950\n",
      "Epoch 138/200\n",
      " - 4s - loss: 0.0150 - acc: 0.9964\n",
      "Epoch 139/200\n",
      " - 4s - loss: 0.0778 - acc: 0.9822\n",
      "Epoch 140/200\n",
      " - 5s - loss: 0.0147 - acc: 0.9979\n",
      "Epoch 141/200\n",
      " - 4s - loss: 0.0120 - acc: 0.9972\n",
      "Epoch 142/200\n",
      " - 4s - loss: 0.0062 - acc: 1.0000\n",
      "Epoch 143/200\n",
      " - 4s - loss: 0.1724 - acc: 0.9751\n",
      "Epoch 144/200\n",
      " - 4s - loss: 0.0190 - acc: 0.9950\n",
      "Epoch 145/200\n",
      " - 4s - loss: 0.0413 - acc: 0.9915\n",
      "Epoch 146/200\n",
      " - 4s - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 147/200\n",
      " - 5s - loss: 0.0520 - acc: 0.9929\n",
      "Epoch 148/200\n",
      " - 4s - loss: 0.0145 - acc: 0.9950\n",
      "Epoch 149/200\n",
      " - 5s - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 150/200\n",
      " - 4s - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 151/200\n",
      " - 4s - loss: 0.0043 - acc: 0.9972\n",
      "Epoch 152/200\n",
      " - 4s - loss: 0.0051 - acc: 0.9986\n",
      "Epoch 153/200\n",
      " - 4s - loss: 0.0037 - acc: 0.9993\n",
      "Epoch 154/200\n",
      " - 4s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 155/200\n",
      " - 4s - loss: 0.0039 - acc: 0.9972\n",
      "Epoch 156/200\n",
      " - 4s - loss: 0.0630 - acc: 0.9900\n",
      "Epoch 157/200\n",
      " - 4s - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 158/200\n",
      " - 4s - loss: 0.0047 - acc: 0.9979\n",
      "Epoch 159/200\n",
      " - 4s - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 160/200\n",
      " - 4s - loss: 0.0867 - acc: 0.9815\n",
      "Epoch 161/200\n",
      " - 4s - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 162/200\n",
      " - 5s - loss: 0.0026 - acc: 0.9993\n",
      "Epoch 163/200\n",
      " - 4s - loss: 0.0046 - acc: 0.9979\n",
      "Epoch 164/200\n",
      " - 4s - loss: 0.0031 - acc: 0.9993\n",
      "Epoch 165/200\n",
      " - 5s - loss: 0.0026 - acc: 0.9986\n",
      "Epoch 166/200\n",
      " - 4s - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 167/200\n",
      " - 5s - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 168/200\n",
      " - 4s - loss: 9.3422e-04 - acc: 1.0000\n",
      "Epoch 169/200\n",
      " - 5s - loss: 9.5755e-04 - acc: 1.0000\n",
      "Epoch 170/200\n",
      " - 5s - loss: 6.1130e-04 - acc: 1.0000\n",
      "Epoch 171/200\n",
      " - 4s - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 172/200\n",
      " - 4s - loss: 0.0201 - acc: 0.9929\n",
      "Epoch 173/200\n",
      " - 4s - loss: 9.1535e-04 - acc: 1.0000\n",
      "Epoch 174/200\n",
      " - 4s - loss: 7.9717e-04 - acc: 1.0000\n",
      "Epoch 175/200\n",
      " - 5s - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 176/200\n",
      " - 4s - loss: 6.8206e-04 - acc: 1.0000\n",
      "Epoch 177/200\n",
      " - 4s - loss: 6.5631e-04 - acc: 1.0000\n",
      "Epoch 178/200\n",
      " - 4s - loss: 4.8827e-04 - acc: 1.0000\n",
      "Epoch 179/200\n",
      " - 4s - loss: 9.2432e-04 - acc: 1.0000\n",
      "Epoch 180/200\n",
      " - 5s - loss: 6.5422e-04 - acc: 1.0000\n",
      "Epoch 181/200\n",
      " - 4s - loss: 4.8310e-04 - acc: 1.0000\n",
      "Epoch 182/200\n",
      " - 4s - loss: 8.9050e-04 - acc: 1.0000\n",
      "Epoch 183/200\n",
      " - 4s - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 184/200\n",
      " - 4s - loss: 5.4822e-04 - acc: 1.0000\n",
      "Epoch 185/200\n",
      " - 4s - loss: 4.8510e-04 - acc: 1.0000\n",
      "Epoch 186/200\n",
      " - 4s - loss: 3.7416e-04 - acc: 1.0000\n",
      "Epoch 187/200\n",
      " - 4s - loss: 4.8579e-04 - acc: 1.0000\n",
      "Epoch 188/200\n",
      " - 4s - loss: 5.2034e-04 - acc: 1.0000\n",
      "Epoch 189/200\n",
      " - 4s - loss: 4.3236e-04 - acc: 1.0000\n",
      "Epoch 190/200\n",
      " - 4s - loss: 3.7710e-04 - acc: 1.0000\n",
      "Epoch 191/200\n",
      " - 4s - loss: 3.7391e-04 - acc: 1.0000\n",
      "Epoch 192/200\n",
      " - 4s - loss: 3.2020e-04 - acc: 1.0000\n",
      "Epoch 193/200\n",
      " - 4s - loss: 3.8304e-04 - acc: 1.0000\n",
      "Epoch 194/200\n",
      " - 4s - loss: 3.3206e-04 - acc: 1.0000\n",
      "Epoch 195/200\n",
      " - 4s - loss: 2.5997e-04 - acc: 1.0000\n",
      "Epoch 196/200\n",
      " - 5s - loss: 3.9353e-04 - acc: 1.0000\n",
      "Epoch 197/200\n",
      " - 5s - loss: 3.6533e-04 - acc: 1.0000\n",
      "Epoch 198/200\n",
      " - 5s - loss: 4.1262e-04 - acc: 1.0000\n",
      "Epoch 199/200\n",
      " - 5s - loss: 2.3222e-04 - acc: 1.0000\n",
      "Epoch 200/200\n",
      " - 4s - loss: 2.6573e-04 - acc: 1.0000\n",
      "[[250   3   0   0   1   0]\n",
      " [  2 162   0   1   7   0]\n",
      " [  0   1 157   0   0   0]\n",
      " [  0   0   0  20   1   0]\n",
      " [  0   2   0   0  63   3]\n",
      " [  0   0   0   0  11   8]]\n",
      "\n",
      "\n",
      "<class 'keras.engine.sequential.Sequential'>\n",
      "||||| Accuracy : 0.8991731717635333 |||||\n",
      "\n",
      "\n",
      "Best actual accuracy : 0.9116562251885808\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_42 (Dense)             (None, 64)                3496384   \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 2000)              130000    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 2000)              4002000   \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 2000)              4002000   \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 6)                 12006     \n",
      "=================================================================\n",
      "Total params: 11,642,390\n",
      "Trainable params: 11,642,390\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training...\n",
      "Epoch 1/200\n",
      " - 7s - loss: 1.7868 - acc: 0.1282\n",
      "Epoch 2/200\n",
      " - 7s - loss: 1.6967 - acc: 0.3034\n",
      "Epoch 3/200\n",
      " - 7s - loss: 1.4049 - acc: 0.4708\n",
      "Epoch 4/200\n",
      " - 7s - loss: 1.1394 - acc: 0.6054\n",
      "Epoch 5/200\n",
      " - 7s - loss: 1.0060 - acc: 0.6717\n",
      "Epoch 6/200\n",
      " - 7s - loss: 0.9120 - acc: 0.7222\n",
      "Epoch 7/200\n",
      " - 7s - loss: 0.8747 - acc: 0.7479\n",
      "Epoch 8/200\n",
      " - 7s - loss: 0.9387 - acc: 0.7486\n",
      "Epoch 9/200\n",
      " - 7s - loss: 0.8123 - acc: 0.7842\n",
      "Epoch 10/200\n",
      " - 7s - loss: 0.7208 - acc: 0.8184\n",
      "Epoch 11/200\n",
      " - 7s - loss: 0.6944 - acc: 0.8362\n",
      "Epoch 12/200\n",
      " - 7s - loss: 0.6794 - acc: 0.8340\n",
      "Epoch 13/200\n",
      " - 7s - loss: 0.8002 - acc: 0.8312\n",
      "Epoch 14/200\n",
      " - 7s - loss: 0.6902 - acc: 0.8369\n",
      "Epoch 15/200\n",
      " - 7s - loss: 0.6068 - acc: 0.8433\n",
      "Epoch 16/200\n",
      " - 7s - loss: 0.7228 - acc: 0.8262\n",
      "Epoch 17/200\n",
      " - 7s - loss: 0.5885 - acc: 0.8697\n",
      "Epoch 18/200\n",
      " - 7s - loss: 0.5528 - acc: 0.8526\n",
      "Epoch 19/200\n",
      " - 7s - loss: 0.5923 - acc: 0.8725\n",
      "Epoch 20/200\n",
      " - 7s - loss: 0.5129 - acc: 0.8775\n",
      "Epoch 21/200\n",
      " - 7s - loss: 0.5235 - acc: 0.8811\n",
      "Epoch 22/200\n",
      " - 7s - loss: 0.5471 - acc: 0.8618\n",
      "Epoch 23/200\n",
      " - 7s - loss: 0.4695 - acc: 0.8860\n",
      "Epoch 24/200\n",
      " - 7s - loss: 0.5111 - acc: 0.8725\n",
      "Epoch 25/200\n",
      " - 7s - loss: 0.4436 - acc: 0.8775\n",
      "Epoch 26/200\n",
      " - 7s - loss: 0.4231 - acc: 0.8917\n",
      "Epoch 27/200\n",
      " - 7s - loss: 0.4168 - acc: 0.8939\n",
      "Epoch 28/200\n",
      " - 7s - loss: 0.3863 - acc: 0.9038\n",
      "Epoch 29/200\n",
      " - 7s - loss: 0.4005 - acc: 0.8910\n",
      "Epoch 30/200\n",
      " - 7s - loss: 0.4285 - acc: 0.8946\n",
      "Epoch 31/200\n",
      " - 7s - loss: 0.4186 - acc: 0.8882\n",
      "Epoch 32/200\n",
      " - 7s - loss: 0.3576 - acc: 0.8953\n",
      "Epoch 33/200\n",
      " - 7s - loss: 0.4422 - acc: 0.8896\n",
      "Epoch 34/200\n",
      " - 7s - loss: 0.3372 - acc: 0.9202\n",
      "Epoch 35/200\n",
      " - 7s - loss: 0.3531 - acc: 0.9124\n",
      "Epoch 36/200\n",
      " - 7s - loss: 0.3128 - acc: 0.9174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/200\n",
      " - 7s - loss: 0.4685 - acc: 0.9024\n",
      "Epoch 38/200\n",
      " - 7s - loss: 0.2809 - acc: 0.9359\n",
      "Epoch 39/200\n",
      " - 7s - loss: 0.3668 - acc: 0.9181\n",
      "Epoch 40/200\n",
      " - 7s - loss: 0.2545 - acc: 0.9366\n",
      "Epoch 41/200\n",
      " - 7s - loss: 0.2364 - acc: 0.9281\n",
      "Epoch 42/200\n",
      " - 7s - loss: 0.2871 - acc: 0.9252\n",
      "Epoch 43/200\n",
      " - 7s - loss: 0.1892 - acc: 0.9537\n",
      "Epoch 44/200\n",
      " - 7s - loss: 0.3273 - acc: 0.9259\n",
      "Epoch 45/200\n",
      " - 7s - loss: 0.3828 - acc: 0.9088\n",
      "Epoch 46/200\n",
      " - 7s - loss: 0.3669 - acc: 0.9238\n",
      "Epoch 47/200\n",
      " - 7s - loss: 0.4542 - acc: 0.9188\n",
      "Epoch 48/200\n",
      " - 7s - loss: 0.6924 - acc: 0.7885\n",
      "Epoch 49/200\n",
      " - 7s - loss: 0.4489 - acc: 0.9017\n",
      "Epoch 50/200\n",
      " - 7s - loss: 0.2029 - acc: 0.9444\n",
      "Epoch 51/200\n",
      " - 7s - loss: 0.2455 - acc: 0.9380\n",
      "Epoch 52/200\n",
      " - 7s - loss: 0.2302 - acc: 0.9359\n",
      "Epoch 53/200\n",
      " - 7s - loss: 0.2246 - acc: 0.9409\n",
      "Epoch 54/200\n",
      " - 7s - loss: 0.1878 - acc: 0.9544\n",
      "Epoch 55/200\n",
      " - 7s - loss: 0.1936 - acc: 0.9566\n",
      "Epoch 56/200\n",
      " - 7s - loss: 0.3481 - acc: 0.9217\n",
      "Epoch 57/200\n",
      " - 7s - loss: 0.1627 - acc: 0.9658\n",
      "Epoch 58/200\n",
      " - 7s - loss: 0.2161 - acc: 0.9480\n",
      "Epoch 59/200\n",
      " - 7s - loss: 0.2525 - acc: 0.9473\n",
      "Epoch 60/200\n",
      " - 7s - loss: 0.2598 - acc: 0.9266\n",
      "Epoch 61/200\n",
      " - 7s - loss: 0.1472 - acc: 0.9644\n",
      "Epoch 62/200\n",
      " - 7s - loss: 0.2941 - acc: 0.9252\n",
      "Epoch 63/200\n",
      " - 7s - loss: 0.3122 - acc: 0.8846\n",
      "Epoch 64/200\n",
      " - 7s - loss: 0.2106 - acc: 0.9537\n",
      "Epoch 65/200\n",
      " - 7s - loss: 0.2855 - acc: 0.9295\n",
      "Epoch 66/200\n",
      " - 7s - loss: 0.1530 - acc: 0.9537\n",
      "Epoch 67/200\n",
      " - 7s - loss: 0.1368 - acc: 0.9644\n",
      "Epoch 68/200\n",
      " - 7s - loss: 0.1269 - acc: 0.9651\n",
      "Epoch 69/200\n",
      " - 7s - loss: 0.1533 - acc: 0.9623\n",
      "Epoch 70/200\n",
      " - 7s - loss: 0.2777 - acc: 0.9259\n",
      "Epoch 71/200\n",
      " - 7s - loss: 0.1207 - acc: 0.9658\n",
      "Epoch 72/200\n",
      " - 7s - loss: 0.2289 - acc: 0.9395\n",
      "Epoch 73/200\n",
      " - 7s - loss: 0.2996 - acc: 0.9152\n",
      "Epoch 74/200\n",
      " - 7s - loss: 0.1863 - acc: 0.9466\n",
      "Epoch 75/200\n",
      " - 7s - loss: 0.1383 - acc: 0.9658\n",
      "Epoch 76/200\n",
      " - 7s - loss: 0.0864 - acc: 0.9801\n",
      "Epoch 77/200\n",
      " - 7s - loss: 0.1327 - acc: 0.9679\n",
      "Epoch 78/200\n",
      " - 7s - loss: 0.2576 - acc: 0.9566\n",
      "Epoch 79/200\n",
      " - 7s - loss: 0.1104 - acc: 0.9765\n",
      "Epoch 80/200\n",
      " - 8s - loss: 0.1079 - acc: 0.9715\n",
      "Epoch 81/200\n",
      " - 7s - loss: 0.1575 - acc: 0.9658\n",
      "Epoch 82/200\n",
      " - 7s - loss: 0.1612 - acc: 0.9601\n",
      "Epoch 83/200\n",
      " - 7s - loss: 0.0719 - acc: 0.9858\n",
      "Epoch 84/200\n",
      " - 7s - loss: 0.1408 - acc: 0.9672\n",
      "Epoch 85/200\n",
      " - 7s - loss: 0.1295 - acc: 0.9687\n",
      "Epoch 86/200\n",
      " - 7s - loss: 0.3277 - acc: 0.9202\n",
      "Epoch 87/200\n",
      " - 7s - loss: 0.0733 - acc: 0.9850\n",
      "Epoch 88/200\n",
      " - 7s - loss: 0.2407 - acc: 0.9430\n",
      "Epoch 89/200\n",
      " - 7s - loss: 0.0419 - acc: 0.9915\n",
      "Epoch 90/200\n",
      " - 7s - loss: 0.2054 - acc: 0.9558\n",
      "Epoch 91/200\n",
      " - 7s - loss: 0.0969 - acc: 0.9836\n",
      "Epoch 92/200\n",
      " - 7s - loss: 0.0711 - acc: 0.9822\n",
      "Epoch 93/200\n",
      " - 7s - loss: 0.0802 - acc: 0.9801\n",
      "Epoch 94/200\n",
      " - 7s - loss: 0.1790 - acc: 0.9509\n",
      "Epoch 95/200\n",
      " - 7s - loss: 0.0755 - acc: 0.9808\n",
      "Epoch 96/200\n",
      " - 7s - loss: 0.1734 - acc: 0.9466\n",
      "Epoch 97/200\n",
      " - 7s - loss: 0.1392 - acc: 0.9672\n",
      "Epoch 98/200\n",
      " - 7s - loss: 0.1136 - acc: 0.9758\n",
      "Epoch 99/200\n",
      " - 7s - loss: 0.3481 - acc: 0.9387\n",
      "Epoch 100/200\n",
      " - 7s - loss: 0.1421 - acc: 0.9665\n",
      "Epoch 101/200\n",
      " - 7s - loss: 0.1784 - acc: 0.9651\n",
      "Epoch 102/200\n",
      " - 7s - loss: 0.0794 - acc: 0.9801\n",
      "Epoch 103/200\n",
      " - 7s - loss: 0.0691 - acc: 0.9822\n",
      "Epoch 104/200\n",
      " - 7s - loss: 0.1521 - acc: 0.9601\n",
      "Epoch 105/200\n",
      " - 7s - loss: 0.1418 - acc: 0.9630\n",
      "Epoch 106/200\n",
      " - 7s - loss: 0.0402 - acc: 0.9865\n",
      "Epoch 107/200\n",
      " - 7s - loss: 0.0167 - acc: 0.9943\n",
      "Epoch 108/200\n",
      " - 7s - loss: 0.1383 - acc: 0.9722\n",
      "Epoch 109/200\n",
      " - 7s - loss: 0.0879 - acc: 0.9829\n",
      "Epoch 110/200\n",
      " - 7s - loss: 0.0655 - acc: 0.9879\n",
      "Epoch 111/200\n",
      " - 7s - loss: 0.0487 - acc: 0.9879\n",
      "Epoch 112/200\n",
      " - 7s - loss: 0.0607 - acc: 0.9957\n",
      "Epoch 113/200\n",
      " - 7s - loss: 0.1507 - acc: 0.9665\n",
      "Epoch 114/200\n",
      " - 7s - loss: 0.1986 - acc: 0.9573\n",
      "Epoch 115/200\n",
      " - 7s - loss: 0.0261 - acc: 0.9957\n",
      "Epoch 116/200\n",
      " - 7s - loss: 0.0780 - acc: 0.9836\n",
      "Epoch 117/200\n",
      " - 7s - loss: 0.0474 - acc: 0.9893\n",
      "Epoch 118/200\n",
      " - 7s - loss: 0.0189 - acc: 0.9929\n",
      "Epoch 119/200\n",
      " - 7s - loss: 0.0101 - acc: 0.9964\n",
      "Epoch 120/200\n",
      " - 7s - loss: 0.3617 - acc: 0.9373\n",
      "Epoch 121/200\n",
      " - 7s - loss: 0.3700 - acc: 0.9074\n",
      "Epoch 122/200\n",
      " - 7s - loss: 0.2771 - acc: 0.9309\n",
      "Epoch 123/200\n",
      " - 7s - loss: 0.2066 - acc: 0.9423\n",
      "Epoch 124/200\n",
      " - 7s - loss: 0.1822 - acc: 0.9480\n",
      "Epoch 125/200\n",
      " - 7s - loss: 0.0561 - acc: 0.9872\n",
      "Epoch 126/200\n",
      " - 8s - loss: 0.0503 - acc: 0.9865\n",
      "Epoch 127/200\n",
      " - 7s - loss: 0.0478 - acc: 0.9907\n",
      "Epoch 128/200\n",
      " - 7s - loss: 0.0389 - acc: 0.9872\n",
      "Epoch 129/200\n",
      " - 8s - loss: 0.0222 - acc: 0.9922\n",
      "Epoch 130/200\n",
      " - 8s - loss: 0.0211 - acc: 0.9950\n",
      "Epoch 131/200\n",
      " - 8s - loss: 0.0144 - acc: 0.9972\n",
      "Epoch 132/200\n",
      " - 7s - loss: 0.0516 - acc: 0.9900\n",
      "Epoch 133/200\n",
      " - 7s - loss: 0.0183 - acc: 0.9986\n",
      "Epoch 134/200\n",
      " - 7s - loss: 0.0354 - acc: 0.9936\n",
      "Epoch 135/200\n",
      " - 7s - loss: 0.3491 - acc: 0.9224\n",
      "Epoch 136/200\n",
      " - 7s - loss: 0.2416 - acc: 0.9466\n",
      "Epoch 137/200\n",
      " - 7s - loss: 0.1035 - acc: 0.9793\n",
      "Epoch 138/200\n",
      " - 7s - loss: 0.0922 - acc: 0.9779\n",
      "Epoch 139/200\n",
      " - 8s - loss: 0.0085 - acc: 0.9993\n",
      "Epoch 140/200\n",
      " - 8s - loss: 0.0081 - acc: 0.9979\n",
      "Epoch 141/200\n",
      " - 8s - loss: 0.0100 - acc: 0.9979\n",
      "Epoch 142/200\n",
      " - 8s - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 143/200\n",
      " - 8s - loss: 0.0107 - acc: 0.9957\n",
      "Epoch 144/200\n",
      " - 8s - loss: 0.0037 - acc: 0.9993\n",
      "Epoch 145/200\n",
      " - 8s - loss: 0.0699 - acc: 0.9929\n",
      "Epoch 146/200\n",
      " - 8s - loss: 0.0084 - acc: 1.0000\n",
      "Epoch 147/200\n",
      " - 8s - loss: 0.0495 - acc: 0.9922\n",
      "Epoch 148/200\n",
      " - 8s - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 149/200\n",
      " - 8s - loss: 0.0030 - acc: 0.9993\n",
      "Epoch 150/200\n",
      " - 8s - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 151/200\n",
      " - 8s - loss: 0.0025 - acc: 0.9993\n",
      "Epoch 152/200\n",
      " - 8s - loss: 0.0039 - acc: 0.9986\n",
      "Epoch 153/200\n",
      " - 8s - loss: 0.0020 - acc: 0.9993\n",
      "Epoch 154/200\n",
      " - 8s - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 155/200\n",
      " - 8s - loss: 9.9119e-04 - acc: 1.0000\n",
      "Epoch 156/200\n",
      " - 8s - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 157/200\n",
      " - 8s - loss: 9.1602e-04 - acc: 1.0000\n",
      "Epoch 158/200\n",
      " - 8s - loss: 0.5517 - acc: 0.9437\n",
      "Epoch 159/200\n",
      " - 8s - loss: 0.0367 - acc: 0.9886\n",
      "Epoch 160/200\n",
      " - 8s - loss: 0.0068 - acc: 0.9993\n",
      "Epoch 161/200\n",
      " - 8s - loss: 0.0124 - acc: 0.9972\n",
      "Epoch 162/200\n",
      " - 8s - loss: 0.0049 - acc: 0.9986\n",
      "Epoch 163/200\n",
      " - 8s - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 164/200\n",
      " - 8s - loss: 0.0033 - acc: 0.9993\n",
      "Epoch 165/200\n",
      " - 8s - loss: 0.0047 - acc: 0.9979\n",
      "Epoch 166/200\n",
      " - 8s - loss: 0.0022 - acc: 0.9986\n",
      "Epoch 167/200\n",
      " - 8s - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 168/200\n",
      " - 8s - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 169/200\n",
      " - 8s - loss: 0.0016 - acc: 0.9993\n",
      "Epoch 170/200\n",
      " - 8s - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 171/200\n",
      " - 8s - loss: 7.3423e-04 - acc: 1.0000\n",
      "Epoch 172/200\n",
      " - 8s - loss: 0.0021 - acc: 0.9986\n",
      "Epoch 173/200\n",
      " - 8s - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 174/200\n",
      " - 8s - loss: 7.4198e-04 - acc: 1.0000\n",
      "Epoch 175/200\n",
      " - 8s - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 176/200\n",
      " - 8s - loss: 5.9035e-04 - acc: 1.0000\n",
      "Epoch 177/200\n",
      " - 8s - loss: 6.4441e-04 - acc: 1.0000\n",
      "Epoch 178/200\n",
      " - 8s - loss: 6.2648e-04 - acc: 1.0000\n",
      "Epoch 179/200\n",
      " - 8s - loss: 5.7274e-04 - acc: 1.0000\n",
      "Epoch 180/200\n",
      " - 8s - loss: 5.4708e-04 - acc: 1.0000\n",
      "Epoch 181/200\n",
      " - 8s - loss: 5.6643e-04 - acc: 1.0000\n",
      "Epoch 182/200\n",
      " - 7s - loss: 5.6649e-04 - acc: 1.0000\n",
      "Epoch 183/200\n",
      " - 7s - loss: 5.3695e-04 - acc: 1.0000\n",
      "Epoch 184/200\n",
      " - 7s - loss: 6.6767e-04 - acc: 1.0000\n",
      "Epoch 185/200\n",
      " - 7s - loss: 4.4220e-04 - acc: 1.0000\n",
      "Epoch 186/200\n",
      " - 8s - loss: 5.9131e-04 - acc: 1.0000\n",
      "Epoch 187/200\n",
      " - 8s - loss: 4.4758e-04 - acc: 1.0000\n",
      "Epoch 188/200\n",
      " - 8s - loss: 6.1712e-04 - acc: 1.0000\n",
      "Epoch 189/200\n",
      " - 8s - loss: 4.7575e-04 - acc: 1.0000\n",
      "Epoch 190/200\n",
      " - 8s - loss: 3.6404e-04 - acc: 1.0000\n",
      "Epoch 191/200\n",
      " - 8s - loss: 2.9915e-04 - acc: 1.0000\n",
      "Epoch 192/200\n",
      " - 7s - loss: 4.5687e-04 - acc: 1.0000\n",
      "Epoch 193/200\n",
      " - 7s - loss: 5.2012e-04 - acc: 1.0000\n",
      "Epoch 194/200\n",
      " - 7s - loss: 3.7863e-04 - acc: 1.0000\n",
      "Epoch 195/200\n",
      " - 8s - loss: 2.6165e-04 - acc: 1.0000\n",
      "Epoch 196/200\n",
      " - 8s - loss: 2.7919e-04 - acc: 1.0000\n",
      "Epoch 197/200\n",
      " - 8s - loss: 7.5609e-04 - acc: 1.0000\n",
      "Epoch 198/200\n",
      " - 8s - loss: 2.4003e-04 - acc: 1.0000\n",
      "Epoch 199/200\n",
      " - 7s - loss: 3.1306e-04 - acc: 1.0000\n",
      "Epoch 200/200\n",
      " - 7s - loss: 4.7192e-04 - acc: 1.0000\n",
      "[[250   3   0   0   1   0]\n",
      " [  3 165   0   1   3   0]\n",
      " [  0   1 157   0   0   0]\n",
      " [  0   1   0  20   0   0]\n",
      " [  0   1   0   0  63   4]\n",
      " [  1   0   0   0   9   9]]\n",
      "\n",
      "\n",
      "<class 'keras.engine.sequential.Sequential'>\n",
      "||||| Accuracy : 0.9038000437192314 |||||\n",
      "\n",
      "\n",
      "Best actual accuracy : 0.9116562251885808\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_47 (Dense)             (None, 64)                3496384   \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 50)                3250      \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 6)                 306       \n",
      "=================================================================\n",
      "Total params: 3,507,590\n",
      "Trainable params: 3,507,590\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      " - 2s - loss: 1.8351 - acc: 0.1617\n",
      "Epoch 2/200\n",
      " - 2s - loss: 1.7862 - acc: 0.1702\n",
      "Epoch 3/200\n",
      " - 2s - loss: 1.7809 - acc: 0.1830\n",
      "Epoch 4/200\n",
      " - 2s - loss: 1.7439 - acc: 0.1838\n",
      "Epoch 5/200\n",
      " - 2s - loss: 1.6664 - acc: 0.2343\n",
      "Epoch 6/200\n",
      " - 2s - loss: 1.6133 - acc: 0.3241\n",
      "Epoch 7/200\n",
      " - 2s - loss: 1.5703 - acc: 0.3440\n",
      "Epoch 8/200\n",
      " - 2s - loss: 1.5542 - acc: 0.3697\n",
      "Epoch 9/200\n",
      " - 2s - loss: 1.5218 - acc: 0.3796\n",
      "Epoch 10/200\n",
      " - 2s - loss: 1.5068 - acc: 0.3846\n",
      "Epoch 11/200\n",
      " - 2s - loss: 1.4736 - acc: 0.3825\n",
      "Epoch 12/200\n",
      " - 2s - loss: 1.4382 - acc: 0.3889\n",
      "Epoch 13/200\n",
      " - 2s - loss: 1.4562 - acc: 0.3974\n",
      "Epoch 14/200\n",
      " - 2s - loss: 1.4196 - acc: 0.4060\n",
      "Epoch 15/200\n",
      " - 2s - loss: 1.4090 - acc: 0.3868\n",
      "Epoch 16/200\n",
      " - 2s - loss: 1.3989 - acc: 0.4060\n",
      "Epoch 17/200\n",
      " - 2s - loss: 1.5371 - acc: 0.3590\n",
      "Epoch 18/200\n",
      " - 2s - loss: 1.4471 - acc: 0.3291\n",
      "Epoch 19/200\n",
      " - 2s - loss: 1.3463 - acc: 0.3768\n",
      "Epoch 20/200\n",
      " - 2s - loss: 1.3129 - acc: 0.3932\n",
      "Epoch 21/200\n",
      " - 2s - loss: 1.2688 - acc: 0.3689\n",
      "Epoch 22/200\n",
      " - 2s - loss: 1.2642 - acc: 0.3511\n",
      "Epoch 23/200\n",
      " - 2s - loss: 1.2651 - acc: 0.3811\n",
      "Epoch 24/200\n",
      " - 2s - loss: 1.3294 - acc: 0.3768\n",
      "Epoch 25/200\n",
      " - 2s - loss: 1.5887 - acc: 0.3647\n",
      "Epoch 26/200\n",
      " - 2s - loss: 1.2457 - acc: 0.3697\n",
      "Epoch 27/200\n",
      " - 2s - loss: 1.2346 - acc: 0.3953\n",
      "Epoch 28/200\n",
      " - 2s - loss: 1.2425 - acc: 0.4046\n",
      "Epoch 29/200\n",
      " - 2s - loss: 1.2406 - acc: 0.4345\n",
      "Epoch 30/200\n",
      " - 2s - loss: 1.2266 - acc: 0.4167\n",
      "Epoch 31/200\n",
      " - 2s - loss: 1.2136 - acc: 0.3939\n",
      "Epoch 32/200\n",
      " - 2s - loss: 1.2519 - acc: 0.3725\n",
      "Epoch 33/200\n",
      " - 2s - loss: 1.2521 - acc: 0.4038\n",
      "Epoch 34/200\n",
      " - 2s - loss: 1.2264 - acc: 0.4010\n",
      "Epoch 35/200\n",
      " - 2s - loss: 1.2143 - acc: 0.4224\n",
      "Epoch 36/200\n",
      " - 2s - loss: 1.2065 - acc: 0.4430\n",
      "Epoch 37/200\n",
      " - 2s - loss: 1.1942 - acc: 0.4366\n",
      "Epoch 38/200\n",
      " - 2s - loss: 1.1919 - acc: 0.4409\n",
      "Epoch 39/200\n",
      " - 2s - loss: 1.2331 - acc: 0.4416\n",
      "Epoch 40/200\n",
      " - 2s - loss: 1.1297 - acc: 0.4850\n",
      "Epoch 41/200\n",
      " - 2s - loss: 1.1389 - acc: 0.5306\n",
      "Epoch 42/200\n",
      " - 2s - loss: 1.1068 - acc: 0.5321\n",
      "Epoch 43/200\n",
      " - 2s - loss: 1.0993 - acc: 0.5199\n",
      "Epoch 44/200\n",
      " - 2s - loss: 1.0663 - acc: 0.5577\n",
      "Epoch 45/200\n",
      " - 2s - loss: 1.0618 - acc: 0.5627\n",
      "Epoch 46/200\n",
      " - 2s - loss: 1.0632 - acc: 0.5548\n",
      "Epoch 47/200\n",
      " - 2s - loss: 1.1074 - acc: 0.5128\n",
      "Epoch 48/200\n",
      " - 2s - loss: 1.1442 - acc: 0.4694\n",
      "Epoch 49/200\n",
      " - 2s - loss: 1.0947 - acc: 0.5442\n",
      "Epoch 50/200\n",
      " - 2s - loss: 1.1110 - acc: 0.5933\n",
      "Epoch 51/200\n",
      " - 2s - loss: 1.0696 - acc: 0.5912\n",
      "Epoch 52/200\n",
      " - 2s - loss: 1.0534 - acc: 0.5919\n",
      "Epoch 53/200\n",
      " - 2s - loss: 1.0274 - acc: 0.5962\n",
      "Epoch 54/200\n",
      " - 2s - loss: 1.0466 - acc: 0.5748\n",
      "Epoch 55/200\n",
      " - 2s - loss: 1.0367 - acc: 0.5734\n",
      "Epoch 56/200\n",
      " - 2s - loss: 1.0683 - acc: 0.5556\n",
      "Epoch 57/200\n",
      " - 2s - loss: 1.0750 - acc: 0.5805\n",
      "Epoch 58/200\n",
      " - 2s - loss: 1.0301 - acc: 0.6624\n",
      "Epoch 59/200\n",
      " - 2s - loss: 0.9901 - acc: 0.6467\n",
      "Epoch 60/200\n",
      " - 2s - loss: 1.0023 - acc: 0.6332\n",
      "Epoch 61/200\n",
      " - 2s - loss: 0.9935 - acc: 0.6474\n",
      "Epoch 62/200\n",
      " - 2s - loss: 0.9478 - acc: 0.6054\n",
      "Epoch 63/200\n",
      " - 2s - loss: 0.9297 - acc: 0.6446\n",
      "Epoch 64/200\n",
      " - 2s - loss: 0.9331 - acc: 0.6346\n",
      "Epoch 65/200\n",
      " - 2s - loss: 0.9181 - acc: 0.6474\n",
      "Epoch 66/200\n",
      " - 2s - loss: 0.9006 - acc: 0.7628\n",
      "Epoch 67/200\n",
      " - 2s - loss: 0.7939 - acc: 0.8084\n",
      "Epoch 68/200\n",
      " - 2s - loss: 0.7504 - acc: 0.8127\n",
      "Epoch 69/200\n",
      " - 2s - loss: 0.7875 - acc: 0.8105\n",
      "Epoch 70/200\n",
      " - 2s - loss: 0.8015 - acc: 0.8155\n",
      "Epoch 71/200\n",
      " - 2s - loss: 0.7715 - acc: 0.8305\n",
      "Epoch 72/200\n",
      " - 2s - loss: 0.8231 - acc: 0.7849\n",
      "Epoch 73/200\n",
      " - 2s - loss: 0.7778 - acc: 0.8141\n",
      "Epoch 74/200\n",
      " - 2s - loss: 0.7043 - acc: 0.8383\n",
      "Epoch 75/200\n",
      " - 2s - loss: 0.7682 - acc: 0.7856\n",
      "Epoch 76/200\n",
      " - 2s - loss: 0.7494 - acc: 0.7927\n",
      "Epoch 77/200\n",
      " - 2s - loss: 0.9171 - acc: 0.7863\n",
      "Epoch 78/200\n",
      " - 2s - loss: 0.7941 - acc: 0.8269\n",
      "Epoch 79/200\n",
      " - 2s - loss: 0.7693 - acc: 0.8454\n",
      "Epoch 80/200\n",
      " - 2s - loss: 0.7992 - acc: 0.7635\n",
      "Epoch 81/200\n",
      " - 2s - loss: 0.7758 - acc: 0.8241\n",
      "Epoch 82/200\n",
      " - 2s - loss: 1.0215 - acc: 0.6567\n",
      "Epoch 83/200\n",
      " - 2s - loss: 0.8868 - acc: 0.7528\n",
      "Epoch 84/200\n",
      " - 2s - loss: 0.8805 - acc: 0.7400\n",
      "Epoch 85/200\n",
      " - 2s - loss: 1.2742 - acc: 0.3839\n",
      "Epoch 86/200\n",
      " - 2s - loss: 1.2525 - acc: 0.3903\n",
      "Epoch 87/200\n",
      " - 2s - loss: 1.1800 - acc: 0.3796\n",
      "Epoch 88/200\n",
      " - 2s - loss: 1.1632 - acc: 0.3967\n",
      "Epoch 89/200\n",
      " - 2s - loss: 1.1418 - acc: 0.3917\n",
      "Epoch 90/200\n",
      " - 2s - loss: 1.1323 - acc: 0.4815\n",
      "Epoch 91/200\n",
      " - 2s - loss: 1.0040 - acc: 0.6332\n",
      "Epoch 92/200\n",
      " - 2s - loss: 1.0343 - acc: 0.6425\n",
      "Epoch 93/200\n",
      " - 2s - loss: 0.9365 - acc: 0.7272\n",
      "Epoch 94/200\n",
      " - 2s - loss: 0.8329 - acc: 0.8134\n",
      "Epoch 95/200\n",
      " - 2s - loss: 0.7950 - acc: 0.8312\n",
      "Epoch 96/200\n",
      " - 2s - loss: 0.7963 - acc: 0.8340\n",
      "Epoch 97/200\n",
      " - 2s - loss: 0.7747 - acc: 0.8519\n",
      "Epoch 98/200\n",
      " - 2s - loss: 0.7458 - acc: 0.8369\n",
      "Epoch 99/200\n",
      " - 2s - loss: 0.7290 - acc: 0.8547\n",
      "Epoch 100/200\n",
      " - 2s - loss: 0.7377 - acc: 0.8511\n",
      "Epoch 101/200\n",
      " - 2s - loss: 0.7340 - acc: 0.8533\n",
      "Epoch 102/200\n",
      " - 2s - loss: 0.7186 - acc: 0.8640\n",
      "Epoch 103/200\n",
      " - 2s - loss: 0.6932 - acc: 0.8547\n",
      "Epoch 104/200\n",
      " - 2s - loss: 0.7552 - acc: 0.8348\n",
      "Epoch 105/200\n",
      " - 2s - loss: 0.7070 - acc: 0.8618\n",
      "Epoch 106/200\n",
      " - 2s - loss: 0.6663 - acc: 0.8768\n",
      "Epoch 107/200\n",
      " - 2s - loss: 0.6508 - acc: 0.8932\n",
      "Epoch 108/200\n",
      " - 2s - loss: 0.6623 - acc: 0.8704\n",
      "Epoch 109/200\n",
      " - 2s - loss: 0.6825 - acc: 0.8640\n",
      "Epoch 110/200\n",
      " - 2s - loss: 0.6615 - acc: 0.8746\n",
      "Epoch 111/200\n",
      " - 2s - loss: 0.6289 - acc: 0.8846\n",
      "Epoch 112/200\n",
      " - 2s - loss: 0.6327 - acc: 0.8818\n",
      "Epoch 113/200\n",
      " - 2s - loss: 0.8711 - acc: 0.8276\n",
      "Epoch 114/200\n",
      " - 2s - loss: 0.6913 - acc: 0.8590\n",
      "Epoch 115/200\n",
      " - 2s - loss: 0.7513 - acc: 0.7942\n",
      "Epoch 116/200\n",
      " - 2s - loss: 0.6911 - acc: 0.8661\n",
      "Epoch 117/200\n",
      " - 2s - loss: 0.9922 - acc: 0.7044\n",
      "Epoch 118/200\n",
      " - 2s - loss: 0.7134 - acc: 0.8632\n",
      "Epoch 119/200\n",
      " - 2s - loss: 0.6983 - acc: 0.8803\n",
      "Epoch 120/200\n",
      " - 2s - loss: 0.7240 - acc: 0.7991\n",
      "Epoch 121/200\n",
      " - 2s - loss: 0.6595 - acc: 0.8725\n",
      "Epoch 122/200\n",
      " - 2s - loss: 0.6391 - acc: 0.8953\n",
      "Epoch 123/200\n",
      " - 2s - loss: 0.6547 - acc: 0.8796\n",
      "Epoch 124/200\n",
      " - 2s - loss: 0.6264 - acc: 0.8860\n",
      "Epoch 125/200\n",
      " - 2s - loss: 0.6522 - acc: 0.8725\n",
      "Epoch 126/200\n",
      " - 2s - loss: 0.6501 - acc: 0.8846\n",
      "Epoch 127/200\n",
      " - 2s - loss: nan - acc: 0.3932\n",
      "Epoch 128/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 129/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 130/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 131/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 132/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 133/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 134/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 135/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 136/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 137/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 138/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 139/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 140/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 141/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 142/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 143/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 144/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 145/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 146/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 147/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 148/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 149/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 150/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 151/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 152/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 153/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 154/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 155/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 156/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 157/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 158/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 159/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 160/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 161/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 162/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 163/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 164/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 165/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 166/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 167/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 168/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 169/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 170/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 171/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 172/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 174/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 175/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 176/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 177/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 178/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 179/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 180/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 181/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 182/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 183/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 184/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 185/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 186/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 187/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 188/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 189/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 190/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 191/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 192/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 193/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 194/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 195/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 196/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 197/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 198/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 199/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "Epoch 200/200\n",
      " - 2s - loss: nan - acc: 0.3533\n",
      "[[254   0   0   0   0   0]\n",
      " [172   0   0   0   0   0]\n",
      " [158   0   0   0   0   0]\n",
      " [ 21   0   0   0   0   0]\n",
      " [ 68   0   0   0   0   0]\n",
      " [ 19   0   0   0   0   0]]\n",
      "\n",
      "\n",
      "<class 'keras.engine.sequential.Sequential'>\n",
      "||||| Accuracy : 0.06117533718689788 |||||\n",
      "\n",
      "\n",
      "Best actual accuracy : 0.9116562251885808\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_53 (Dense)             (None, 64)                3496384   \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 100)               6500      \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 3,533,790\n",
      "Trainable params: 3,533,790\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training...\n",
      "Epoch 1/200\n",
      " - 3s - loss: 1.8106 - acc: 0.1610\n",
      "Epoch 2/200\n",
      " - 2s - loss: 1.8176 - acc: 0.1396\n",
      "Epoch 3/200\n",
      " - 2s - loss: 1.7616 - acc: 0.2272\n",
      "Epoch 4/200\n",
      " - 2s - loss: 1.6969 - acc: 0.2301\n",
      "Epoch 5/200\n",
      " - 2s - loss: 1.5997 - acc: 0.3127\n",
      "Epoch 6/200\n",
      " - 2s - loss: 1.4031 - acc: 0.4160\n",
      "Epoch 7/200\n",
      " - 2s - loss: 1.3209 - acc: 0.4879\n",
      "Epoch 8/200\n",
      " - 2s - loss: 1.2098 - acc: 0.5427\n",
      "Epoch 9/200\n",
      " - 2s - loss: 1.1234 - acc: 0.5926\n",
      "Epoch 10/200\n",
      " - 2s - loss: 1.2465 - acc: 0.5577\n",
      "Epoch 11/200\n",
      " - 2s - loss: 1.0316 - acc: 0.6182\n",
      "Epoch 12/200\n",
      " - 2s - loss: 1.0410 - acc: 0.6303\n",
      "Epoch 13/200\n",
      " - 2s - loss: 1.0039 - acc: 0.6360\n",
      "Epoch 14/200\n",
      " - 2s - loss: 0.9525 - acc: 0.6952\n",
      "Epoch 15/200\n",
      " - 2s - loss: 0.9617 - acc: 0.6581\n",
      "Epoch 16/200\n",
      " - 2s - loss: 0.8999 - acc: 0.7244\n",
      "Epoch 17/200\n",
      " - 2s - loss: 0.9009 - acc: 0.7066\n",
      "Epoch 18/200\n",
      " - 2s - loss: 0.8667 - acc: 0.7557\n",
      "Epoch 19/200\n",
      " - 2s - loss: 0.9898 - acc: 0.6916\n",
      "Epoch 20/200\n",
      " - 2s - loss: 0.8459 - acc: 0.7543\n",
      "Epoch 21/200\n",
      " - 2s - loss: 0.8494 - acc: 0.7528\n",
      "Epoch 22/200\n",
      " - 2s - loss: 0.8610 - acc: 0.7407\n",
      "Epoch 23/200\n",
      " - 2s - loss: 0.7898 - acc: 0.7785\n",
      "Epoch 24/200\n",
      " - 2s - loss: 0.8012 - acc: 0.7721\n",
      "Epoch 25/200\n",
      " - 2s - loss: 0.7404 - acc: 0.8098\n",
      "Epoch 26/200\n",
      " - 2s - loss: 0.7306 - acc: 0.8084\n",
      "Epoch 27/200\n",
      " - 2s - loss: 0.7642 - acc: 0.7970\n",
      "Epoch 28/200\n",
      " - 2s - loss: 0.8211 - acc: 0.7799\n",
      "Epoch 29/200\n",
      " - 2s - loss: 0.8411 - acc: 0.7934\n",
      "Epoch 30/200\n",
      " - 2s - loss: 0.8041 - acc: 0.7607\n",
      "Epoch 31/200\n",
      " - 2s - loss: 0.7306 - acc: 0.8170\n",
      "Epoch 32/200\n",
      " - 2s - loss: 0.7662 - acc: 0.8113\n",
      "Epoch 33/200\n",
      " - 2s - loss: 0.7648 - acc: 0.8105\n",
      "Epoch 34/200\n",
      " - 2s - loss: 0.7089 - acc: 0.8241\n",
      "Epoch 35/200\n",
      " - 2s - loss: 0.6892 - acc: 0.8298\n",
      "Epoch 36/200\n",
      " - 2s - loss: 0.8202 - acc: 0.7657\n",
      "Epoch 37/200\n",
      " - 2s - loss: 0.7032 - acc: 0.8170\n",
      "Epoch 38/200\n",
      " - 2s - loss: 0.6475 - acc: 0.8454\n",
      "Epoch 39/200\n",
      " - 2s - loss: 0.6725 - acc: 0.8312\n",
      "Epoch 40/200\n",
      " - 2s - loss: 0.6653 - acc: 0.8462\n",
      "Epoch 41/200\n",
      " - 2s - loss: 0.6794 - acc: 0.8276\n",
      "Epoch 42/200\n",
      " - 2s - loss: 0.6838 - acc: 0.8397\n",
      "Epoch 43/200\n",
      " - 2s - loss: 0.6728 - acc: 0.8412\n",
      "Epoch 44/200\n",
      " - 2s - loss: 0.7126 - acc: 0.8255\n",
      "Epoch 45/200\n",
      " - 2s - loss: 0.7117 - acc: 0.8191\n",
      "Epoch 46/200\n",
      " - 2s - loss: 0.6669 - acc: 0.8369\n",
      "Epoch 47/200\n",
      " - 2s - loss: 0.6585 - acc: 0.8298\n",
      "Epoch 48/200\n",
      " - 2s - loss: 0.6753 - acc: 0.8269\n",
      "Epoch 49/200\n",
      " - 2s - loss: 0.6293 - acc: 0.8575\n",
      "Epoch 50/200\n",
      " - 2s - loss: 0.6731 - acc: 0.8369\n",
      "Epoch 51/200\n",
      " - 2s - loss: 0.6458 - acc: 0.8540\n",
      "Epoch 52/200\n",
      " - 2s - loss: 0.6314 - acc: 0.8426\n",
      "Epoch 53/200\n",
      " - 2s - loss: 0.6116 - acc: 0.8611\n",
      "Epoch 54/200\n",
      " - 2s - loss: 0.6171 - acc: 0.8590\n",
      "Epoch 55/200\n",
      " - 2s - loss: 0.6446 - acc: 0.8519\n",
      "Epoch 56/200\n",
      " - 2s - loss: 0.5732 - acc: 0.8689\n",
      "Epoch 57/200\n",
      " - 2s - loss: 0.7014 - acc: 0.8312\n",
      "Epoch 58/200\n",
      " - 2s - loss: 0.6009 - acc: 0.8654\n",
      "Epoch 59/200\n",
      " - 2s - loss: 0.6124 - acc: 0.8597\n",
      "Epoch 60/200\n",
      " - 2s - loss: 0.5304 - acc: 0.8818\n",
      "Epoch 61/200\n",
      " - 2s - loss: 0.8194 - acc: 0.8056\n",
      "Epoch 62/200\n",
      " - 2s - loss: 0.5607 - acc: 0.8718\n",
      "Epoch 63/200\n",
      " - 2s - loss: 0.5854 - acc: 0.8775\n",
      "Epoch 64/200\n",
      " - 2s - loss: 0.6622 - acc: 0.8590\n",
      "Epoch 65/200\n",
      " - 2s - loss: 0.6180 - acc: 0.8668\n",
      "Epoch 66/200\n",
      " - 2s - loss: 0.5851 - acc: 0.8647\n",
      "Epoch 67/200\n",
      " - 2s - loss: 0.5489 - acc: 0.8853\n",
      "Epoch 68/200\n",
      " - 2s - loss: 0.5214 - acc: 0.8818\n",
      "Epoch 69/200\n",
      " - 2s - loss: 0.5538 - acc: 0.8682\n",
      "Epoch 70/200\n",
      " - 2s - loss: 0.4927 - acc: 0.8967\n",
      "Epoch 71/200\n",
      " - 2s - loss: 0.5390 - acc: 0.8803\n",
      "Epoch 72/200\n",
      " - 2s - loss: 0.5688 - acc: 0.8818\n",
      "Epoch 73/200\n",
      " - 2s - loss: 0.6049 - acc: 0.8654\n",
      "Epoch 74/200\n",
      " - 2s - loss: 0.5239 - acc: 0.8925\n",
      "Epoch 75/200\n",
      " - 2s - loss: 0.5344 - acc: 0.8846\n",
      "Epoch 76/200\n",
      " - 2s - loss: 0.4807 - acc: 0.8882\n",
      "Epoch 77/200\n",
      " - 2s - loss: 0.5828 - acc: 0.8618\n",
      "Epoch 78/200\n",
      " - 2s - loss: 0.4481 - acc: 0.9017\n",
      "Epoch 79/200\n",
      " - 2s - loss: 0.4740 - acc: 0.8939\n",
      "Epoch 80/200\n",
      " - 2s - loss: 0.5320 - acc: 0.8754\n",
      "Epoch 81/200\n",
      " - 2s - loss: 0.4973 - acc: 0.8853\n",
      "Epoch 82/200\n",
      " - 2s - loss: 0.4913 - acc: 0.8917\n",
      "Epoch 83/200\n",
      " - 2s - loss: 0.4622 - acc: 0.8932\n",
      "Epoch 84/200\n",
      " - 2s - loss: 0.4303 - acc: 0.8974\n",
      "Epoch 85/200\n",
      " - 2s - loss: 0.4569 - acc: 0.8925\n",
      "Epoch 86/200\n",
      " - 2s - loss: 0.4693 - acc: 0.8853\n",
      "Epoch 87/200\n",
      " - 2s - loss: 0.4300 - acc: 0.8925\n",
      "Epoch 88/200\n",
      " - 2s - loss: 0.6699 - acc: 0.8084\n",
      "Epoch 89/200\n",
      " - 2s - loss: 0.5257 - acc: 0.8725\n",
      "Epoch 90/200\n",
      " - 2s - loss: 0.4427 - acc: 0.8960\n",
      "Epoch 91/200\n",
      " - 2s - loss: 0.4698 - acc: 0.8832\n",
      "Epoch 92/200\n",
      " - 2s - loss: 0.4361 - acc: 0.8989\n",
      "Epoch 93/200\n",
      " - 2s - loss: 0.4179 - acc: 0.8960\n",
      "Epoch 94/200\n",
      " - 2s - loss: 0.3832 - acc: 0.9024\n",
      "Epoch 95/200\n",
      " - 2s - loss: 0.4522 - acc: 0.8768\n",
      "Epoch 96/200\n",
      " - 2s - loss: 0.4187 - acc: 0.8910\n",
      "Epoch 97/200\n",
      " - 2s - loss: 0.5912 - acc: 0.8654\n",
      "Epoch 98/200\n",
      " - 2s - loss: 0.4223 - acc: 0.8917\n",
      "Epoch 99/200\n",
      " - 2s - loss: 0.3750 - acc: 0.9152\n",
      "Epoch 100/200\n",
      " - 2s - loss: 0.4650 - acc: 0.9031\n",
      "Epoch 101/200\n",
      " - 2s - loss: 0.4597 - acc: 0.8903\n",
      "Epoch 102/200\n",
      " - 2s - loss: 0.3996 - acc: 0.9038\n",
      "Epoch 103/200\n",
      " - 2s - loss: 0.5462 - acc: 0.8689\n",
      "Epoch 104/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 2s - loss: 0.4799 - acc: 0.8996\n",
      "Epoch 105/200\n",
      " - 2s - loss: 0.4653 - acc: 0.8868\n",
      "Epoch 106/200\n",
      " - 2s - loss: 0.4405 - acc: 0.8946\n",
      "Epoch 107/200\n",
      " - 2s - loss: 0.4335 - acc: 0.8946\n",
      "Epoch 108/200\n",
      " - 2s - loss: 0.3777 - acc: 0.9117\n",
      "Epoch 109/200\n",
      " - 2s - loss: 0.5240 - acc: 0.8825\n",
      "Epoch 110/200\n",
      " - 2s - loss: 0.4205 - acc: 0.9046\n",
      "Epoch 111/200\n",
      " - 2s - loss: 0.3465 - acc: 0.9152\n",
      "Epoch 112/200\n",
      " - 2s - loss: 4.4463 - acc: 0.4765\n",
      "Epoch 113/200\n",
      " - 2s - loss: 6.2925 - acc: 0.1994\n",
      "Epoch 114/200\n",
      " - 2s - loss: 6.2993 - acc: 0.2009\n",
      "Epoch 115/200\n",
      " - 2s - loss: 6.3094 - acc: 0.1959\n",
      "Epoch 116/200\n",
      " - 2s - loss: 6.2980 - acc: 0.2037\n",
      "Epoch 117/200\n",
      " - 2s - loss: 6.2926 - acc: 0.2051\n",
      "Epoch 118/200\n",
      " - 2s - loss: 4.4479 - acc: 0.2379\n",
      "Epoch 119/200\n",
      " - 2s - loss: 1.3200 - acc: 0.4359\n",
      "Epoch 120/200\n",
      " - 2s - loss: 1.0193 - acc: 0.6282\n",
      "Epoch 121/200\n",
      " - 2s - loss: 0.6748 - acc: 0.8369\n",
      "Epoch 122/200\n",
      " - 2s - loss: 0.5169 - acc: 0.9202\n",
      "Epoch 123/200\n",
      " - 2s - loss: 0.4663 - acc: 0.9138\n",
      "Epoch 124/200\n",
      " - 2s - loss: 0.4920 - acc: 0.9095\n",
      "Epoch 125/200\n",
      " - 2s - loss: 0.4670 - acc: 0.9074\n",
      "Epoch 126/200\n",
      " - 2s - loss: 0.5058 - acc: 0.8960\n",
      "Epoch 127/200\n",
      " - 2s - loss: 0.4807 - acc: 0.9202\n",
      "Epoch 128/200\n",
      " - 2s - loss: 0.4715 - acc: 0.9074\n",
      "Epoch 129/200\n",
      " - 2s - loss: 0.4508 - acc: 0.9124\n",
      "Epoch 130/200\n",
      " - 2s - loss: 0.4191 - acc: 0.9145\n",
      "Epoch 131/200\n",
      " - 2s - loss: 0.4473 - acc: 0.9167\n",
      "Epoch 132/200\n",
      " - 2s - loss: 0.4302 - acc: 0.9224\n",
      "Epoch 133/200\n",
      " - 2s - loss: 0.4205 - acc: 0.9224\n",
      "Epoch 134/200\n",
      " - 2s - loss: 0.5395 - acc: 0.8853\n",
      "Epoch 135/200\n",
      " - 2s - loss: 0.4836 - acc: 0.8932\n",
      "Epoch 136/200\n",
      " - 2s - loss: 0.4733 - acc: 0.8925\n",
      "Epoch 137/200\n",
      " - 2s - loss: 0.4476 - acc: 0.8896\n",
      "Epoch 138/200\n",
      " - 2s - loss: 0.3344 - acc: 0.9152\n",
      "Epoch 139/200\n",
      " - 2s - loss: 0.3666 - acc: 0.9053\n",
      "Epoch 140/200\n",
      " - 2s - loss: 0.3901 - acc: 0.9167\n",
      "Epoch 141/200\n",
      " - 2s - loss: 0.4033 - acc: 0.9038\n",
      "Epoch 142/200\n",
      " - 2s - loss: 0.3087 - acc: 0.9231\n",
      "Epoch 143/200\n",
      " - 2s - loss: 0.8498 - acc: 0.7877\n",
      "Epoch 144/200\n",
      " - 2s - loss: 0.5190 - acc: 0.9138\n",
      "Epoch 145/200\n",
      " - 2s - loss: 0.5309 - acc: 0.9031\n",
      "Epoch 146/200\n",
      " - 2s - loss: 0.4120 - acc: 0.9366\n",
      "Epoch 147/200\n",
      " - 2s - loss: 0.3971 - acc: 0.9252\n",
      "Epoch 148/200\n",
      " - 2s - loss: 0.4826 - acc: 0.8989\n",
      "Epoch 149/200\n",
      " - 2s - loss: 0.3680 - acc: 0.9188\n",
      "Epoch 150/200\n",
      " - 2s - loss: 0.3736 - acc: 0.9046\n",
      "Epoch 151/200\n",
      " - 2s - loss: 0.3954 - acc: 0.9174\n",
      "Epoch 152/200\n",
      " - 2s - loss: 0.2785 - acc: 0.9281\n",
      "Epoch 153/200\n",
      " - 2s - loss: 0.3811 - acc: 0.9003\n",
      "Epoch 154/200\n",
      " - 2s - loss: 0.3299 - acc: 0.9238\n",
      "Epoch 155/200\n",
      " - 2s - loss: 0.3125 - acc: 0.9281\n",
      "Epoch 156/200\n",
      " - 2s - loss: 0.3958 - acc: 0.9074\n",
      "Epoch 157/200\n",
      " - 2s - loss: 0.4177 - acc: 0.8960\n",
      "Epoch 158/200\n",
      " - 2s - loss: 0.2926 - acc: 0.9373\n",
      "Epoch 159/200\n",
      " - 2s - loss: 0.2499 - acc: 0.9352\n",
      "Epoch 160/200\n",
      " - 2s - loss: 0.3117 - acc: 0.9209\n",
      "Epoch 161/200\n",
      " - 2s - loss: 0.2989 - acc: 0.9316\n",
      "Epoch 162/200\n",
      " - 2s - loss: 0.5859 - acc: 0.8967\n",
      "Epoch 163/200\n",
      " - 2s - loss: 0.2976 - acc: 0.9494\n",
      "Epoch 164/200\n",
      " - 2s - loss: 0.3715 - acc: 0.9231\n",
      "Epoch 165/200\n",
      " - 2s - loss: 0.3487 - acc: 0.9195\n",
      "Epoch 166/200\n",
      " - 2s - loss: 0.3300 - acc: 0.9167\n",
      "Epoch 167/200\n",
      " - 2s - loss: 0.6711 - acc: 0.8590\n",
      "Epoch 168/200\n",
      " - 2s - loss: 0.3782 - acc: 0.9031\n",
      "Epoch 169/200\n",
      " - 2s - loss: 0.3289 - acc: 0.9124\n",
      "Epoch 170/200\n",
      " - 2s - loss: 0.3747 - acc: 0.9281\n",
      "Epoch 171/200\n",
      " - 2s - loss: 0.2879 - acc: 0.9231\n",
      "Epoch 172/200\n",
      " - 2s - loss: 0.3251 - acc: 0.9281\n",
      "Epoch 173/200\n",
      " - 2s - loss: 0.3664 - acc: 0.9288\n",
      "Epoch 174/200\n",
      " - 2s - loss: 0.2966 - acc: 0.9238\n",
      "Epoch 175/200\n",
      " - 2s - loss: 0.2350 - acc: 0.9473\n",
      "Epoch 176/200\n",
      " - 2s - loss: 0.3222 - acc: 0.9274\n",
      "Epoch 177/200\n",
      " - 2s - loss: 0.2078 - acc: 0.9523\n",
      "Epoch 178/200\n",
      " - 2s - loss: 0.2779 - acc: 0.9316\n",
      "Epoch 179/200\n",
      " - 2s - loss: 0.7482 - acc: 0.8454\n",
      "Epoch 180/200\n",
      " - 2s - loss: 0.3146 - acc: 0.9323\n",
      "Epoch 181/200\n",
      " - 2s - loss: 0.2879 - acc: 0.9352\n",
      "Epoch 182/200\n",
      " - 2s - loss: 0.2683 - acc: 0.9338\n",
      "Epoch 183/200\n",
      " - 2s - loss: 0.4104 - acc: 0.9003\n",
      "Epoch 184/200\n",
      " - 2s - loss: 0.2058 - acc: 0.9501\n",
      "Epoch 185/200\n",
      " - 2s - loss: 0.2904 - acc: 0.9345\n",
      "Epoch 186/200\n",
      " - 2s - loss: 0.2676 - acc: 0.9395\n",
      "Epoch 187/200\n",
      " - 2s - loss: 0.2721 - acc: 0.9330\n",
      "Epoch 188/200\n",
      " - 2s - loss: 0.4809 - acc: 0.8725\n",
      "Epoch 189/200\n",
      " - 2s - loss: 0.3388 - acc: 0.9103\n",
      "Epoch 190/200\n",
      " - 2s - loss: 0.3207 - acc: 0.9281\n",
      "Epoch 191/200\n",
      " - 2s - loss: 0.2950 - acc: 0.9459\n",
      "Epoch 192/200\n",
      " - 2s - loss: 0.3261 - acc: 0.9266\n",
      "Epoch 193/200\n",
      " - 2s - loss: 0.2955 - acc: 0.9288\n",
      "Epoch 194/200\n",
      " - 2s - loss: 0.2845 - acc: 0.9452\n",
      "Epoch 195/200\n",
      " - 2s - loss: 0.2791 - acc: 0.9566\n",
      "Epoch 196/200\n",
      " - 2s - loss: 0.2693 - acc: 0.9665\n",
      "Epoch 197/200\n",
      " - 2s - loss: 0.4282 - acc: 0.9266\n",
      "Epoch 198/200\n",
      " - 2s - loss: 0.2312 - acc: 0.9665\n",
      "Epoch 199/200\n",
      " - 2s - loss: 0.2272 - acc: 0.9729\n",
      "Epoch 200/200\n",
      " - 2s - loss: 0.1861 - acc: 0.9786\n",
      "[[252   1   0   0   1   0]\n",
      " [  4 163   0   0   5   0]\n",
      " [  1   0 157   0   0   0]\n",
      " [  0   0   0  17   2   2]\n",
      " [  0   5   0   0  61   2]\n",
      " [  1   0   0   0  11   7]]\n",
      "\n",
      "\n",
      "<class 'keras.engine.sequential.Sequential'>\n",
      "||||| Accuracy : 0.8900174773050445 |||||\n",
      "\n",
      "\n",
      "Best actual accuracy : 0.9116562251885808\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_59 (Dense)             (None, 64)                3496384   \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 1000)              65000     \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 6)                 6006      \n",
      "=================================================================\n",
      "Total params: 6,570,390\n",
      "Trainable params: 6,570,390\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training...\n",
      "Epoch 1/200\n",
      " - 4s - loss: 1.7926 - acc: 0.1717\n",
      "Epoch 2/200\n",
      " - 3s - loss: 1.7798 - acc: 0.1325\n",
      "Epoch 3/200\n",
      " - 3s - loss: 1.6882 - acc: 0.3084\n",
      "Epoch 4/200\n",
      " - 3s - loss: 1.4796 - acc: 0.4167\n",
      "Epoch 5/200\n",
      " - 3s - loss: 1.2084 - acc: 0.5506\n",
      "Epoch 6/200\n",
      " - 4s - loss: 1.0679 - acc: 0.6360\n",
      "Epoch 7/200\n",
      " - 4s - loss: 1.0493 - acc: 0.6624\n",
      "Epoch 8/200\n",
      " - 3s - loss: 0.8996 - acc: 0.7450\n",
      "Epoch 9/200\n",
      " - 4s - loss: 0.9095 - acc: 0.7578\n",
      "Epoch 10/200\n",
      " - 4s - loss: 0.8226 - acc: 0.7991\n",
      "Epoch 11/200\n",
      " - 4s - loss: 0.8189 - acc: 0.7942\n",
      "Epoch 12/200\n",
      " - 4s - loss: 0.7818 - acc: 0.7906\n",
      "Epoch 13/200\n",
      " - 4s - loss: 0.8678 - acc: 0.7806\n",
      "Epoch 14/200\n",
      " - 4s - loss: 0.7490 - acc: 0.8319\n",
      "Epoch 15/200\n",
      " - 4s - loss: 0.6963 - acc: 0.8298\n",
      "Epoch 16/200\n",
      " - 4s - loss: 0.7591 - acc: 0.8191\n",
      "Epoch 17/200\n",
      " - 4s - loss: 0.7979 - acc: 0.7956\n",
      "Epoch 18/200\n",
      " - 4s - loss: 0.6925 - acc: 0.8305\n",
      "Epoch 19/200\n",
      " - 4s - loss: 0.6784 - acc: 0.8234\n",
      "Epoch 20/200\n",
      " - 4s - loss: 0.6523 - acc: 0.8447\n",
      "Epoch 21/200\n",
      " - 4s - loss: 0.6472 - acc: 0.8383\n",
      "Epoch 22/200\n",
      " - 4s - loss: 0.5747 - acc: 0.8761\n",
      "Epoch 23/200\n",
      " - 4s - loss: 0.5613 - acc: 0.8554\n",
      "Epoch 24/200\n",
      " - 4s - loss: 0.5775 - acc: 0.8625\n",
      "Epoch 25/200\n",
      " - 4s - loss: 0.5620 - acc: 0.8718\n",
      "Epoch 26/200\n",
      " - 4s - loss: 0.5128 - acc: 0.8789\n",
      "Epoch 27/200\n",
      " - 4s - loss: 0.5293 - acc: 0.8725\n",
      "Epoch 28/200\n",
      " - 4s - loss: 0.4519 - acc: 0.8853\n",
      "Epoch 29/200\n",
      " - 4s - loss: 0.5147 - acc: 0.8796\n",
      "Epoch 30/200\n",
      " - 4s - loss: 0.4792 - acc: 0.8761\n",
      "Epoch 31/200\n",
      " - 4s - loss: 0.4732 - acc: 0.8782\n",
      "Epoch 32/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 4s - loss: 0.4836 - acc: 0.8782\n",
      "Epoch 33/200\n",
      " - 4s - loss: 0.4461 - acc: 0.8846\n",
      "Epoch 34/200\n",
      " - 4s - loss: 0.4690 - acc: 0.8889\n",
      "Epoch 35/200\n",
      " - 4s - loss: 0.4263 - acc: 0.8996\n",
      "Epoch 36/200\n",
      " - 4s - loss: 0.3589 - acc: 0.9124\n",
      "Epoch 37/200\n",
      " - 4s - loss: 0.6222 - acc: 0.8362\n",
      "Epoch 38/200\n",
      " - 4s - loss: 0.4345 - acc: 0.8967\n",
      "Epoch 39/200\n",
      " - 4s - loss: 0.3870 - acc: 0.8974\n",
      "Epoch 40/200\n",
      " - 4s - loss: 0.3856 - acc: 0.9024\n",
      "Epoch 41/200\n",
      " - 4s - loss: 0.3550 - acc: 0.9145\n",
      "Epoch 42/200\n",
      " - 4s - loss: 0.3884 - acc: 0.8989\n",
      "Epoch 43/200\n",
      " - 4s - loss: 0.3496 - acc: 0.9103\n",
      "Epoch 44/200\n",
      " - 4s - loss: 0.3107 - acc: 0.9217\n",
      "Epoch 45/200\n",
      " - 4s - loss: 0.3453 - acc: 0.9053\n",
      "Epoch 46/200\n",
      " - 4s - loss: 0.3493 - acc: 0.9117\n",
      "Epoch 47/200\n",
      " - 4s - loss: 0.4091 - acc: 0.8953\n",
      "Epoch 48/200\n",
      " - 4s - loss: 0.2816 - acc: 0.9209\n",
      "Epoch 49/200\n",
      " - 4s - loss: 0.2983 - acc: 0.9053\n",
      "Epoch 50/200\n",
      " - 4s - loss: 0.3459 - acc: 0.8932\n",
      "Epoch 51/200\n",
      " - 4s - loss: 0.4185 - acc: 0.8754\n",
      "Epoch 52/200\n",
      " - 4s - loss: 0.3279 - acc: 0.9259\n",
      "Epoch 53/200\n",
      " - 4s - loss: 0.3331 - acc: 0.9174\n",
      "Epoch 54/200\n",
      " - 4s - loss: 0.2404 - acc: 0.9259\n",
      "Epoch 55/200\n",
      " - 4s - loss: 0.2149 - acc: 0.9466\n",
      "Epoch 56/200\n",
      " - 4s - loss: 0.2405 - acc: 0.9359\n",
      "Epoch 57/200\n",
      " - 4s - loss: 0.5403 - acc: 0.8746\n",
      "Epoch 58/200\n",
      " - 4s - loss: 0.2308 - acc: 0.9409\n",
      "Epoch 59/200\n",
      " - 4s - loss: 0.3401 - acc: 0.9309\n",
      "Epoch 60/200\n",
      " - 4s - loss: 0.2489 - acc: 0.9380\n",
      "Epoch 61/200\n",
      " - 4s - loss: 0.2669 - acc: 0.9274\n",
      "Epoch 62/200\n",
      " - 4s - loss: 0.2767 - acc: 0.9274\n",
      "Epoch 63/200\n",
      " - 4s - loss: 0.2542 - acc: 0.9345\n",
      "Epoch 64/200\n",
      " - 4s - loss: 0.2069 - acc: 0.9409\n",
      "Epoch 65/200\n",
      " - 4s - loss: 0.3123 - acc: 0.9152\n",
      "Epoch 66/200\n",
      " - 4s - loss: 0.2323 - acc: 0.9309\n",
      "Epoch 67/200\n",
      " - 4s - loss: 0.1459 - acc: 0.9573\n",
      "Epoch 68/200\n",
      " - 4s - loss: 0.2714 - acc: 0.9366\n",
      "Epoch 69/200\n",
      " - 4s - loss: 0.1953 - acc: 0.9423\n",
      "Epoch 70/200\n",
      " - 4s - loss: 0.1840 - acc: 0.9494\n",
      "Epoch 71/200\n",
      " - 4s - loss: 0.2046 - acc: 0.9452\n",
      "Epoch 72/200\n",
      " - 4s - loss: 0.2175 - acc: 0.9402\n",
      "Epoch 73/200\n",
      " - 4s - loss: 0.1430 - acc: 0.9608\n",
      "Epoch 74/200\n",
      " - 4s - loss: 0.4174 - acc: 0.8782\n",
      "Epoch 75/200\n",
      " - 4s - loss: 0.2059 - acc: 0.9459\n",
      "Epoch 76/200\n",
      " - 4s - loss: 0.1627 - acc: 0.9587\n",
      "Epoch 77/200\n",
      " - 4s - loss: 0.3643 - acc: 0.8761\n",
      "Epoch 78/200\n",
      " - 4s - loss: 1.1190 - acc: 0.8775\n",
      "Epoch 79/200\n",
      " - 4s - loss: 0.3912 - acc: 0.9359\n",
      "Epoch 80/200\n",
      " - 4s - loss: 0.1471 - acc: 0.9573\n",
      "Epoch 81/200\n",
      " - 4s - loss: 0.2073 - acc: 0.9509\n",
      "Epoch 82/200\n",
      " - 4s - loss: 0.1597 - acc: 0.9608\n",
      "Epoch 83/200\n",
      " - 4s - loss: 0.1320 - acc: 0.9708\n",
      "Epoch 84/200\n",
      " - 4s - loss: 0.1456 - acc: 0.9594\n",
      "Epoch 85/200\n",
      " - 4s - loss: 0.1230 - acc: 0.9637\n",
      "Epoch 86/200\n",
      " - 4s - loss: 0.1142 - acc: 0.9658\n",
      "Epoch 87/200\n",
      " - 4s - loss: 0.1175 - acc: 0.9672\n",
      "Epoch 88/200\n",
      " - 4s - loss: 0.1747 - acc: 0.9501\n",
      "Epoch 89/200\n",
      " - 4s - loss: 0.1730 - acc: 0.9566\n",
      "Epoch 90/200\n",
      " - 4s - loss: 0.1304 - acc: 0.9637\n",
      "Epoch 91/200\n",
      " - 4s - loss: 0.1263 - acc: 0.9672\n",
      "Epoch 92/200\n",
      " - 4s - loss: 0.1037 - acc: 0.9722\n",
      "Epoch 93/200\n",
      " - 4s - loss: 0.3129 - acc: 0.9473\n",
      "Epoch 94/200\n",
      " - 4s - loss: 0.1982 - acc: 0.9551\n",
      "Epoch 95/200\n",
      " - 4s - loss: 0.0874 - acc: 0.9801\n",
      "Epoch 96/200\n",
      " - 4s - loss: 0.1286 - acc: 0.9708\n",
      "Epoch 97/200\n",
      " - 4s - loss: 0.1702 - acc: 0.9537\n",
      "Epoch 98/200\n",
      " - 4s - loss: 0.0940 - acc: 0.9765\n",
      "Epoch 99/200\n",
      " - 4s - loss: 0.4397 - acc: 0.9174\n",
      "Epoch 100/200\n",
      " - 4s - loss: 0.2365 - acc: 0.9437\n",
      "Epoch 101/200\n",
      " - 4s - loss: 0.0747 - acc: 0.9829\n",
      "Epoch 102/200\n",
      " - 4s - loss: 0.1275 - acc: 0.9751\n",
      "Epoch 103/200\n",
      " - 4s - loss: 0.0771 - acc: 0.9751\n",
      "Epoch 104/200\n",
      " - 4s - loss: 0.1145 - acc: 0.9715\n",
      "Epoch 105/200\n",
      " - 4s - loss: 0.3927 - acc: 0.9167\n",
      "Epoch 106/200\n",
      " - 4s - loss: 0.0938 - acc: 0.9779\n",
      "Epoch 107/200\n",
      " - 4s - loss: 0.0958 - acc: 0.9779\n",
      "Epoch 108/200\n",
      " - 4s - loss: 0.0691 - acc: 0.9822\n",
      "Epoch 109/200\n",
      " - 4s - loss: 0.0682 - acc: 0.9829\n",
      "Epoch 110/200\n",
      " - 4s - loss: 0.3249 - acc: 0.9323\n",
      "Epoch 111/200\n",
      " - 4s - loss: 0.1677 - acc: 0.9594\n",
      "Epoch 112/200\n",
      " - 4s - loss: 0.1327 - acc: 0.9687\n",
      "Epoch 113/200\n",
      " - 4s - loss: 0.0894 - acc: 0.9801\n",
      "Epoch 114/200\n",
      " - 4s - loss: 0.3328 - acc: 0.9160\n",
      "Epoch 115/200\n",
      " - 4s - loss: 0.0852 - acc: 0.9779\n",
      "Epoch 116/200\n",
      " - 4s - loss: 0.0558 - acc: 0.9843\n",
      "Epoch 117/200\n",
      " - 4s - loss: 0.1224 - acc: 0.9765\n",
      "Epoch 118/200\n",
      " - 4s - loss: 0.2588 - acc: 0.9366\n",
      "Epoch 119/200\n",
      " - 4s - loss: 0.2088 - acc: 0.9516\n",
      "Epoch 120/200\n",
      " - 4s - loss: 0.1659 - acc: 0.9644\n",
      "Epoch 121/200\n",
      " - 4s - loss: 0.0738 - acc: 0.9858\n",
      "Epoch 122/200\n",
      " - 4s - loss: 0.0275 - acc: 0.9957\n",
      "Epoch 123/200\n",
      " - 4s - loss: 0.1250 - acc: 0.9722\n",
      "Epoch 124/200\n",
      " - 4s - loss: 0.0310 - acc: 0.9879\n",
      "Epoch 125/200\n",
      " - 4s - loss: 0.1086 - acc: 0.9665\n",
      "Epoch 126/200\n",
      " - 4s - loss: 0.0463 - acc: 0.9872\n",
      "Epoch 127/200\n",
      " - 4s - loss: 0.1022 - acc: 0.9786\n",
      "Epoch 128/200\n",
      " - 4s - loss: 0.1056 - acc: 0.9744\n",
      "Epoch 129/200\n",
      " - 4s - loss: 0.0981 - acc: 0.9758\n",
      "Epoch 130/200\n",
      " - 4s - loss: 0.0843 - acc: 0.9850\n",
      "Epoch 131/200\n",
      " - 4s - loss: 0.1510 - acc: 0.9744\n",
      "Epoch 132/200\n",
      " - 4s - loss: 0.0628 - acc: 0.9836\n",
      "Epoch 133/200\n",
      " - 4s - loss: 0.0187 - acc: 0.9929\n",
      "Epoch 134/200\n",
      " - 4s - loss: 0.2012 - acc: 0.9466\n",
      "Epoch 135/200\n",
      " - 4s - loss: 0.1096 - acc: 0.9765\n",
      "Epoch 136/200\n",
      " - 4s - loss: 0.2092 - acc: 0.9416\n",
      "Epoch 137/200\n",
      " - 4s - loss: 0.1488 - acc: 0.9615\n",
      "Epoch 138/200\n",
      " - 4s - loss: 0.1650 - acc: 0.9594\n",
      "Epoch 139/200\n",
      " - 4s - loss: 0.0401 - acc: 0.9907\n",
      "Epoch 140/200\n",
      " - 4s - loss: 0.0174 - acc: 0.9957\n",
      "Epoch 141/200\n",
      " - 4s - loss: 0.2681 - acc: 0.9537\n",
      "Epoch 142/200\n",
      " - 4s - loss: 0.0712 - acc: 0.9822\n",
      "Epoch 143/200\n",
      " - 4s - loss: 0.0275 - acc: 0.9915\n",
      "Epoch 144/200\n",
      " - 4s - loss: 0.0140 - acc: 0.9950\n",
      "Epoch 145/200\n",
      " - 4s - loss: 0.0493 - acc: 0.9865\n",
      "Epoch 146/200\n",
      " - 4s - loss: 0.0050 - acc: 0.9993\n",
      "Epoch 147/200\n",
      " - 4s - loss: 0.0049 - acc: 0.9993\n",
      "Epoch 148/200\n",
      " - 4s - loss: 0.0323 - acc: 0.9915\n",
      "Epoch 149/200\n",
      " - 4s - loss: 0.0081 - acc: 0.9972\n",
      "Epoch 150/200\n",
      " - 4s - loss: 0.0200 - acc: 0.9929\n",
      "Epoch 151/200\n",
      " - 4s - loss: 0.0067 - acc: 0.9979\n",
      "Epoch 152/200\n",
      " - 4s - loss: 0.0080 - acc: 0.9972\n",
      "Epoch 153/200\n",
      " - 4s - loss: 0.0056 - acc: 0.9964\n",
      "Epoch 154/200\n",
      " - 4s - loss: 0.0073 - acc: 0.9972\n",
      "Epoch 155/200\n",
      " - 4s - loss: 0.2525 - acc: 0.9551\n",
      "Epoch 156/200\n",
      " - 4s - loss: 0.3780 - acc: 0.8910\n",
      "Epoch 157/200\n",
      " - 4s - loss: 0.2631 - acc: 0.9487\n",
      "Epoch 158/200\n",
      " - 4s - loss: 0.0842 - acc: 0.9786\n",
      "Epoch 159/200\n",
      " - 4s - loss: 0.0395 - acc: 0.9886\n",
      "Epoch 160/200\n",
      " - 4s - loss: 0.4540 - acc: 0.9017\n",
      "Epoch 161/200\n",
      " - 4s - loss: 0.4195 - acc: 0.9060\n",
      "Epoch 162/200\n",
      " - 4s - loss: 0.1974 - acc: 0.9701\n",
      "Epoch 163/200\n",
      " - 4s - loss: 0.0374 - acc: 0.9929\n",
      "Epoch 164/200\n",
      " - 4s - loss: 0.0894 - acc: 0.9808\n",
      "Epoch 165/200\n",
      " - 4s - loss: 0.0436 - acc: 0.9900\n",
      "Epoch 166/200\n",
      " - 4s - loss: 0.0086 - acc: 0.9986\n",
      "Epoch 167/200\n",
      " - 4s - loss: 0.0478 - acc: 0.9858\n",
      "Epoch 168/200\n",
      " - 4s - loss: 0.0143 - acc: 0.9957\n",
      "Epoch 169/200\n",
      " - 4s - loss: 0.0035 - acc: 0.9993\n",
      "Epoch 170/200\n",
      " - 4s - loss: 0.0061 - acc: 0.9979\n",
      "Epoch 171/200\n",
      " - 4s - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 172/200\n",
      " - 4s - loss: 0.0045 - acc: 0.9986\n",
      "Epoch 173/200\n",
      " - 4s - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 174/200\n",
      " - 4s - loss: 0.0117 - acc: 0.9950\n",
      "Epoch 175/200\n",
      " - 4s - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 176/200\n",
      " - 4s - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 177/200\n",
      " - 4s - loss: 9.7263e-04 - acc: 1.0000\n",
      "Epoch 178/200\n",
      " - 4s - loss: 0.0040 - acc: 0.9979\n",
      "Epoch 179/200\n",
      " - 4s - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 180/200\n",
      " - 4s - loss: 0.0610 - acc: 0.9879\n",
      "Epoch 181/200\n",
      " - 4s - loss: 0.0034 - acc: 0.9993\n",
      "Epoch 182/200\n",
      " - 4s - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 183/200\n",
      " - 4s - loss: 0.1150 - acc: 0.9801\n",
      "Epoch 184/200\n",
      " - 4s - loss: 0.0046 - acc: 0.9993\n",
      "Epoch 185/200\n",
      " - 4s - loss: 0.0186 - acc: 0.9943\n",
      "Epoch 186/200\n",
      " - 4s - loss: 0.0122 - acc: 0.9950\n",
      "Epoch 187/200\n",
      " - 4s - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 188/200\n",
      " - 4s - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 189/200\n",
      " - 4s - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 190/200\n",
      " - 4s - loss: 0.0021 - acc: 0.9993\n",
      "Epoch 191/200\n",
      " - 4s - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 192/200\n",
      " - 4s - loss: 8.0267e-04 - acc: 1.0000\n",
      "Epoch 193/200\n",
      " - 4s - loss: 6.8230e-04 - acc: 1.0000\n",
      "Epoch 194/200\n",
      " - 4s - loss: 8.7659e-04 - acc: 1.0000\n",
      "Epoch 195/200\n",
      " - 4s - loss: 9.4477e-04 - acc: 1.0000\n",
      "Epoch 196/200\n",
      " - 4s - loss: 0.0017 - acc: 0.9993\n",
      "Epoch 197/200\n",
      " - 4s - loss: 8.1201e-04 - acc: 1.0000\n",
      "Epoch 198/200\n",
      " - 4s - loss: 8.9953e-04 - acc: 1.0000\n",
      "Epoch 199/200\n",
      " - 4s - loss: 5.7115e-04 - acc: 1.0000\n",
      "Epoch 200/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 4s - loss: 6.3687e-04 - acc: 1.0000\n",
      "[[252   1   0   0   1   0]\n",
      " [  4 164   0   1   3   0]\n",
      " [  0   1 157   0   0   0]\n",
      " [  0   1   0  20   0   0]\n",
      " [  0   4   0   0  61   3]\n",
      " [  1   0   0   0   9   9]]\n",
      "\n",
      "\n",
      "<class 'keras.engine.sequential.Sequential'>\n",
      "||||| Accuracy : 0.9110523918787282 |||||\n",
      "\n",
      "\n",
      "Best actual accuracy : 0.9116562251885808\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_65 (Dense)             (None, 64)                3496384   \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 1500)              97500     \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 1500)              0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 1500)              2251500   \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 1500)              0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 1500)              2251500   \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 1500)              0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 1500)              2251500   \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 1500)              0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 6)                 9006      \n",
      "=================================================================\n",
      "Total params: 10,357,390\n",
      "Trainable params: 10,357,390\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training...\n",
      "Epoch 1/200\n",
      " - 7s - loss: 1.7964 - acc: 0.1147\n",
      "Epoch 2/200\n",
      " - 7s - loss: 1.7794 - acc: 0.1154\n",
      "Epoch 3/200\n",
      " - 7s - loss: 1.6702 - acc: 0.2799\n",
      "Epoch 4/200\n",
      " - 6s - loss: 1.4362 - acc: 0.4081\n",
      "Epoch 5/200\n",
      " - 6s - loss: 1.2476 - acc: 0.5157\n",
      "Epoch 6/200\n",
      " - 6s - loss: 1.0163 - acc: 0.6603\n",
      "Epoch 7/200\n",
      " - 7s - loss: 0.9376 - acc: 0.7066\n",
      "Epoch 8/200\n",
      " - 7s - loss: 0.8729 - acc: 0.7308\n",
      "Epoch 9/200\n",
      " - 6s - loss: 0.8378 - acc: 0.7621\n",
      "Epoch 10/200\n",
      " - 6s - loss: 0.7900 - acc: 0.7877\n",
      "Epoch 11/200\n",
      " - 6s - loss: 0.7764 - acc: 0.8027\n",
      "Epoch 12/200\n",
      " - 6s - loss: 0.8696 - acc: 0.7564\n",
      "Epoch 13/200\n",
      " - 7s - loss: 0.7540 - acc: 0.8191\n",
      "Epoch 14/200\n",
      " - 7s - loss: 0.7494 - acc: 0.8084\n",
      "Epoch 15/200\n",
      " - 6s - loss: 0.8044 - acc: 0.7991\n",
      "Epoch 16/200\n",
      " - 6s - loss: 0.7551 - acc: 0.8248\n",
      "Epoch 17/200\n",
      " - 7s - loss: 0.7171 - acc: 0.8283\n",
      "Epoch 18/200\n",
      " - 7s - loss: 0.6906 - acc: 0.8333\n",
      "Epoch 19/200\n",
      " - 7s - loss: 0.6930 - acc: 0.8141\n",
      "Epoch 20/200\n",
      " - 7s - loss: 0.6455 - acc: 0.8440\n",
      "Epoch 21/200\n",
      " - 7s - loss: 0.5858 - acc: 0.8504\n",
      "Epoch 22/200\n",
      " - 7s - loss: 0.7050 - acc: 0.8191\n",
      "Epoch 23/200\n",
      " - 7s - loss: 0.5877 - acc: 0.8618\n",
      "Epoch 24/200\n",
      " - 7s - loss: 0.6046 - acc: 0.8483\n",
      "Epoch 25/200\n",
      " - 7s - loss: 0.6018 - acc: 0.8526\n",
      "Epoch 26/200\n",
      " - 7s - loss: 0.5383 - acc: 0.8504\n",
      "Epoch 27/200\n",
      " - 7s - loss: 0.6511 - acc: 0.8526\n",
      "Epoch 28/200\n",
      " - 7s - loss: 0.5484 - acc: 0.8618\n",
      "Epoch 29/200\n",
      " - 7s - loss: 0.5105 - acc: 0.8875\n",
      "Epoch 30/200\n",
      " - 7s - loss: 0.4496 - acc: 0.8818\n",
      "Epoch 31/200\n",
      " - 7s - loss: 0.5301 - acc: 0.8739\n",
      "Epoch 32/200\n",
      " - 7s - loss: 0.4993 - acc: 0.8853\n",
      "Epoch 33/200\n",
      " - 7s - loss: 0.4680 - acc: 0.8789\n",
      "Epoch 34/200\n",
      " - 7s - loss: 0.4843 - acc: 0.8718\n",
      "Epoch 35/200\n",
      " - 6s - loss: 0.3916 - acc: 0.8832\n",
      "Epoch 36/200\n",
      " - 6s - loss: 0.4674 - acc: 0.8668\n",
      "Epoch 37/200\n",
      " - 7s - loss: 0.4491 - acc: 0.8889\n",
      "Epoch 38/200\n",
      " - 6s - loss: 0.3361 - acc: 0.9138\n",
      "Epoch 39/200\n",
      " - 7s - loss: 0.3723 - acc: 0.9067\n",
      "Epoch 40/200\n",
      " - 7s - loss: 0.4651 - acc: 0.8989\n",
      "Epoch 41/200\n",
      " - 7s - loss: 0.4301 - acc: 0.8917\n",
      "Epoch 42/200\n",
      " - 7s - loss: 0.3459 - acc: 0.9195\n",
      "Epoch 43/200\n",
      " - 7s - loss: 0.3465 - acc: 0.9160\n",
      "Epoch 44/200\n",
      " - 7s - loss: 0.3394 - acc: 0.9160\n",
      "Epoch 45/200\n",
      " - 7s - loss: 0.3539 - acc: 0.8889\n",
      "Epoch 46/200\n",
      " - 7s - loss: 0.4360 - acc: 0.8989\n",
      "Epoch 47/200\n",
      " - 7s - loss: 0.2995 - acc: 0.9281\n",
      "Epoch 48/200\n",
      " - 7s - loss: 0.2478 - acc: 0.9387\n",
      "Epoch 49/200\n",
      " - 6s - loss: 0.3605 - acc: 0.8981\n",
      "Epoch 50/200\n",
      " - 7s - loss: 0.2744 - acc: 0.9252\n",
      "Epoch 51/200\n",
      " - 7s - loss: 0.3167 - acc: 0.9131\n",
      "Epoch 52/200\n",
      " - 7s - loss: 0.3143 - acc: 0.9181\n",
      "Epoch 53/200\n",
      " - 7s - loss: 0.2744 - acc: 0.9395\n",
      "Epoch 54/200\n",
      " - 6s - loss: 0.3656 - acc: 0.9345\n",
      "Epoch 55/200\n",
      " - 6s - loss: 0.3659 - acc: 0.8796\n",
      "Epoch 56/200\n",
      " - 6s - loss: 0.2943 - acc: 0.9188\n",
      "Epoch 57/200\n",
      " - 6s - loss: 0.2343 - acc: 0.9302\n",
      "Epoch 58/200\n",
      " - 6s - loss: 0.3201 - acc: 0.9145\n",
      "Epoch 59/200\n",
      " - 6s - loss: 0.2875 - acc: 0.9195\n",
      "Epoch 60/200\n",
      " - 6s - loss: 0.2654 - acc: 0.9281\n",
      "Epoch 61/200\n",
      " - 6s - loss: 0.1852 - acc: 0.9537\n",
      "Epoch 62/200\n",
      " - 6s - loss: 0.3666 - acc: 0.9188\n",
      "Epoch 63/200\n",
      " - 6s - loss: 0.1857 - acc: 0.9509\n",
      "Epoch 64/200\n",
      " - 6s - loss: 0.2270 - acc: 0.9459\n",
      "Epoch 65/200\n",
      " - 6s - loss: 0.1841 - acc: 0.9608\n",
      "Epoch 66/200\n",
      " - 6s - loss: 0.1933 - acc: 0.9551\n",
      "Epoch 67/200\n",
      " - 6s - loss: 0.1885 - acc: 0.9480\n",
      "Epoch 68/200\n",
      " - 6s - loss: 0.3185 - acc: 0.9138\n",
      "Epoch 69/200\n",
      " - 6s - loss: 0.2867 - acc: 0.9259\n",
      "Epoch 70/200\n",
      " - 6s - loss: 0.1657 - acc: 0.9601\n",
      "Epoch 71/200\n",
      " - 6s - loss: 0.2672 - acc: 0.9231\n",
      "Epoch 72/200\n",
      " - 6s - loss: 0.2942 - acc: 0.9266\n",
      "Epoch 73/200\n",
      " - 6s - loss: 0.4094 - acc: 0.8818\n",
      "Epoch 74/200\n",
      " - 6s - loss: 0.2063 - acc: 0.9473\n",
      "Epoch 75/200\n",
      " - 6s - loss: 0.3329 - acc: 0.9466\n",
      "Epoch 76/200\n",
      " - 6s - loss: 0.1943 - acc: 0.9537\n",
      "Epoch 77/200\n",
      " - 6s - loss: 0.1964 - acc: 0.9580\n",
      "Epoch 78/200\n",
      " - 6s - loss: 0.1655 - acc: 0.9594\n",
      "Epoch 79/200\n",
      " - 6s - loss: 0.1871 - acc: 0.9501\n",
      "Epoch 80/200\n",
      " - 6s - loss: 0.2903 - acc: 0.9188\n",
      "Epoch 81/200\n",
      " - 6s - loss: 0.1851 - acc: 0.9551\n",
      "Epoch 82/200\n",
      " - 6s - loss: 0.1798 - acc: 0.9558\n",
      "Epoch 83/200\n",
      " - 6s - loss: 0.1463 - acc: 0.9551\n",
      "Epoch 84/200\n",
      " - 6s - loss: 0.1394 - acc: 0.9658\n",
      "Epoch 85/200\n",
      " - 6s - loss: 0.1862 - acc: 0.9509\n",
      "Epoch 86/200\n",
      " - 6s - loss: 0.1808 - acc: 0.9480\n",
      "Epoch 87/200\n",
      " - 6s - loss: 0.0973 - acc: 0.9765\n",
      "Epoch 88/200\n",
      " - 6s - loss: 0.2895 - acc: 0.9352\n",
      "Epoch 89/200\n",
      " - 6s - loss: 0.1329 - acc: 0.9658\n",
      "Epoch 90/200\n",
      " - 6s - loss: 0.3516 - acc: 0.9038\n",
      "Epoch 91/200\n",
      " - 6s - loss: 0.1507 - acc: 0.9637\n",
      "Epoch 92/200\n",
      " - 6s - loss: 0.1909 - acc: 0.9501\n",
      "Epoch 93/200\n",
      " - 6s - loss: 0.0755 - acc: 0.9808\n",
      "Epoch 94/200\n",
      " - 6s - loss: 0.2096 - acc: 0.9630\n",
      "Epoch 95/200\n",
      " - 6s - loss: 0.4285 - acc: 0.8561\n",
      "Epoch 96/200\n",
      " - 6s - loss: 0.2444 - acc: 0.9316\n",
      "Epoch 97/200\n",
      " - 6s - loss: 0.4368 - acc: 0.9224\n",
      "Epoch 98/200\n",
      " - 6s - loss: 0.1472 - acc: 0.9701\n",
      "Epoch 99/200\n",
      " - 6s - loss: 0.0993 - acc: 0.9751\n",
      "Epoch 100/200\n",
      " - 6s - loss: 0.1059 - acc: 0.9729\n",
      "Epoch 101/200\n",
      " - 6s - loss: 0.0934 - acc: 0.9772\n",
      "Epoch 102/200\n",
      " - 6s - loss: 0.1128 - acc: 0.9736\n",
      "Epoch 103/200\n",
      " - 6s - loss: 0.0963 - acc: 0.9736\n",
      "Epoch 104/200\n",
      " - 6s - loss: 0.1458 - acc: 0.9665\n",
      "Epoch 105/200\n",
      " - 6s - loss: 0.1319 - acc: 0.9672\n",
      "Epoch 106/200\n",
      " - 5s - loss: 0.0676 - acc: 0.9879\n",
      "Epoch 107/200\n",
      " - 6s - loss: 0.0603 - acc: 0.9836\n",
      "Epoch 108/200\n",
      " - 6s - loss: 0.0936 - acc: 0.9765\n",
      "Epoch 109/200\n",
      " - 6s - loss: 0.0888 - acc: 0.9729\n",
      "Epoch 110/200\n",
      " - 6s - loss: 0.1327 - acc: 0.9736\n",
      "Epoch 111/200\n",
      " - 6s - loss: 0.0957 - acc: 0.9765\n",
      "Epoch 112/200\n",
      " - 6s - loss: 0.0499 - acc: 0.9872\n",
      "Epoch 113/200\n",
      " - 6s - loss: 0.0187 - acc: 0.9943\n",
      "Epoch 114/200\n",
      " - 6s - loss: 0.2290 - acc: 0.9509\n",
      "Epoch 115/200\n",
      " - 5s - loss: 0.0614 - acc: 0.9822\n",
      "Epoch 116/200\n",
      " - 6s - loss: 0.1544 - acc: 0.9644\n",
      "Epoch 117/200\n",
      " - 5s - loss: 0.0506 - acc: 0.9886\n",
      "Epoch 118/200\n",
      " - 6s - loss: 0.3825 - acc: 0.9224\n",
      "Epoch 119/200\n",
      " - 6s - loss: 0.1668 - acc: 0.9651\n",
      "Epoch 120/200\n",
      " - 6s - loss: 0.0299 - acc: 0.9922\n",
      "Epoch 121/200\n",
      " - 6s - loss: 0.1405 - acc: 0.9694\n",
      "Epoch 122/200\n",
      " - 6s - loss: 0.0755 - acc: 0.9765\n",
      "Epoch 123/200\n",
      " - 6s - loss: 0.0379 - acc: 0.9936\n",
      "Epoch 124/200\n",
      " - 6s - loss: 0.1149 - acc: 0.9722\n",
      "Epoch 125/200\n",
      " - 6s - loss: 0.1204 - acc: 0.9786\n",
      "Epoch 126/200\n",
      " - 6s - loss: 0.0213 - acc: 0.9950\n",
      "Epoch 127/200\n",
      " - 6s - loss: 0.0401 - acc: 0.9893\n",
      "Epoch 128/200\n",
      " - 6s - loss: 0.0375 - acc: 0.9929\n",
      "Epoch 129/200\n",
      " - 6s - loss: 0.0670 - acc: 0.9850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/200\n",
      " - 6s - loss: 0.0132 - acc: 0.9993\n",
      "Epoch 131/200\n",
      " - 6s - loss: 0.0153 - acc: 0.9950\n",
      "Epoch 132/200\n",
      " - 6s - loss: 0.0772 - acc: 0.9843\n",
      "Epoch 133/200\n",
      " - 6s - loss: 0.0092 - acc: 0.9979\n",
      "Epoch 134/200\n",
      " - 6s - loss: 0.1000 - acc: 0.9836\n",
      "Epoch 135/200\n",
      " - 6s - loss: 0.0832 - acc: 0.9858\n",
      "Epoch 136/200\n",
      " - 6s - loss: 0.0205 - acc: 0.9943\n",
      "Epoch 137/200\n",
      " - 6s - loss: 0.0079 - acc: 0.9986\n",
      "Epoch 138/200\n",
      " - 6s - loss: 0.0046 - acc: 0.9979\n",
      "Epoch 139/200\n",
      " - 6s - loss: 0.0313 - acc: 0.9922\n",
      "Epoch 140/200\n",
      " - 6s - loss: 0.0163 - acc: 0.9957\n",
      "Epoch 141/200\n",
      " - 6s - loss: 0.0101 - acc: 0.9972\n",
      "Epoch 142/200\n",
      " - 6s - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 143/200\n",
      " - 6s - loss: 0.0118 - acc: 0.9950\n",
      "Epoch 144/200\n",
      " - 6s - loss: 0.0133 - acc: 0.9943\n",
      "Epoch 145/200\n",
      " - 6s - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 146/200\n",
      " - 6s - loss: 0.0036 - acc: 0.9979\n",
      "Epoch 147/200\n",
      " - 6s - loss: 0.0903 - acc: 0.9850\n",
      "Epoch 148/200\n",
      " - 6s - loss: 0.0450 - acc: 0.9979\n",
      "Epoch 149/200\n",
      " - 6s - loss: 0.0063 - acc: 0.9979\n",
      "Epoch 150/200\n",
      " - 6s - loss: 0.0991 - acc: 0.9822\n",
      "Epoch 151/200\n",
      " - 6s - loss: 0.1854 - acc: 0.9694\n",
      "Epoch 152/200\n",
      " - 6s - loss: 0.0094 - acc: 0.9972\n",
      "Epoch 153/200\n",
      " - 7s - loss: 0.0068 - acc: 0.9993\n",
      "Epoch 154/200\n",
      " - 7s - loss: 0.0036 - acc: 0.9993\n",
      "Epoch 155/200\n",
      " - 7s - loss: 0.0030 - acc: 0.9993\n",
      "Epoch 156/200\n",
      " - 7s - loss: 0.0031 - acc: 0.9993\n",
      "Epoch 157/200\n",
      " - 7s - loss: 0.0028 - acc: 0.9986\n",
      "Epoch 158/200\n",
      " - 6s - loss: 0.0989 - acc: 0.9815\n",
      "Epoch 159/200\n",
      " - 6s - loss: 0.0461 - acc: 0.9900\n",
      "Epoch 160/200\n",
      " - 6s - loss: 0.0045 - acc: 0.9993\n",
      "Epoch 161/200\n",
      " - 6s - loss: 0.0042 - acc: 0.9986\n",
      "Epoch 162/200\n",
      " - 6s - loss: 0.1176 - acc: 0.9786\n",
      "Epoch 163/200\n",
      " - 6s - loss: 0.0107 - acc: 0.9986\n",
      "Epoch 164/200\n",
      " - 6s - loss: 0.0060 - acc: 0.9993\n",
      "Epoch 165/200\n",
      " - 6s - loss: 0.0048 - acc: 0.9972\n",
      "Epoch 166/200\n",
      " - 7s - loss: 0.0025 - acc: 0.9993\n",
      "Epoch 167/200\n",
      " - 7s - loss: 0.0423 - acc: 0.9865\n",
      "Epoch 168/200\n",
      " - 7s - loss: 0.0041 - acc: 0.9993\n",
      "Epoch 169/200\n",
      " - 6s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 170/200\n",
      " - 6s - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 171/200\n",
      " - 6s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 172/200\n",
      " - 6s - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 173/200\n",
      " - 6s - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 174/200\n",
      " - 6s - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 175/200\n",
      " - 6s - loss: 8.2834e-04 - acc: 1.0000\n",
      "Epoch 176/200\n",
      " - 6s - loss: 9.0485e-04 - acc: 1.0000\n",
      "Epoch 177/200\n",
      " - 6s - loss: 6.8716e-04 - acc: 1.0000\n",
      "Epoch 178/200\n",
      " - 6s - loss: 6.2632e-04 - acc: 1.0000\n",
      "Epoch 179/200\n",
      " - 6s - loss: 8.3003e-04 - acc: 1.0000\n",
      "Epoch 180/200\n",
      " - 6s - loss: 7.7325e-04 - acc: 1.0000\n",
      "Epoch 181/200\n",
      " - 6s - loss: 0.0023 - acc: 0.9993\n",
      "Epoch 182/200\n",
      " - 6s - loss: 6.0602e-04 - acc: 1.0000\n",
      "Epoch 183/200\n",
      " - 6s - loss: 6.9311e-04 - acc: 1.0000\n",
      "Epoch 184/200\n",
      " - 6s - loss: 9.2873e-04 - acc: 0.9993\n",
      "Epoch 185/200\n",
      " - 6s - loss: 0.1628 - acc: 0.9687\n",
      "Epoch 186/200\n",
      " - 6s - loss: 0.0985 - acc: 0.9736\n",
      "Epoch 187/200\n",
      " - 6s - loss: 0.0089 - acc: 0.9986\n",
      "Epoch 188/200\n",
      " - 7s - loss: 0.0028 - acc: 0.9993\n",
      "Epoch 189/200\n",
      " - 7s - loss: 0.0176 - acc: 0.9979\n",
      "Epoch 190/200\n",
      " - 7s - loss: 0.0605 - acc: 0.9886\n",
      "Epoch 191/200\n",
      " - 7s - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 192/200\n",
      " - 7s - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 193/200\n",
      " - 7s - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 194/200\n",
      " - 7s - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 195/200\n",
      " - 7s - loss: 8.5113e-04 - acc: 1.0000\n",
      "Epoch 196/200\n",
      " - 7s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 197/200\n",
      " - 7s - loss: 7.7358e-04 - acc: 1.0000\n",
      "Epoch 198/200\n",
      " - 7s - loss: 8.6056e-04 - acc: 1.0000\n",
      "Epoch 199/200\n",
      " - 7s - loss: 5.3008e-04 - acc: 1.0000\n",
      "Epoch 200/200\n",
      " - 7s - loss: 5.3497e-04 - acc: 1.0000\n",
      "[[250   3   0   0   1   0]\n",
      " [  3 163   0   1   5   0]\n",
      " [  0   1 157   0   0   0]\n",
      " [  0   0   0  20   1   0]\n",
      " [  0   2   0   0  62   4]\n",
      " [  1   0   0   0   9   9]]\n",
      "\n",
      "\n",
      "<class 'keras.engine.sequential.Sequential'>\n",
      "||||| Accuracy : 0.8980515749140826 |||||\n",
      "\n",
      "\n",
      "Best actual accuracy : 0.9116562251885808\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_71 (Dense)             (None, 64)                3496384   \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 2000)              130000    \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 2000)              4002000   \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 2000)              4002000   \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 2000)              4002000   \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 6)                 12006     \n",
      "=================================================================\n",
      "Total params: 15,644,390\n",
      "Trainable params: 15,644,390\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training...\n",
      "Epoch 1/200\n",
      " - 11s - loss: 1.7951 - acc: 0.1439\n",
      "Epoch 2/200\n",
      " - 11s - loss: 1.7815 - acc: 0.2051\n",
      "Epoch 3/200\n",
      " - 10s - loss: 1.6736 - acc: 0.2835\n",
      "Epoch 4/200\n",
      " - 11s - loss: 1.4094 - acc: 0.4174\n",
      "Epoch 5/200\n",
      " - 11s - loss: 1.2298 - acc: 0.5434\n",
      "Epoch 6/200\n",
      " - 10s - loss: 1.0448 - acc: 0.6560\n",
      "Epoch 7/200\n",
      " - 9s - loss: 0.9674 - acc: 0.6880\n",
      "Epoch 8/200\n",
      " - 9s - loss: 0.8748 - acc: 0.7500\n",
      "Epoch 9/200\n",
      " - 11s - loss: 0.8598 - acc: 0.7707\n",
      "Epoch 10/200\n",
      " - 11s - loss: 0.8467 - acc: 0.7785\n",
      "Epoch 11/200\n",
      " - 11s - loss: 0.7746 - acc: 0.8127\n",
      "Epoch 12/200\n",
      " - 11s - loss: 0.7411 - acc: 0.8248\n",
      "Epoch 13/200\n",
      " - 11s - loss: 0.7108 - acc: 0.8248\n",
      "Epoch 14/200\n",
      " - 11s - loss: 0.7276 - acc: 0.8269\n",
      "Epoch 15/200\n",
      " - 11s - loss: 0.8474 - acc: 0.7692\n",
      "Epoch 16/200\n",
      " - 11s - loss: 0.8354 - acc: 0.7842\n",
      "Epoch 17/200\n",
      " - 11s - loss: 0.8377 - acc: 0.7543\n",
      "Epoch 18/200\n",
      " - 11s - loss: 0.6842 - acc: 0.8397\n",
      "Epoch 19/200\n",
      " - 10s - loss: 0.6595 - acc: 0.8312\n",
      "Epoch 20/200\n",
      " - 11s - loss: 0.6962 - acc: 0.8212\n",
      "Epoch 21/200\n",
      " - 11s - loss: 0.6217 - acc: 0.8469\n",
      "Epoch 22/200\n",
      " - 11s - loss: 0.6085 - acc: 0.8511\n",
      "Epoch 23/200\n",
      " - 10s - loss: 0.5577 - acc: 0.8632\n",
      "Epoch 24/200\n",
      " - 10s - loss: 0.7570 - acc: 0.7999\n",
      "Epoch 25/200\n",
      " - 10s - loss: 0.7086 - acc: 0.8041\n",
      "Epoch 26/200\n",
      " - 10s - loss: 0.5641 - acc: 0.8632\n",
      "Epoch 27/200\n",
      " - 10s - loss: 0.4912 - acc: 0.8746\n",
      "Epoch 28/200\n",
      " - 10s - loss: 0.5235 - acc: 0.8654\n",
      "Epoch 29/200\n",
      " - 10s - loss: 0.5207 - acc: 0.8661\n",
      "Epoch 30/200\n",
      " - 10s - loss: 0.4626 - acc: 0.8739\n",
      "Epoch 31/200\n",
      " - 10s - loss: 0.4621 - acc: 0.8896\n",
      "Epoch 32/200\n",
      " - 10s - loss: 0.7031 - acc: 0.8519\n",
      "Epoch 33/200\n",
      " - 10s - loss: 0.4242 - acc: 0.8996\n",
      "Epoch 34/200\n",
      " - 10s - loss: 0.4351 - acc: 0.8967\n",
      "Epoch 35/200\n",
      " - 10s - loss: 0.4001 - acc: 0.8974\n",
      "Epoch 36/200\n",
      " - 11s - loss: 0.3891 - acc: 0.8989\n",
      "Epoch 37/200\n",
      " - 10s - loss: 0.4918 - acc: 0.8967\n",
      "Epoch 38/200\n",
      " - 10s - loss: 0.3973 - acc: 0.9138\n",
      "Epoch 39/200\n",
      " - 10s - loss: 0.3200 - acc: 0.9145\n",
      "Epoch 40/200\n",
      " - 10s - loss: 0.3721 - acc: 0.9145\n",
      "Epoch 41/200\n",
      " - 10s - loss: 0.3816 - acc: 0.9095\n",
      "Epoch 42/200\n",
      " - 11s - loss: 0.3397 - acc: 0.9074\n",
      "Epoch 43/200\n",
      " - 10s - loss: 0.3988 - acc: 0.8903\n",
      "Epoch 44/200\n",
      " - 9s - loss: 0.3760 - acc: 0.9160\n",
      "Epoch 45/200\n",
      " - 10s - loss: 0.3122 - acc: 0.9195\n",
      "Epoch 46/200\n",
      " - 10s - loss: 0.3578 - acc: 0.9010\n",
      "Epoch 47/200\n",
      " - 11s - loss: 0.2881 - acc: 0.9274\n",
      "Epoch 48/200\n",
      " - 10s - loss: 0.4420 - acc: 0.8761\n",
      "Epoch 49/200\n",
      " - 11s - loss: 0.3930 - acc: 0.8939\n",
      "Epoch 50/200\n",
      " - 12s - loss: 0.3316 - acc: 0.9245\n",
      "Epoch 51/200\n",
      " - 10s - loss: 0.2161 - acc: 0.9466\n",
      "Epoch 52/200\n",
      " - 9s - loss: 0.4408 - acc: 0.8960\n",
      "Epoch 53/200\n",
      " - 9s - loss: 0.3957 - acc: 0.8853\n",
      "Epoch 54/200\n",
      " - 9s - loss: 0.2759 - acc: 0.9252\n",
      "Epoch 55/200\n",
      " - 9s - loss: 0.2441 - acc: 0.9373\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 9s - loss: 0.3556 - acc: 0.8910\n",
      "Epoch 57/200\n",
      " - 9s - loss: 0.2461 - acc: 0.9288\n",
      "Epoch 58/200\n",
      " - 9s - loss: 0.2880 - acc: 0.9252\n",
      "Epoch 59/200\n",
      " - 9s - loss: 0.2118 - acc: 0.9359\n",
      "Epoch 60/200\n",
      " - 9s - loss: 0.2168 - acc: 0.9416\n",
      "Epoch 61/200\n",
      " - 9s - loss: 0.3189 - acc: 0.9259\n",
      "Epoch 62/200\n",
      " - 9s - loss: 0.3912 - acc: 0.8761\n",
      "Epoch 63/200\n",
      " - 9s - loss: 0.3575 - acc: 0.8853\n",
      "Epoch 64/200\n",
      " - 10s - loss: 0.1846 - acc: 0.9452\n",
      "Epoch 65/200\n",
      " - 10s - loss: 0.3381 - acc: 0.9181\n",
      "Epoch 66/200\n",
      " - 10s - loss: 0.2210 - acc: 0.9366\n",
      "Epoch 67/200\n",
      " - 10s - loss: 0.1586 - acc: 0.9551\n",
      "Epoch 68/200\n",
      " - 11s - loss: 0.3280 - acc: 0.9224\n",
      "Epoch 69/200\n",
      " - 10s - loss: 0.1699 - acc: 0.9573\n",
      "Epoch 70/200\n",
      " - 10s - loss: 0.1566 - acc: 0.9558\n",
      "Epoch 71/200\n",
      " - 10s - loss: 0.2413 - acc: 0.9352\n",
      "Epoch 72/200\n",
      " - 11s - loss: 0.2137 - acc: 0.9537\n",
      "Epoch 73/200\n",
      " - 11s - loss: 0.1878 - acc: 0.9466\n",
      "Epoch 74/200\n",
      " - 11s - loss: 0.1286 - acc: 0.9651\n",
      "Epoch 75/200\n",
      " - 11s - loss: 0.2709 - acc: 0.9501\n",
      "Epoch 76/200\n",
      " - 10s - loss: 0.1742 - acc: 0.9608\n",
      "Epoch 77/200\n",
      " - 11s - loss: 0.1868 - acc: 0.9530\n",
      "Epoch 78/200\n",
      " - 10s - loss: 0.1449 - acc: 0.9651\n",
      "Epoch 79/200\n",
      " - 11s - loss: 0.1440 - acc: 0.9580\n",
      "Epoch 80/200\n",
      " - 11s - loss: 0.2237 - acc: 0.9487\n",
      "Epoch 81/200\n",
      " - 11s - loss: 0.1839 - acc: 0.9466\n",
      "Epoch 82/200\n",
      " - 10s - loss: 0.1953 - acc: 0.9444\n",
      "Epoch 83/200\n",
      " - 10s - loss: 0.3525 - acc: 0.8989\n",
      "Epoch 84/200\n",
      " - 9s - loss: 0.2289 - acc: 0.9373\n",
      "Epoch 85/200\n",
      " - 9s - loss: 0.2271 - acc: 0.9544\n",
      "Epoch 86/200\n",
      " - 9s - loss: 0.1179 - acc: 0.9679\n",
      "Epoch 87/200\n",
      " - 9s - loss: 0.1380 - acc: 0.9658\n",
      "Epoch 88/200\n",
      " - 9s - loss: 0.1369 - acc: 0.9601\n",
      "Epoch 89/200\n",
      " - 9s - loss: 0.1752 - acc: 0.9516\n",
      "Epoch 90/200\n",
      " - 11s - loss: 0.1220 - acc: 0.9694\n",
      "Epoch 91/200\n",
      " - 12s - loss: 0.1755 - acc: 0.9566\n",
      "Epoch 92/200\n",
      " - 11s - loss: 0.2804 - acc: 0.9487\n",
      "Epoch 93/200\n",
      " - 11s - loss: 0.1528 - acc: 0.9566\n",
      "Epoch 94/200\n",
      " - 11s - loss: 0.1019 - acc: 0.9722\n",
      "Epoch 95/200\n",
      " - 11s - loss: 0.0879 - acc: 0.9808\n",
      "Epoch 96/200\n",
      " - 11s - loss: 0.1302 - acc: 0.9687\n",
      "Epoch 97/200\n",
      " - 11s - loss: 0.1266 - acc: 0.9722\n",
      "Epoch 98/200\n",
      " - 11s - loss: 0.2193 - acc: 0.9452\n",
      "Epoch 99/200\n",
      " - 11s - loss: 0.2581 - acc: 0.9402\n",
      "Epoch 100/200\n",
      " - 11s - loss: 0.1302 - acc: 0.9694\n",
      "Epoch 101/200\n",
      " - 11s - loss: 0.1794 - acc: 0.9551\n",
      "Epoch 102/200\n",
      " - 11s - loss: 0.1390 - acc: 0.9630\n",
      "Epoch 103/200\n",
      " - 11s - loss: 0.1036 - acc: 0.9765\n",
      "Epoch 104/200\n",
      " - 11s - loss: 0.1100 - acc: 0.9772\n",
      "Epoch 105/200\n",
      " - 11s - loss: 0.3683 - acc: 0.9081\n",
      "Epoch 106/200\n",
      " - 11s - loss: 0.2279 - acc: 0.9494\n",
      "Epoch 107/200\n",
      " - 11s - loss: 0.1119 - acc: 0.9793\n",
      "Epoch 108/200\n",
      " - 11s - loss: 0.1935 - acc: 0.9494\n",
      "Epoch 109/200\n",
      " - 11s - loss: 0.0727 - acc: 0.9850\n",
      "Epoch 110/200\n",
      " - 11s - loss: 0.1324 - acc: 0.9722\n",
      "Epoch 111/200\n",
      " - 11s - loss: 0.0934 - acc: 0.9751\n",
      "Epoch 112/200\n",
      " - 11s - loss: 0.1072 - acc: 0.9687\n",
      "Epoch 113/200\n",
      " - 11s - loss: 0.1041 - acc: 0.9779\n",
      "Epoch 114/200\n",
      " - 11s - loss: 0.1057 - acc: 0.9758\n",
      "Epoch 115/200\n",
      " - 11s - loss: 0.1578 - acc: 0.9679\n",
      "Epoch 116/200\n",
      " - 11s - loss: 0.0293 - acc: 0.9936\n",
      "Epoch 117/200\n",
      " - 11s - loss: 0.0701 - acc: 0.9879\n",
      "Epoch 118/200\n",
      " - 11s - loss: 0.0542 - acc: 0.9879\n",
      "Epoch 119/200\n",
      " - 11s - loss: 0.0509 - acc: 0.9879\n",
      "Epoch 120/200\n",
      " - 11s - loss: 0.0135 - acc: 0.9957\n",
      "Epoch 121/200\n",
      " - 11s - loss: 0.0108 - acc: 0.9964\n",
      "Epoch 122/200\n",
      " - 11s - loss: 0.5481 - acc: 0.8839\n",
      "Epoch 123/200\n",
      " - 11s - loss: 0.2101 - acc: 0.9437\n",
      "Epoch 124/200\n",
      " - 11s - loss: 0.1896 - acc: 0.9580\n",
      "Epoch 125/200\n",
      " - 11s - loss: 0.1202 - acc: 0.9744\n",
      "Epoch 126/200\n",
      " - 11s - loss: 0.1305 - acc: 0.9736\n",
      "Epoch 127/200\n",
      " - 11s - loss: 0.4028 - acc: 0.9316\n",
      "Epoch 128/200\n",
      " - 11s - loss: 0.2946 - acc: 0.9302\n",
      "Epoch 129/200\n",
      " - 11s - loss: 0.0962 - acc: 0.9793\n",
      "Epoch 130/200\n",
      " - 11s - loss: 0.0570 - acc: 0.9858\n",
      "Epoch 131/200\n",
      " - 11s - loss: 0.1233 - acc: 0.9793\n",
      "Epoch 132/200\n",
      " - 11s - loss: 0.0681 - acc: 0.9865\n",
      "Epoch 133/200\n",
      " - 11s - loss: 0.0527 - acc: 0.9836\n",
      "Epoch 134/200\n",
      " - 11s - loss: 0.0589 - acc: 0.9843\n",
      "Epoch 135/200\n",
      " - 11s - loss: 0.0890 - acc: 0.9822\n",
      "Epoch 136/200\n",
      " - 11s - loss: 0.0240 - acc: 0.9886\n",
      "Epoch 137/200\n",
      " - 10s - loss: 0.0630 - acc: 0.9872\n",
      "Epoch 138/200\n",
      " - 11s - loss: 0.0180 - acc: 0.9957\n",
      "Epoch 139/200\n",
      " - 11s - loss: 0.0104 - acc: 0.9964\n",
      "Epoch 140/200\n",
      " - 11s - loss: 0.0330 - acc: 0.9922\n",
      "Epoch 141/200\n",
      " - 11s - loss: 0.2678 - acc: 0.9345\n",
      "Epoch 142/200\n",
      " - 11s - loss: 0.0422 - acc: 0.9922\n",
      "Epoch 143/200\n",
      " - 11s - loss: 0.0091 - acc: 0.9972\n",
      "Epoch 144/200\n",
      " - 11s - loss: 0.0058 - acc: 0.9993\n",
      "Epoch 145/200\n",
      " - 11s - loss: 0.0045 - acc: 0.9986\n",
      "Epoch 146/200\n",
      " - 11s - loss: 0.0051 - acc: 0.9986\n",
      "Epoch 147/200\n",
      " - 11s - loss: 0.0091 - acc: 0.9986\n",
      "Epoch 148/200\n",
      " - 11s - loss: 0.0178 - acc: 0.9964\n",
      "Epoch 149/200\n",
      " - 11s - loss: 0.9305 - acc: 0.8412\n",
      "Epoch 150/200\n",
      " - 11s - loss: 0.2634 - acc: 0.9366\n",
      "Epoch 151/200\n",
      " - 11s - loss: 0.4170 - acc: 0.9160\n",
      "Epoch 152/200\n",
      " - 11s - loss: 0.2153 - acc: 0.9615\n",
      "Epoch 153/200\n",
      " - 11s - loss: 0.2934 - acc: 0.9088\n",
      "Epoch 154/200\n",
      " - 11s - loss: 0.2263 - acc: 0.9530\n",
      "Epoch 155/200\n",
      " - 11s - loss: 0.1643 - acc: 0.9672\n",
      "Epoch 156/200\n",
      " - 11s - loss: 0.1620 - acc: 0.9587\n",
      "Epoch 157/200\n",
      " - 11s - loss: 0.0389 - acc: 0.9915\n",
      "Epoch 158/200\n",
      " - 11s - loss: 0.0789 - acc: 0.9815\n",
      "Epoch 159/200\n",
      " - 11s - loss: 0.0728 - acc: 0.9893\n",
      "Epoch 160/200\n",
      " - 11s - loss: 0.0238 - acc: 0.9922\n",
      "Epoch 161/200\n",
      " - 11s - loss: 0.0448 - acc: 0.9929\n",
      "Epoch 162/200\n",
      " - 11s - loss: 0.0100 - acc: 0.9993\n",
      "Epoch 163/200\n",
      " - 11s - loss: 0.0059 - acc: 0.9986\n",
      "Epoch 164/200\n",
      " - 11s - loss: 0.0085 - acc: 0.9972\n",
      "Epoch 165/200\n",
      " - 11s - loss: 0.0040 - acc: 0.9993\n",
      "Epoch 166/200\n",
      " - 11s - loss: 0.0875 - acc: 0.9829\n",
      "Epoch 167/200\n",
      " - 11s - loss: 0.0067 - acc: 0.9993\n",
      "Epoch 168/200\n",
      " - 11s - loss: 0.0033 - acc: 0.9993\n",
      "Epoch 169/200\n",
      " - 11s - loss: 0.0036 - acc: 0.9986\n",
      "Epoch 170/200\n",
      " - 11s - loss: 0.0322 - acc: 0.9907\n",
      "Epoch 171/200\n",
      " - 11s - loss: 0.0029 - acc: 0.9993\n",
      "Epoch 172/200\n",
      " - 11s - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 173/200\n",
      " - 11s - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 174/200\n",
      " - 11s - loss: 0.0013 - acc: 0.9993\n",
      "Epoch 175/200\n",
      " - 11s - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 176/200\n",
      " - 11s - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 177/200\n",
      " - 11s - loss: 0.0025 - acc: 0.9993\n",
      "Epoch 178/200\n",
      " - 11s - loss: 0.0043 - acc: 0.9979\n",
      "Epoch 179/200\n",
      " - 10s - loss: 0.0020 - acc: 0.9993\n",
      "Epoch 180/200\n",
      " - 9s - loss: 0.0042 - acc: 0.9979\n",
      "Epoch 181/200\n",
      " - 10s - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 182/200\n",
      " - 10s - loss: 0.0015 - acc: 0.9993\n",
      "Epoch 183/200\n",
      " - 9s - loss: 8.2235e-04 - acc: 1.0000\n",
      "Epoch 184/200\n",
      " - 9s - loss: 6.1227e-04 - acc: 1.0000\n",
      "Epoch 185/200\n",
      " - 9s - loss: 6.8702e-04 - acc: 1.0000\n",
      "Epoch 186/200\n",
      " - 10s - loss: 6.2008e-04 - acc: 1.0000\n",
      "Epoch 187/200\n",
      " - 11s - loss: 6.7348e-04 - acc: 1.0000\n",
      "Epoch 188/200\n",
      " - 11s - loss: 0.0011 - acc: 0.9993\n",
      "Epoch 189/200\n",
      " - 11s - loss: 5.1648e-04 - acc: 1.0000\n",
      "Epoch 190/200\n",
      " - 11s - loss: 4.8354e-04 - acc: 1.0000\n",
      "Epoch 191/200\n",
      " - 11s - loss: 0.0020 - acc: 0.9993\n",
      "Epoch 192/200\n",
      " - 11s - loss: 4.2156e-04 - acc: 1.0000\n",
      "Epoch 193/200\n",
      " - 11s - loss: 5.2566e-04 - acc: 1.0000\n",
      "Epoch 194/200\n",
      " - 11s - loss: 5.9905e-04 - acc: 1.0000\n",
      "Epoch 195/200\n",
      " - 11s - loss: 5.4395e-04 - acc: 1.0000\n",
      "Epoch 196/200\n",
      " - 11s - loss: 4.0329e-04 - acc: 1.0000\n",
      "Epoch 197/200\n",
      " - 11s - loss: 4.3042e-04 - acc: 1.0000\n",
      "Epoch 198/200\n",
      " - 11s - loss: 4.0696e-04 - acc: 1.0000\n",
      "Epoch 199/200\n",
      " - 11s - loss: 4.2978e-04 - acc: 1.0000\n",
      "Epoch 200/200\n",
      " - 11s - loss: 3.3296e-04 - acc: 1.0000\n",
      "[[250   3   0   0   1   0]\n",
      " [  3 162   0   1   6   0]\n",
      " [  0   1 157   0   0   0]\n",
      " [  0   0   0  20   1   0]\n",
      " [  0   1   0   0  64   3]\n",
      " [  1   0   0   0  10   8]]\n",
      "\n",
      "\n",
      "<class 'keras.engine.sequential.Sequential'>\n",
      "||||| Accuracy : 0.9024088888791977 |||||\n",
      "\n",
      "\n",
      "Best actual accuracy : 0.9116562251885808\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_77 (Dense)             (None, 64)                3496384   \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 50)                3250      \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 6)                 306       \n",
      "=================================================================\n",
      "Total params: 3,510,140\n",
      "Trainable params: 3,510,140\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      " - 3s - loss: 1.8220 - acc: 0.2849\n",
      "Epoch 2/200\n",
      " - 2s - loss: 1.7938 - acc: 0.2849\n",
      "Epoch 3/200\n",
      " - 2s - loss: 1.7804 - acc: 0.3483\n",
      "Epoch 4/200\n",
      " - 2s - loss: 1.7661 - acc: 0.3939\n",
      "Epoch 5/200\n",
      " - 2s - loss: 1.7467 - acc: 0.4323\n",
      "Epoch 6/200\n",
      " - 2s - loss: 1.7163 - acc: 0.4651\n",
      "Epoch 7/200\n",
      " - 2s - loss: 1.6951 - acc: 0.4452\n",
      "Epoch 8/200\n",
      " - 2s - loss: 1.6559 - acc: 0.4772\n",
      "Epoch 9/200\n",
      " - 2s - loss: 1.6381 - acc: 0.5085\n",
      "Epoch 10/200\n",
      " - 2s - loss: 1.6072 - acc: 0.4922\n",
      "Epoch 11/200\n",
      " - 2s - loss: 1.5642 - acc: 0.4943\n",
      "Epoch 12/200\n",
      " - 2s - loss: 1.5691 - acc: 0.4758\n",
      "Epoch 13/200\n",
      " - 2s - loss: 1.8131 - acc: 0.2051\n",
      "Epoch 14/200\n",
      " - 2s - loss: 1.7987 - acc: 0.2058\n",
      "Epoch 15/200\n",
      " - 2s - loss: 1.7984 - acc: 0.2058\n",
      "Epoch 16/200\n",
      " - 2s - loss: 1.7972 - acc: 0.2058\n",
      "Epoch 17/200\n",
      " - 2s - loss: 1.7971 - acc: 0.2051\n",
      "Epoch 18/200\n",
      " - 2s - loss: 1.7958 - acc: 0.2037\n",
      "Epoch 19/200\n",
      " - 2s - loss: 1.7953 - acc: 0.2066\n",
      "Epoch 20/200\n",
      " - 2s - loss: 1.7947 - acc: 0.2030\n",
      "Epoch 21/200\n",
      " - 2s - loss: 1.7946 - acc: 0.2016\n",
      "Epoch 22/200\n",
      " - 2s - loss: 1.7942 - acc: 0.2023\n",
      "Epoch 23/200\n",
      " - 2s - loss: 1.7939 - acc: 0.2016\n",
      "Epoch 24/200\n",
      " - 2s - loss: 1.7928 - acc: 0.1987\n",
      "Epoch 25/200\n",
      " - 2s - loss: 1.7931 - acc: 0.1823\n",
      "Epoch 26/200\n",
      " - 2s - loss: 1.7936 - acc: 0.1873\n",
      "Epoch 27/200\n",
      " - 2s - loss: 1.7929 - acc: 0.1923\n",
      "Epoch 28/200\n",
      " - 2s - loss: 1.7928 - acc: 0.1994\n",
      "Epoch 29/200\n",
      " - 2s - loss: 1.7928 - acc: 0.1916\n",
      "Epoch 30/200\n",
      " - 2s - loss: 1.7929 - acc: 0.1959\n",
      "Epoch 31/200\n",
      " - 2s - loss: 1.7926 - acc: 0.1923\n",
      "Epoch 32/200\n",
      " - 2s - loss: 1.7931 - acc: 0.1781\n",
      "Epoch 33/200\n",
      " - 2s - loss: 1.7922 - acc: 0.1610\n",
      "Epoch 34/200\n",
      " - 2s - loss: 1.7925 - acc: 0.1517\n",
      "Epoch 35/200\n",
      " - 2s - loss: 1.7922 - acc: 0.1496\n",
      "Epoch 36/200\n",
      " - 2s - loss: 1.7921 - acc: 0.1296\n",
      "Epoch 37/200\n",
      " - 2s - loss: 1.7924 - acc: 0.1353\n",
      "Epoch 38/200\n",
      " - 2s - loss: 1.7925 - acc: 0.0848\n",
      "Epoch 39/200\n",
      " - 2s - loss: 1.7924 - acc: 0.1090\n",
      "Epoch 40/200\n",
      " - 2s - loss: 1.7925 - acc: 0.1446\n",
      "Epoch 41/200\n",
      " - 2s - loss: 1.7920 - acc: 0.1296\n",
      "Epoch 42/200\n",
      " - 2s - loss: 1.7925 - acc: 0.1410\n",
      "Epoch 43/200\n",
      " - 2s - loss: 1.7923 - acc: 0.1268\n",
      "Epoch 44/200\n",
      " - 2s - loss: 1.7921 - acc: 0.1189\n",
      "Epoch 45/200\n",
      " - 2s - loss: 1.7918 - acc: 0.0905\n",
      "Epoch 46/200\n",
      " - 2s - loss: 1.7922 - acc: 0.1068\n",
      "Epoch 47/200\n",
      " - 2s - loss: 1.7918 - acc: 0.0848\n",
      "Epoch 48/200\n",
      " - 2s - loss: 1.7920 - acc: 0.0762\n",
      "Epoch 49/200\n",
      " - 2s - loss: 1.7920 - acc: 0.0719\n",
      "Epoch 50/200\n",
      " - 2s - loss: 1.7917 - acc: 0.1061\n",
      "Epoch 51/200\n",
      " - 2s - loss: 1.7921 - acc: 0.0848\n",
      "Epoch 52/200\n",
      " - 2s - loss: 1.7923 - acc: 0.0905\n",
      "Epoch 53/200\n",
      " - 2s - loss: 1.7920 - acc: 0.0712\n",
      "Epoch 54/200\n",
      " - 2s - loss: 1.7917 - acc: 0.0947\n",
      "Epoch 55/200\n",
      " - 2s - loss: 1.7923 - acc: 0.0855\n",
      "Epoch 56/200\n",
      " - 2s - loss: 1.7916 - acc: 0.0805\n",
      "Epoch 57/200\n",
      " - 2s - loss: 1.7926 - acc: 0.0627\n",
      "Epoch 58/200\n",
      " - 2s - loss: 1.7921 - acc: 0.0634\n",
      "Epoch 59/200\n",
      " - 2s - loss: 1.7923 - acc: 0.0855\n",
      "Epoch 60/200\n",
      " - 2s - loss: 1.7922 - acc: 0.0662\n",
      "Epoch 61/200\n",
      " - 2s - loss: 1.7923 - acc: 0.0876\n",
      "Epoch 62/200\n",
      " - 2s - loss: 1.7923 - acc: 0.1168\n",
      "Epoch 63/200\n",
      " - 2s - loss: 1.7920 - acc: 0.0755\n",
      "Epoch 64/200\n",
      " - 2s - loss: 1.7919 - acc: 0.0698\n",
      "Epoch 65/200\n",
      " - 2s - loss: 1.7920 - acc: 0.1033\n",
      "Epoch 66/200\n",
      " - 2s - loss: 1.7920 - acc: 0.0805\n",
      "Epoch 67/200\n",
      " - 2s - loss: 1.7923 - acc: 0.1019\n",
      "Epoch 68/200\n",
      " - 2s - loss: 1.7919 - acc: 0.1118\n",
      "Epoch 69/200\n",
      " - 2s - loss: 1.7919 - acc: 0.1246\n",
      "Epoch 70/200\n",
      " - 2s - loss: 1.7920 - acc: 0.1268\n",
      "Epoch 71/200\n",
      " - 2s - loss: 1.7921 - acc: 0.1147\n",
      "Epoch 72/200\n",
      " - 2s - loss: 1.7918 - acc: 0.1232\n",
      "Epoch 73/200\n",
      " - 2s - loss: 1.7923 - acc: 0.1289\n",
      "Epoch 74/200\n",
      " - 2s - loss: 1.7919 - acc: 0.0940\n",
      "Epoch 75/200\n",
      " - 2s - loss: 1.7924 - acc: 0.1004\n",
      "Epoch 76/200\n",
      " - 2s - loss: 1.7921 - acc: 0.1261\n",
      "Epoch 77/200\n",
      " - 2s - loss: 1.7922 - acc: 0.1125\n",
      "Epoch 78/200\n",
      " - 2s - loss: 1.7924 - acc: 0.1161\n",
      "Epoch 79/200\n",
      " - 2s - loss: 1.7924 - acc: 0.0983\n",
      "Epoch 80/200\n",
      " - 2s - loss: 1.7919 - acc: 0.1246\n",
      "Epoch 81/200\n",
      " - 2s - loss: 1.7921 - acc: 0.1140\n",
      "Epoch 82/200\n",
      " - 2s - loss: 1.7921 - acc: 0.1189\n",
      "Epoch 83/200\n",
      " - 2s - loss: 1.7921 - acc: 0.0912\n",
      "Epoch 84/200\n",
      " - 2s - loss: 1.7919 - acc: 0.0634\n",
      "Epoch 85/200\n",
      " - 2s - loss: 1.7921 - acc: 0.1232\n",
      "Epoch 86/200\n",
      " - 2s - loss: 1.7919 - acc: 0.0798\n",
      "Epoch 87/200\n",
      " - 2s - loss: 1.7922 - acc: 0.0684\n",
      "Epoch 88/200\n",
      " - 2s - loss: 1.7920 - acc: 0.0969\n",
      "Epoch 89/200\n",
      " - 2s - loss: 1.7924 - acc: 0.0962\n",
      "Epoch 90/200\n",
      " - 2s - loss: 1.7922 - acc: 0.1268\n",
      "Epoch 91/200\n",
      " - 2s - loss: 1.7921 - acc: 0.0848\n",
      "Epoch 92/200\n",
      " - 2s - loss: 1.7918 - acc: 0.1161\n",
      "Epoch 93/200\n",
      " - 2s - loss: 1.7920 - acc: 0.0926\n",
      "Epoch 94/200\n",
      " - 2s - loss: 1.7920 - acc: 0.1026\n",
      "Epoch 95/200\n",
      " - 2s - loss: 1.7919 - acc: 0.1460\n",
      "Epoch 96/200\n",
      " - 2s - loss: 1.7918 - acc: 0.1140\n",
      "Epoch 97/200\n",
      " - 2s - loss: 1.7923 - acc: 0.1090\n",
      "Epoch 98/200\n",
      " - 2s - loss: 1.7921 - acc: 0.1168\n",
      "Epoch 99/200\n",
      " - 2s - loss: 1.7921 - acc: 0.1410\n",
      "Epoch 100/200\n",
      " - 2s - loss: 1.7924 - acc: 0.0969\n",
      "Epoch 101/200\n",
      " - 2s - loss: 1.7919 - acc: 0.1047\n",
      "Epoch 102/200\n",
      " - 2s - loss: 1.7919 - acc: 0.1595\n",
      "Epoch 103/200\n",
      " - 2s - loss: 1.7918 - acc: 0.1759\n",
      "Epoch 104/200\n",
      " - 2s - loss: 1.7919 - acc: 0.1496\n",
      "Epoch 105/200\n",
      " - 2s - loss: 1.7918 - acc: 0.1232\n",
      "Epoch 106/200\n",
      " - 2s - loss: 1.7922 - acc: 0.1432\n",
      "Epoch 107/200\n",
      " - 2s - loss: 1.7919 - acc: 0.1318\n",
      "Epoch 108/200\n",
      " - 2s - loss: 1.7921 - acc: 0.1531\n",
      "Epoch 109/200\n",
      " - 2s - loss: 1.7919 - acc: 0.1603\n",
      "Epoch 110/200\n",
      " - 2s - loss: 1.7920 - acc: 0.1389\n",
      "Epoch 111/200\n",
      " - 2s - loss: 1.7921 - acc: 0.1075\n",
      "Epoch 112/200\n",
      " - 2s - loss: 1.7918 - acc: 0.1944\n",
      "Epoch 113/200\n",
      " - 2s - loss: 1.7920 - acc: 0.1353\n",
      "Epoch 114/200\n",
      " - 2s - loss: 1.7918 - acc: 0.1660\n",
      "Epoch 115/200\n",
      " - 2s - loss: 1.7918 - acc: 0.1410\n",
      "Epoch 116/200\n",
      " - 2s - loss: 1.7919 - acc: 0.1211\n",
      "Epoch 117/200\n",
      " - 2s - loss: 1.7922 - acc: 0.1745\n",
      "Epoch 118/200\n",
      " - 2s - loss: 1.7920 - acc: 0.0769\n",
      "Epoch 119/200\n",
      " - 2s - loss: 1.7920 - acc: 0.1332\n",
      "Epoch 120/200\n",
      " - 2s - loss: 1.7918 - acc: 0.1019\n",
      "Epoch 121/200\n",
      " - 2s - loss: 1.7922 - acc: 0.1125\n",
      "Epoch 122/200\n",
      " - 2s - loss: 1.7923 - acc: 0.1225\n",
      "Epoch 123/200\n",
      " - 2s - loss: 1.7920 - acc: 0.1368\n",
      "Epoch 124/200\n",
      " - 2s - loss: 1.7921 - acc: 0.0869\n",
      "Epoch 125/200\n",
      " - 2s - loss: 1.7919 - acc: 0.1140\n",
      "Epoch 126/200\n",
      " - 2s - loss: 1.7920 - acc: 0.1318\n",
      "Epoch 127/200\n",
      " - 2s - loss: 1.7919 - acc: 0.1019\n",
      "Epoch 128/200\n",
      " - 2s - loss: 1.7921 - acc: 0.0848\n",
      "Epoch 129/200\n",
      " - 2s - loss: 1.7919 - acc: 0.0869\n",
      "Epoch 130/200\n",
      " - 2s - loss: 1.7919 - acc: 0.1318\n",
      "Epoch 131/200\n",
      " - 2s - loss: 1.7920 - acc: 0.1774\n",
      "Epoch 132/200\n",
      " - 2s - loss: 1.7919 - acc: 0.1154\n",
      "Epoch 133/200\n",
      " - 2s - loss: 1.7922 - acc: 0.1318\n",
      "Epoch 134/200\n",
      " - 2s - loss: 1.7920 - acc: 0.0805\n",
      "Epoch 135/200\n",
      " - 2s - loss: 1.7920 - acc: 0.0912\n",
      "Epoch 136/200\n",
      " - 2s - loss: 1.7921 - acc: 0.0997\n",
      "Epoch 137/200\n",
      " - 2s - loss: 1.7918 - acc: 0.1396\n",
      "Epoch 138/200\n",
      " - 2s - loss: 1.7918 - acc: 0.0905\n",
      "Epoch 139/200\n",
      " - 2s - loss: 1.7918 - acc: 0.0741\n",
      "Epoch 140/200\n",
      " - 2s - loss: 1.7920 - acc: 0.1425\n",
      "Epoch 141/200\n",
      " - 2s - loss: 1.7919 - acc: 0.1097\n",
      "Epoch 142/200\n",
      " - 2s - loss: 1.7919 - acc: 0.1019\n",
      "Epoch 143/200\n",
      " - 2s - loss: 1.7917 - acc: 0.1802\n",
      "Epoch 144/200\n",
      " - 2s - loss: 1.7919 - acc: 0.1638\n",
      "Epoch 145/200\n",
      " - 2s - loss: 1.7918 - acc: 0.1688\n",
      "Epoch 146/200\n",
      " - 2s - loss: 1.7919 - acc: 0.1339\n",
      "Epoch 147/200\n",
      " - 2s - loss: 1.7919 - acc: 0.1218\n",
      "Epoch 148/200\n",
      " - 2s - loss: 1.7920 - acc: 0.1510\n",
      "Epoch 149/200\n",
      " - 2s - loss: 1.7917 - acc: 0.1432\n",
      "Epoch 150/200\n",
      " - 2s - loss: 1.7918 - acc: 0.1489\n",
      "Epoch 151/200\n",
      " - 2s - loss: 1.7918 - acc: 0.1503\n",
      "Epoch 152/200\n",
      " - 2s - loss: 1.7920 - acc: 0.1823\n",
      "Epoch 153/200\n",
      " - 2s - loss: 1.7918 - acc: 0.1346\n",
      "Epoch 154/200\n",
      " - 2s - loss: 1.7920 - acc: 0.1546\n",
      "Epoch 155/200\n",
      " - 2s - loss: 1.7916 - acc: 0.1830\n",
      "Epoch 156/200\n",
      " - 2s - loss: 1.7919 - acc: 0.1788\n",
      "Epoch 157/200\n",
      " - 2s - loss: 1.7918 - acc: 0.1389\n",
      "Epoch 158/200\n",
      " - 2s - loss: 1.7916 - acc: 0.1788\n",
      "Epoch 159/200\n",
      " - 2s - loss: 1.7918 - acc: 0.1674\n",
      "Epoch 160/200\n",
      " - 2s - loss: 1.7919 - acc: 0.1474\n",
      "Epoch 161/200\n",
      " - 2s - loss: 1.7919 - acc: 0.2251\n",
      "Epoch 162/200\n",
      " - 2s - loss: 1.7918 - acc: 0.1937\n",
      "Epoch 163/200\n",
      " - 2s - loss: 1.7922 - acc: 0.1745\n",
      "Epoch 164/200\n",
      " - 2s - loss: 1.7920 - acc: 0.2087\n",
      "Epoch 165/200\n",
      " - 2s - loss: 1.7920 - acc: 0.1346\n",
      "Epoch 166/200\n",
      " - 2s - loss: 1.7919 - acc: 0.1624\n",
      "Epoch 167/200\n",
      " - 2s - loss: 1.7920 - acc: 0.1887\n",
      "Epoch 168/200\n",
      " - 2s - loss: 1.7918 - acc: 0.1660\n",
      "Epoch 169/200\n",
      " - 2s - loss: 1.7919 - acc: 0.1261\n",
      "Epoch 170/200\n",
      " - 2s - loss: 1.7918 - acc: 0.1553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/200\n",
      " - 2s - loss: 1.7917 - acc: 0.1681\n",
      "Epoch 172/200\n",
      " - 2s - loss: 1.7919 - acc: 0.1481\n",
      "Epoch 173/200\n",
      " - 2s - loss: 1.7918 - acc: 0.1660\n",
      "Epoch 174/200\n",
      " - 2s - loss: 1.7920 - acc: 0.1425\n",
      "Epoch 175/200\n",
      " - 2s - loss: 1.7919 - acc: 0.1417\n",
      "Epoch 176/200\n",
      " - 2s - loss: 1.7919 - acc: 0.1745\n",
      "Epoch 177/200\n",
      " - 2s - loss: 1.7920 - acc: 0.1097\n",
      "Epoch 178/200\n",
      " - 2s - loss: 1.7921 - acc: 0.1097\n",
      "Epoch 179/200\n",
      " - 2s - loss: 1.7920 - acc: 0.1325\n",
      "Epoch 180/200\n",
      " - 2s - loss: 1.7920 - acc: 0.1168\n",
      "Epoch 181/200\n",
      " - 2s - loss: 1.7920 - acc: 0.1239\n",
      "Epoch 182/200\n",
      " - 2s - loss: 1.7917 - acc: 0.1638\n",
      "Epoch 183/200\n",
      " - 2s - loss: 1.7921 - acc: 0.1083\n",
      "Epoch 184/200\n",
      " - 2s - loss: 1.7921 - acc: 0.1453\n",
      "Epoch 185/200\n",
      " - 2s - loss: 1.7919 - acc: 0.0969\n",
      "Epoch 186/200\n",
      " - 2s - loss: 1.7917 - acc: 0.1638\n",
      "Epoch 187/200\n",
      " - 2s - loss: 1.7918 - acc: 0.1097\n",
      "Epoch 188/200\n",
      " - 2s - loss: 1.7917 - acc: 0.1567\n",
      "Epoch 189/200\n",
      " - 2s - loss: 1.7921 - acc: 0.1496\n",
      "Epoch 190/200\n",
      " - 2s - loss: 1.7921 - acc: 0.1097\n",
      "Epoch 191/200\n",
      " - 2s - loss: 1.7919 - acc: 0.0933\n",
      "Epoch 192/200\n",
      " - 2s - loss: 1.7920 - acc: 0.0876\n",
      "Epoch 193/200\n",
      " - 2s - loss: 1.7919 - acc: 0.2179\n",
      "Epoch 194/200\n",
      " - 2s - loss: 1.7917 - acc: 0.1353\n",
      "Epoch 195/200\n",
      " - 2s - loss: 1.7922 - acc: 0.1289\n",
      "Epoch 196/200\n",
      " - 2s - loss: 1.7919 - acc: 0.1389\n",
      "Epoch 197/200\n",
      " - 2s - loss: 1.7919 - acc: 0.1588\n",
      "Epoch 198/200\n",
      " - 2s - loss: 1.7914 - acc: 0.1845\n",
      "Epoch 199/200\n",
      " - 2s - loss: 1.7918 - acc: 0.1417\n",
      "Epoch 200/200\n",
      " - 2s - loss: 1.7920 - acc: 0.1339\n",
      "[[  0   0   0   0 254   0]\n",
      " [  0   0   0   0 172   0]\n",
      " [  0   0   0   0 158   0]\n",
      " [  0   0   0   0  21   0]\n",
      " [  0   0   0   0  68   0]\n",
      " [  0   0   0   0  19   0]]\n",
      "\n",
      "\n",
      "<class 'keras.engine.sequential.Sequential'>\n",
      "||||| Accuracy : 0.016377649325626204 |||||\n",
      "\n",
      "\n",
      "Best actual accuracy : 0.9116562251885808\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_84 (Dense)             (None, 64)                3496384   \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 100)               6500      \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 3,543,890\n",
      "Trainable params: 3,543,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training...\n",
      "Epoch 1/200\n",
      " - 3s - loss: 1.8117 - acc: 0.1624\n",
      "Epoch 2/200\n",
      " - 2s - loss: 1.8040 - acc: 0.1375\n",
      "Epoch 3/200\n",
      " - 2s - loss: 1.8004 - acc: 0.1510\n",
      "Epoch 4/200\n",
      " - 2s - loss: 1.7919 - acc: 0.1709\n",
      "Epoch 5/200\n",
      " - 2s - loss: 1.7821 - acc: 0.1759\n",
      "Epoch 6/200\n",
      " - 2s - loss: 1.7545 - acc: 0.2080\n",
      "Epoch 7/200\n",
      " - 2s - loss: 1.6569 - acc: 0.2963\n",
      "Epoch 8/200\n",
      " - 2s - loss: 1.4775 - acc: 0.3390\n",
      "Epoch 9/200\n",
      " - 2s - loss: 1.3691 - acc: 0.3846\n",
      "Epoch 10/200\n",
      " - 2s - loss: 1.3194 - acc: 0.4231\n",
      "Epoch 11/200\n",
      " - 2s - loss: 1.3810 - acc: 0.3917\n",
      "Epoch 12/200\n",
      " - 2s - loss: 1.2515 - acc: 0.4879\n",
      "Epoch 13/200\n",
      " - 2s - loss: 1.1772 - acc: 0.5356\n",
      "Epoch 14/200\n",
      " - 2s - loss: 1.1881 - acc: 0.5463\n",
      "Epoch 15/200\n",
      " - 2s - loss: 1.0812 - acc: 0.5933\n",
      "Epoch 16/200\n",
      " - 2s - loss: 1.0947 - acc: 0.6118\n",
      "Epoch 17/200\n",
      " - 2s - loss: 1.0096 - acc: 0.6688\n",
      "Epoch 18/200\n",
      " - 2s - loss: 0.9278 - acc: 0.7016\n",
      "Epoch 19/200\n",
      " - 2s - loss: 1.0453 - acc: 0.6631\n",
      "Epoch 20/200\n",
      " - 2s - loss: 0.9016 - acc: 0.7222\n",
      "Epoch 21/200\n",
      " - 2s - loss: 1.0762 - acc: 0.7073\n",
      "Epoch 22/200\n",
      " - 2s - loss: 0.9164 - acc: 0.7479\n",
      "Epoch 23/200\n",
      " - 2s - loss: 0.8926 - acc: 0.7457\n",
      "Epoch 24/200\n",
      " - 2s - loss: 0.8382 - acc: 0.7628\n",
      "Epoch 25/200\n",
      " - 2s - loss: 0.8949 - acc: 0.7393\n",
      "Epoch 26/200\n",
      " - 2s - loss: 0.8028 - acc: 0.7906\n",
      "Epoch 27/200\n",
      " - 2s - loss: 0.7459 - acc: 0.8283\n",
      "Epoch 28/200\n",
      " - 2s - loss: 0.7543 - acc: 0.8113\n",
      "Epoch 29/200\n",
      " - 2s - loss: 0.9167 - acc: 0.7614\n",
      "Epoch 30/200\n",
      " - 2s - loss: 0.7621 - acc: 0.8184\n",
      "Epoch 31/200\n",
      " - 2s - loss: 0.7675 - acc: 0.7991\n",
      "Epoch 32/200\n",
      " - 2s - loss: 0.7723 - acc: 0.8184\n",
      "Epoch 33/200\n",
      " - 2s - loss: 0.7979 - acc: 0.8006\n",
      "Epoch 34/200\n",
      " - 2s - loss: 0.7197 - acc: 0.8583\n",
      "Epoch 35/200\n",
      " - 2s - loss: 0.8458 - acc: 0.8006\n",
      "Epoch 36/200\n",
      " - 2s - loss: 0.7981 - acc: 0.7913\n",
      "Epoch 37/200\n",
      " - 2s - loss: 0.7109 - acc: 0.8454\n",
      "Epoch 38/200\n",
      " - 2s - loss: 0.7304 - acc: 0.8390\n",
      "Epoch 39/200\n",
      " - 2s - loss: 0.7432 - acc: 0.8447\n",
      "Epoch 40/200\n",
      " - 2s - loss: 0.7384 - acc: 0.8248\n",
      "Epoch 41/200\n",
      " - 2s - loss: 0.7080 - acc: 0.8575\n",
      "Epoch 42/200\n",
      " - 2s - loss: 0.6959 - acc: 0.8575\n",
      "Epoch 43/200\n",
      " - 2s - loss: 0.6674 - acc: 0.8583\n",
      "Epoch 44/200\n",
      " - 2s - loss: 0.6848 - acc: 0.8462\n",
      "Epoch 45/200\n",
      " - 2s - loss: 0.6966 - acc: 0.8590\n",
      "Epoch 46/200\n",
      " - 2s - loss: 0.6909 - acc: 0.8661\n",
      "Epoch 47/200\n",
      " - 2s - loss: 0.6718 - acc: 0.8725\n",
      "Epoch 48/200\n",
      " - 2s - loss: 0.6797 - acc: 0.8561\n",
      "Epoch 49/200\n",
      " - 2s - loss: 0.6525 - acc: 0.8675\n",
      "Epoch 50/200\n",
      " - 2s - loss: 0.6622 - acc: 0.8711\n",
      "Epoch 51/200\n",
      " - 2s - loss: 0.8620 - acc: 0.7934\n",
      "Epoch 52/200\n",
      " - 2s - loss: 0.6646 - acc: 0.8725\n",
      "Epoch 53/200\n",
      " - 2s - loss: 0.6796 - acc: 0.8697\n",
      "Epoch 54/200\n",
      " - 2s - loss: 0.6523 - acc: 0.8647\n",
      "Epoch 55/200\n",
      " - 2s - loss: 0.6736 - acc: 0.8568\n",
      "Epoch 56/200\n",
      " - 2s - loss: 0.6497 - acc: 0.8604\n",
      "Epoch 57/200\n",
      " - 2s - loss: 0.6747 - acc: 0.8704\n",
      "Epoch 58/200\n",
      " - 2s - loss: 0.6168 - acc: 0.8839\n",
      "Epoch 59/200\n",
      " - 2s - loss: 0.6452 - acc: 0.8725\n",
      "Epoch 60/200\n",
      " - 2s - loss: 0.6526 - acc: 0.8768\n",
      "Epoch 61/200\n",
      " - 2s - loss: 0.6526 - acc: 0.8718\n",
      "Epoch 62/200\n",
      " - 2s - loss: 0.6757 - acc: 0.8739\n",
      "Epoch 63/200\n",
      " - 2s - loss: 0.6228 - acc: 0.8811\n",
      "Epoch 64/200\n",
      " - 2s - loss: 0.8241 - acc: 0.8063\n",
      "Epoch 65/200\n",
      " - 2s - loss: 0.6423 - acc: 0.8846\n",
      "Epoch 66/200\n",
      " - 2s - loss: 0.6298 - acc: 0.8732\n",
      "Epoch 67/200\n",
      " - 2s - loss: 0.6593 - acc: 0.8661\n",
      "Epoch 68/200\n",
      " - 2s - loss: 0.6834 - acc: 0.8625\n",
      "Epoch 69/200\n",
      " - 2s - loss: 0.6257 - acc: 0.8754\n",
      "Epoch 70/200\n",
      " - 2s - loss: 0.6652 - acc: 0.8647\n",
      "Epoch 71/200\n",
      " - 2s - loss: 0.6587 - acc: 0.8668\n",
      "Epoch 72/200\n",
      " - 2s - loss: 0.6761 - acc: 0.8561\n",
      "Epoch 73/200\n",
      " - 2s - loss: 0.6621 - acc: 0.8604\n",
      "Epoch 74/200\n",
      " - 2s - loss: 0.6167 - acc: 0.8761\n",
      "Epoch 75/200\n",
      " - 2s - loss: 0.6824 - acc: 0.8497\n",
      "Epoch 76/200\n",
      " - 2s - loss: 0.6249 - acc: 0.8832\n",
      "Epoch 77/200\n",
      " - 2s - loss: 0.6068 - acc: 0.8739\n",
      "Epoch 78/200\n",
      " - 2s - loss: 0.6152 - acc: 0.8704\n",
      "Epoch 79/200\n",
      " - 2s - loss: 0.6075 - acc: 0.8882\n",
      "Epoch 80/200\n",
      " - 2s - loss: 0.6821 - acc: 0.8711\n",
      "Epoch 81/200\n",
      " - 2s - loss: 0.7646 - acc: 0.7792\n",
      "Epoch 82/200\n",
      " - 2s - loss: 0.6567 - acc: 0.8682\n",
      "Epoch 83/200\n",
      " - 2s - loss: 0.6210 - acc: 0.8768\n",
      "Epoch 84/200\n",
      " - 2s - loss: 0.6059 - acc: 0.8875\n",
      "Epoch 85/200\n",
      " - 2s - loss: 0.5885 - acc: 0.8889\n",
      "Epoch 86/200\n",
      " - 2s - loss: 0.6669 - acc: 0.8668\n",
      "Epoch 87/200\n",
      " - 2s - loss: 0.5988 - acc: 0.8860\n",
      "Epoch 88/200\n",
      " - 2s - loss: 0.5834 - acc: 0.8925\n",
      "Epoch 89/200\n",
      " - 2s - loss: 0.6244 - acc: 0.8818\n",
      "Epoch 90/200\n",
      " - 2s - loss: 0.7020 - acc: 0.8340\n",
      "Epoch 91/200\n",
      " - 2s - loss: 0.6183 - acc: 0.8818\n",
      "Epoch 92/200\n",
      " - 2s - loss: 0.8010 - acc: 0.7942\n",
      "Epoch 93/200\n",
      " - 2s - loss: 0.6191 - acc: 0.8754\n",
      "Epoch 94/200\n",
      " - 2s - loss: 0.6011 - acc: 0.8761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/200\n",
      " - 2s - loss: 0.6024 - acc: 0.8796\n",
      "Epoch 96/200\n",
      " - 2s - loss: 0.6061 - acc: 0.8732\n",
      "Epoch 97/200\n",
      " - 2s - loss: 0.6665 - acc: 0.8305\n",
      "Epoch 98/200\n",
      " - 2s - loss: 0.5797 - acc: 0.8768\n",
      "Epoch 99/200\n",
      " - 2s - loss: 0.5764 - acc: 0.8917\n",
      "Epoch 100/200\n",
      " - 2s - loss: 0.5743 - acc: 0.8939\n",
      "Epoch 101/200\n",
      " - 2s - loss: 0.6114 - acc: 0.8640\n",
      "Epoch 102/200\n",
      " - 2s - loss: 0.5756 - acc: 0.9003\n",
      "Epoch 103/200\n",
      " - 2s - loss: 0.5930 - acc: 0.8818\n",
      "Epoch 104/200\n",
      " - 2s - loss: 0.6300 - acc: 0.8590\n",
      "Epoch 105/200\n",
      " - 2s - loss: 0.5874 - acc: 0.8860\n",
      "Epoch 106/200\n",
      " - 2s - loss: 0.5652 - acc: 0.8875\n",
      "Epoch 107/200\n",
      " - 2s - loss: 0.5667 - acc: 0.8917\n",
      "Epoch 108/200\n",
      " - 2s - loss: 0.6178 - acc: 0.8497\n",
      "Epoch 109/200\n",
      " - 2s - loss: 0.5731 - acc: 0.8796\n",
      "Epoch 110/200\n",
      " - 2s - loss: 0.6239 - acc: 0.8561\n",
      "Epoch 111/200\n",
      " - 2s - loss: 0.6360 - acc: 0.8654\n",
      "Epoch 112/200\n",
      " - 2s - loss: 0.5782 - acc: 0.8832\n",
      "Epoch 113/200\n",
      " - 2s - loss: 0.5343 - acc: 0.9010\n",
      "Epoch 114/200\n",
      " - 2s - loss: 0.5907 - acc: 0.8654\n",
      "Epoch 115/200\n",
      " - 2s - loss: 0.7234 - acc: 0.8248\n",
      "Epoch 116/200\n",
      " - 2s - loss: 0.5738 - acc: 0.8746\n",
      "Epoch 117/200\n",
      " - 2s - loss: 0.5823 - acc: 0.8661\n",
      "Epoch 118/200\n",
      " - 2s - loss: 0.5599 - acc: 0.8917\n",
      "Epoch 119/200\n",
      " - 2s - loss: 0.5425 - acc: 0.8860\n",
      "Epoch 120/200\n",
      " - 2s - loss: 0.6075 - acc: 0.8618\n",
      "Epoch 121/200\n",
      " - 2s - loss: 0.5043 - acc: 0.9074\n",
      "Epoch 122/200\n",
      " - 2s - loss: 0.5122 - acc: 0.8896\n",
      "Epoch 123/200\n",
      " - 2s - loss: 0.5003 - acc: 0.8946\n",
      "Epoch 124/200\n",
      " - 2s - loss: 0.5367 - acc: 0.8839\n",
      "Epoch 125/200\n",
      " - 2s - loss: 0.5253 - acc: 0.8889\n",
      "Epoch 126/200\n",
      " - 2s - loss: 0.5156 - acc: 0.8853\n",
      "Epoch 127/200\n",
      " - 2s - loss: 0.5432 - acc: 0.8860\n",
      "Epoch 128/200\n",
      " - 2s - loss: 0.4462 - acc: 0.9117\n",
      "Epoch 129/200\n",
      " - 2s - loss: 0.6171 - acc: 0.8782\n",
      "Epoch 130/200\n",
      " - 2s - loss: 0.6044 - acc: 0.8754\n",
      "Epoch 131/200\n",
      " - 2s - loss: 0.5207 - acc: 0.8789\n",
      "Epoch 132/200\n",
      " - 2s - loss: 0.4702 - acc: 0.8939\n",
      "Epoch 133/200\n",
      " - 2s - loss: 0.4881 - acc: 0.8996\n",
      "Epoch 134/200\n",
      " - 2s - loss: 0.5574 - acc: 0.8732\n",
      "Epoch 135/200\n",
      " - 2s - loss: 0.4720 - acc: 0.9003\n",
      "Epoch 136/200\n",
      " - 2s - loss: 0.4610 - acc: 0.8996\n",
      "Epoch 137/200\n",
      " - 2s - loss: 0.4697 - acc: 0.8996\n",
      "Epoch 138/200\n",
      " - 2s - loss: 0.4883 - acc: 0.8889\n",
      "Epoch 139/200\n",
      " - 2s - loss: 0.4539 - acc: 0.9088\n",
      "Epoch 140/200\n",
      " - 2s - loss: 0.4403 - acc: 0.8960\n",
      "Epoch 141/200\n",
      " - 2s - loss: 0.5249 - acc: 0.8825\n",
      "Epoch 142/200\n",
      " - 2s - loss: 0.5011 - acc: 0.8882\n",
      "Epoch 143/200\n",
      " - 2s - loss: 0.4520 - acc: 0.9060\n",
      "Epoch 144/200\n",
      " - 2s - loss: 0.4043 - acc: 0.9081\n",
      "Epoch 145/200\n",
      " - 2s - loss: 0.4465 - acc: 0.9117\n",
      "Epoch 146/200\n",
      " - 2s - loss: 0.5420 - acc: 0.8746\n",
      "Epoch 147/200\n",
      " - 2s - loss: 0.5377 - acc: 0.8782\n",
      "Epoch 148/200\n",
      " - 2s - loss: 0.4183 - acc: 0.9103\n",
      "Epoch 149/200\n",
      " - 2s - loss: 0.5246 - acc: 0.8796\n",
      "Epoch 150/200\n",
      " - 2s - loss: 0.5657 - acc: 0.8561\n",
      "Epoch 151/200\n",
      " - 2s - loss: 0.4605 - acc: 0.9003\n",
      "Epoch 152/200\n",
      " - 2s - loss: 0.4233 - acc: 0.9110\n",
      "Epoch 153/200\n",
      " - 2s - loss: 0.3955 - acc: 0.9081\n",
      "Epoch 154/200\n",
      " - 2s - loss: 0.3849 - acc: 0.9031\n",
      "Epoch 155/200\n",
      " - 2s - loss: 0.3402 - acc: 0.9209\n",
      "Epoch 156/200\n",
      " - 2s - loss: 0.7088 - acc: 0.8340\n",
      "Epoch 157/200\n",
      " - 2s - loss: 0.4466 - acc: 0.9031\n",
      "Epoch 158/200\n",
      " - 2s - loss: 0.5638 - acc: 0.8725\n",
      "Epoch 159/200\n",
      " - 2s - loss: 0.3605 - acc: 0.9167\n",
      "Epoch 160/200\n",
      " - 2s - loss: 0.3557 - acc: 0.9138\n",
      "Epoch 161/200\n",
      " - 2s - loss: 0.4332 - acc: 0.9010\n",
      "Epoch 162/200\n",
      " - 2s - loss: 0.3601 - acc: 0.9160\n",
      "Epoch 163/200\n",
      " - 2s - loss: 0.3803 - acc: 0.9252\n",
      "Epoch 164/200\n",
      " - 2s - loss: 0.3783 - acc: 0.9167\n",
      "Epoch 165/200\n",
      " - 2s - loss: 0.3863 - acc: 0.9209\n",
      "Epoch 166/200\n",
      " - 2s - loss: 0.4286 - acc: 0.9010\n",
      "Epoch 167/200\n",
      " - 2s - loss: 0.3167 - acc: 0.9266\n",
      "Epoch 168/200\n",
      " - 2s - loss: 0.4210 - acc: 0.8996\n",
      "Epoch 169/200\n",
      " - 2s - loss: 0.3089 - acc: 0.9231\n",
      "Epoch 170/200\n",
      " - 2s - loss: 0.4709 - acc: 0.8860\n",
      "Epoch 171/200\n",
      " - 2s - loss: 0.3794 - acc: 0.9017\n",
      "Epoch 172/200\n",
      " - 2s - loss: 0.3274 - acc: 0.9231\n",
      "Epoch 173/200\n",
      " - 2s - loss: 0.5850 - acc: 0.8283\n",
      "Epoch 174/200\n",
      " - 2s - loss: 0.3518 - acc: 0.9252\n",
      "Epoch 175/200\n",
      " - 2s - loss: 0.3489 - acc: 0.9152\n",
      "Epoch 176/200\n",
      " - 2s - loss: 0.3814 - acc: 0.9167\n",
      "Epoch 177/200\n",
      " - 2s - loss: 0.3063 - acc: 0.9288\n",
      "Epoch 178/200\n",
      " - 2s - loss: 1.3194 - acc: 0.7308\n",
      "Epoch 179/200\n",
      " - 2s - loss: 0.7837 - acc: 0.6752\n",
      "Epoch 180/200\n",
      " - 2s - loss: 0.5030 - acc: 0.8597\n",
      "Epoch 181/200\n",
      " - 2s - loss: 0.3883 - acc: 0.9024\n",
      "Epoch 182/200\n",
      " - 2s - loss: 0.3593 - acc: 0.9281\n",
      "Epoch 183/200\n",
      " - 2s - loss: 0.4081 - acc: 0.8846\n",
      "Epoch 184/200\n",
      " - 2s - loss: 0.3497 - acc: 0.9238\n",
      "Epoch 185/200\n",
      " - 2s - loss: 0.3471 - acc: 0.9224\n",
      "Epoch 186/200\n",
      " - 2s - loss: 0.4080 - acc: 0.9160\n",
      "Epoch 187/200\n",
      " - 2s - loss: 0.3735 - acc: 0.9160\n",
      "Epoch 188/200\n",
      " - 2s - loss: 0.4978 - acc: 0.8875\n",
      "Epoch 189/200\n",
      " - 2s - loss: 0.4038 - acc: 0.9209\n",
      "Epoch 190/200\n",
      " - 2s - loss: 0.3174 - acc: 0.9266\n",
      "Epoch 191/200\n",
      " - 2s - loss: 0.3729 - acc: 0.8996\n",
      "Epoch 192/200\n",
      " - 2s - loss: 0.3581 - acc: 0.9345\n",
      "Epoch 193/200\n",
      " - 2s - loss: 0.3305 - acc: 0.9295\n",
      "Epoch 194/200\n",
      " - 2s - loss: 0.4398 - acc: 0.9202\n",
      "Epoch 195/200\n",
      " - 2s - loss: 0.3653 - acc: 0.9202\n",
      "Epoch 196/200\n",
      " - 2s - loss: 0.6106 - acc: 0.8397\n",
      "Epoch 197/200\n",
      " - 2s - loss: 0.4369 - acc: 0.9095\n",
      "Epoch 198/200\n",
      " - 2s - loss: 0.3069 - acc: 0.9615\n",
      "Epoch 199/200\n",
      " - 2s - loss: 0.3024 - acc: 0.9523\n",
      "Epoch 200/200\n",
      " - 2s - loss: 0.2956 - acc: 0.9594\n",
      "[[251   2   0   0   1   0]\n",
      " [  3 161   0   0   8   0]\n",
      " [  1   0 157   0   0   0]\n",
      " [  0   0   0  20   0   1]\n",
      " [  0   1   0   0  52  15]\n",
      " [  0   0   0   0   6  13]]\n",
      "\n",
      "\n",
      "<class 'keras.engine.sequential.Sequential'>\n",
      "||||| Accuracy : 0.8650693846029012 |||||\n",
      "\n",
      "\n",
      "Best actual accuracy : 0.9116562251885808\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_91 (Dense)             (None, 64)                3496384   \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 1000)              65000     \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 6)                 6006      \n",
      "=================================================================\n",
      "Total params: 7,571,390\n",
      "Trainable params: 7,571,390\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training...\n",
      "Epoch 1/200\n",
      " - 5s - loss: 1.7928 - acc: 0.2051\n",
      "Epoch 2/200\n",
      " - 4s - loss: 1.7923 - acc: 0.1510\n",
      "Epoch 3/200\n",
      " - 4s - loss: 1.7857 - acc: 0.1403\n",
      "Epoch 4/200\n",
      " - 4s - loss: 1.7232 - acc: 0.2543\n",
      "Epoch 5/200\n",
      " - 4s - loss: 1.5066 - acc: 0.3647\n",
      "Epoch 6/200\n",
      " - 4s - loss: 1.4401 - acc: 0.3925\n",
      "Epoch 7/200\n",
      " - 4s - loss: 1.2082 - acc: 0.5114\n",
      "Epoch 8/200\n",
      " - 4s - loss: 1.1144 - acc: 0.5883\n",
      "Epoch 9/200\n",
      " - 4s - loss: 1.0664 - acc: 0.6517\n",
      "Epoch 10/200\n",
      " - 4s - loss: 0.9586 - acc: 0.6916\n",
      "Epoch 11/200\n",
      " - 4s - loss: 0.8872 - acc: 0.7415\n",
      "Epoch 12/200\n",
      " - 4s - loss: 0.8772 - acc: 0.7571\n",
      "Epoch 13/200\n",
      " - 4s - loss: 0.8327 - acc: 0.7821\n",
      "Epoch 14/200\n",
      " - 4s - loss: 0.7738 - acc: 0.8077\n",
      "Epoch 15/200\n",
      " - 4s - loss: 0.7706 - acc: 0.8198\n",
      "Epoch 16/200\n",
      " - 4s - loss: 0.7476 - acc: 0.8113\n",
      "Epoch 17/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 4s - loss: 0.7479 - acc: 0.8105\n",
      "Epoch 18/200\n",
      " - 4s - loss: 0.7522 - acc: 0.8006\n",
      "Epoch 19/200\n",
      " - 4s - loss: 0.7082 - acc: 0.8276\n",
      "Epoch 20/200\n",
      " - 4s - loss: 0.7375 - acc: 0.8276\n",
      "Epoch 21/200\n",
      " - 4s - loss: 0.7855 - acc: 0.7913\n",
      "Epoch 22/200\n",
      " - 4s - loss: 0.7281 - acc: 0.8333\n",
      "Epoch 23/200\n",
      " - 4s - loss: 0.6967 - acc: 0.8390\n",
      "Epoch 24/200\n",
      " - 4s - loss: 0.6775 - acc: 0.8405\n",
      "Epoch 25/200\n",
      " - 4s - loss: 0.7730 - acc: 0.7991\n",
      "Epoch 26/200\n",
      " - 4s - loss: 0.6814 - acc: 0.8262\n",
      "Epoch 27/200\n",
      " - 4s - loss: 0.6742 - acc: 0.8390\n",
      "Epoch 28/200\n",
      " - 4s - loss: 0.6678 - acc: 0.8312\n",
      "Epoch 29/200\n",
      " - 4s - loss: 0.6416 - acc: 0.8476\n",
      "Epoch 30/200\n",
      " - 4s - loss: 0.6696 - acc: 0.8469\n",
      "Epoch 31/200\n",
      " - 4s - loss: 0.6651 - acc: 0.8405\n",
      "Epoch 32/200\n",
      " - 4s - loss: 0.6894 - acc: 0.8390\n",
      "Epoch 33/200\n",
      " - 4s - loss: 0.6852 - acc: 0.8519\n",
      "Epoch 34/200\n",
      " - 4s - loss: 0.5941 - acc: 0.8754\n",
      "Epoch 35/200\n",
      " - 4s - loss: 0.5735 - acc: 0.8811\n",
      "Epoch 36/200\n",
      " - 4s - loss: 0.5974 - acc: 0.8625\n",
      "Epoch 37/200\n",
      " - 4s - loss: 0.5797 - acc: 0.8668\n",
      "Epoch 38/200\n",
      " - 4s - loss: 0.5169 - acc: 0.8818\n",
      "Epoch 39/200\n",
      " - 4s - loss: 0.5866 - acc: 0.8533\n",
      "Epoch 40/200\n",
      " - 4s - loss: 0.5513 - acc: 0.8754\n",
      "Epoch 41/200\n",
      " - 4s - loss: 0.5004 - acc: 0.9081\n",
      "Epoch 42/200\n",
      " - 4s - loss: 0.5460 - acc: 0.8618\n",
      "Epoch 43/200\n",
      " - 4s - loss: 0.5074 - acc: 0.8846\n",
      "Epoch 44/200\n",
      " - 5s - loss: 0.5188 - acc: 0.8768\n",
      "Epoch 45/200\n",
      " - 5s - loss: 0.4892 - acc: 0.8775\n",
      "Epoch 46/200\n",
      " - 5s - loss: 0.4834 - acc: 0.8811\n",
      "Epoch 47/200\n",
      " - 4s - loss: 0.4086 - acc: 0.9038\n",
      "Epoch 48/200\n",
      " - 5s - loss: 0.4067 - acc: 0.9003\n",
      "Epoch 49/200\n",
      " - 5s - loss: 0.3858 - acc: 0.9110\n",
      "Epoch 50/200\n",
      " - 5s - loss: 0.4319 - acc: 0.9046\n",
      "Epoch 51/200\n",
      " - 4s - loss: 0.3881 - acc: 0.9152\n",
      "Epoch 52/200\n",
      " - 4s - loss: 0.3581 - acc: 0.9088\n",
      "Epoch 53/200\n",
      " - 4s - loss: 0.3883 - acc: 0.9281\n",
      "Epoch 54/200\n",
      " - 4s - loss: 0.3117 - acc: 0.9245\n",
      "Epoch 55/200\n",
      " - 4s - loss: 0.3339 - acc: 0.9188\n",
      "Epoch 56/200\n",
      " - 5s - loss: 0.4274 - acc: 0.9081\n",
      "Epoch 57/200\n",
      " - 5s - loss: 0.2882 - acc: 0.9309\n",
      "Epoch 58/200\n",
      " - 5s - loss: 0.5121 - acc: 0.8853\n",
      "Epoch 59/200\n",
      " - 5s - loss: 0.3695 - acc: 0.9245\n",
      "Epoch 60/200\n",
      " - 5s - loss: 0.3122 - acc: 0.9231\n",
      "Epoch 61/200\n",
      " - 5s - loss: 0.3194 - acc: 0.9295\n",
      "Epoch 62/200\n",
      " - 4s - loss: 0.3916 - acc: 0.8889\n",
      "Epoch 63/200\n",
      " - 4s - loss: 0.3017 - acc: 0.9202\n",
      "Epoch 64/200\n",
      " - 4s - loss: 0.2893 - acc: 0.9323\n",
      "Epoch 65/200\n",
      " - 4s - loss: 0.3012 - acc: 0.9252\n",
      "Epoch 66/200\n",
      " - 4s - loss: 0.2538 - acc: 0.9345\n",
      "Epoch 67/200\n",
      " - 5s - loss: 0.4291 - acc: 0.8803\n",
      "Epoch 68/200\n",
      " - 4s - loss: 0.3003 - acc: 0.9338\n",
      "Epoch 69/200\n",
      " - 5s - loss: 0.3271 - acc: 0.9338\n",
      "Epoch 70/200\n",
      " - 4s - loss: 0.1965 - acc: 0.9466\n",
      "Epoch 71/200\n",
      " - 4s - loss: 0.3272 - acc: 0.9124\n",
      "Epoch 72/200\n",
      " - 4s - loss: 0.1648 - acc: 0.9573\n",
      "Epoch 73/200\n",
      " - 4s - loss: 0.2072 - acc: 0.9466\n",
      "Epoch 74/200\n",
      " - 4s - loss: 0.2215 - acc: 0.9345\n",
      "Epoch 75/200\n",
      " - 4s - loss: 0.3761 - acc: 0.9252\n",
      "Epoch 76/200\n",
      " - 5s - loss: 0.2067 - acc: 0.9509\n",
      "Epoch 77/200\n",
      " - 4s - loss: 0.3370 - acc: 0.8953\n",
      "Epoch 78/200\n",
      " - 4s - loss: 0.3441 - acc: 0.9231\n",
      "Epoch 79/200\n",
      " - 5s - loss: 0.4533 - acc: 0.8597\n",
      "Epoch 80/200\n",
      " - 5s - loss: 0.4108 - acc: 0.8682\n",
      "Epoch 81/200\n",
      " - 5s - loss: 0.2779 - acc: 0.9245\n",
      "Epoch 82/200\n",
      " - 5s - loss: 0.1706 - acc: 0.9594\n",
      "Epoch 83/200\n",
      " - 5s - loss: 0.2041 - acc: 0.9409\n",
      "Epoch 84/200\n",
      " - 5s - loss: 0.2792 - acc: 0.9174\n",
      "Epoch 85/200\n",
      " - 5s - loss: 0.1724 - acc: 0.9537\n",
      "Epoch 86/200\n",
      " - 5s - loss: 0.2249 - acc: 0.9473\n",
      "Epoch 87/200\n",
      " - 5s - loss: 0.2539 - acc: 0.9274\n",
      "Epoch 88/200\n",
      " - 4s - loss: 0.2529 - acc: 0.9402\n",
      "Epoch 89/200\n",
      " - 4s - loss: 0.1507 - acc: 0.9665\n",
      "Epoch 90/200\n",
      " - 4s - loss: 0.1391 - acc: 0.9573\n",
      "Epoch 91/200\n",
      " - 4s - loss: 0.1582 - acc: 0.9580\n",
      "Epoch 92/200\n",
      " - 5s - loss: 0.1972 - acc: 0.9444\n",
      "Epoch 93/200\n",
      " - 5s - loss: 0.2072 - acc: 0.9523\n",
      "Epoch 94/200\n",
      " - 5s - loss: 0.1930 - acc: 0.9516\n",
      "Epoch 95/200\n",
      " - 5s - loss: 0.0894 - acc: 0.9751\n",
      "Epoch 96/200\n",
      " - 5s - loss: 0.1521 - acc: 0.9644\n",
      "Epoch 97/200\n",
      " - 5s - loss: 0.2731 - acc: 0.9152\n",
      "Epoch 98/200\n",
      " - 5s - loss: 0.2920 - acc: 0.9366\n",
      "Epoch 99/200\n",
      " - 5s - loss: 0.2102 - acc: 0.9480\n",
      "Epoch 100/200\n",
      " - 5s - loss: 0.1892 - acc: 0.9430\n",
      "Epoch 101/200\n",
      " - 4s - loss: 0.2775 - acc: 0.9309\n",
      "Epoch 102/200\n",
      " - 5s - loss: 0.1343 - acc: 0.9615\n",
      "Epoch 103/200\n",
      " - 5s - loss: 0.1017 - acc: 0.9736\n",
      "Epoch 104/200\n",
      " - 5s - loss: 0.1879 - acc: 0.9523\n",
      "Epoch 105/200\n",
      " - 5s - loss: 0.2636 - acc: 0.9509\n",
      "Epoch 106/200\n",
      " - 5s - loss: 0.2448 - acc: 0.9387\n",
      "Epoch 107/200\n",
      " - 4s - loss: 0.1460 - acc: 0.9530\n",
      "Epoch 108/200\n",
      " - 5s - loss: 0.0957 - acc: 0.9758\n",
      "Epoch 109/200\n",
      " - 5s - loss: 0.1490 - acc: 0.9551\n",
      "Epoch 110/200\n",
      " - 5s - loss: 0.1226 - acc: 0.9694\n",
      "Epoch 111/200\n",
      " - 5s - loss: 0.0731 - acc: 0.9765\n",
      "Epoch 112/200\n",
      " - 5s - loss: 0.1767 - acc: 0.9480\n",
      "Epoch 113/200\n",
      " - 5s - loss: 0.1154 - acc: 0.9701\n",
      "Epoch 114/200\n",
      " - 5s - loss: 0.1375 - acc: 0.9679\n",
      "Epoch 115/200\n",
      " - 5s - loss: 0.1556 - acc: 0.9601\n",
      "Epoch 116/200\n",
      " - 5s - loss: 0.2419 - acc: 0.9473\n",
      "Epoch 117/200\n",
      " - 5s - loss: 0.1307 - acc: 0.9701\n",
      "Epoch 118/200\n",
      " - 5s - loss: 0.0972 - acc: 0.9829\n",
      "Epoch 119/200\n",
      " - 5s - loss: 0.1088 - acc: 0.9779\n",
      "Epoch 120/200\n",
      " - 5s - loss: 0.0683 - acc: 0.9850\n",
      "Epoch 121/200\n",
      " - 5s - loss: 0.1467 - acc: 0.9566\n",
      "Epoch 122/200\n",
      " - 5s - loss: 0.0481 - acc: 0.9879\n",
      "Epoch 123/200\n",
      " - 5s - loss: 0.0887 - acc: 0.9765\n",
      "Epoch 124/200\n",
      " - 5s - loss: 0.1617 - acc: 0.9580\n",
      "Epoch 125/200\n",
      " - 5s - loss: 0.0674 - acc: 0.9850\n",
      "Epoch 126/200\n",
      " - 4s - loss: 0.0947 - acc: 0.9793\n",
      "Epoch 127/200\n",
      " - 5s - loss: 0.0900 - acc: 0.9772\n",
      "Epoch 128/200\n",
      " - 5s - loss: 0.0660 - acc: 0.9879\n",
      "Epoch 129/200\n",
      " - 5s - loss: 0.2430 - acc: 0.9523\n",
      "Epoch 130/200\n",
      " - 5s - loss: 0.0463 - acc: 0.9879\n",
      "Epoch 131/200\n",
      " - 5s - loss: 0.2803 - acc: 0.9323\n",
      "Epoch 132/200\n",
      " - 5s - loss: 0.0806 - acc: 0.9772\n",
      "Epoch 133/200\n",
      " - 4s - loss: 0.0370 - acc: 0.9907\n",
      "Epoch 134/200\n",
      " - 4s - loss: 0.3310 - acc: 0.9209\n",
      "Epoch 135/200\n",
      " - 5s - loss: 0.2076 - acc: 0.9630\n",
      "Epoch 136/200\n",
      " - 5s - loss: 0.0879 - acc: 0.9808\n",
      "Epoch 137/200\n",
      " - 5s - loss: 0.1637 - acc: 0.9558\n",
      "Epoch 138/200\n",
      " - 5s - loss: 0.0416 - acc: 0.9843\n",
      "Epoch 139/200\n",
      " - 5s - loss: 0.2193 - acc: 0.9366\n",
      "Epoch 140/200\n",
      " - 5s - loss: 0.0585 - acc: 0.9865\n",
      "Epoch 141/200\n",
      " - 5s - loss: 0.0932 - acc: 0.9779\n",
      "Epoch 142/200\n",
      " - 5s - loss: 0.0561 - acc: 0.9822\n",
      "Epoch 143/200\n",
      " - 4s - loss: 0.0128 - acc: 0.9957\n",
      "Epoch 144/200\n",
      " - 4s - loss: 0.0881 - acc: 0.9801\n",
      "Epoch 145/200\n",
      " - 4s - loss: 0.1740 - acc: 0.9530\n",
      "Epoch 146/200\n",
      " - 4s - loss: 0.0819 - acc: 0.9801\n",
      "Epoch 147/200\n",
      " - 5s - loss: 0.0265 - acc: 0.9907\n",
      "Epoch 148/200\n",
      " - 5s - loss: 0.0096 - acc: 0.9979\n",
      "Epoch 149/200\n",
      " - 4s - loss: 0.0111 - acc: 0.9964\n",
      "Epoch 150/200\n",
      " - 5s - loss: 0.0778 - acc: 0.9865\n",
      "Epoch 151/200\n",
      " - 5s - loss: 0.0429 - acc: 0.9850\n",
      "Epoch 152/200\n",
      " - 5s - loss: 0.3773 - acc: 0.9323\n",
      "Epoch 153/200\n",
      " - 5s - loss: 0.0833 - acc: 0.9808\n",
      "Epoch 154/200\n",
      " - 5s - loss: 0.3874 - acc: 0.9103\n",
      "Epoch 155/200\n",
      " - 5s - loss: 0.2307 - acc: 0.9387\n",
      "Epoch 156/200\n",
      " - 5s - loss: 0.1254 - acc: 0.9687\n",
      "Epoch 157/200\n",
      " - 5s - loss: 0.0620 - acc: 0.9829\n",
      "Epoch 158/200\n",
      " - 5s - loss: 0.0937 - acc: 0.9758\n",
      "Epoch 159/200\n",
      " - 5s - loss: 0.0423 - acc: 0.9886\n",
      "Epoch 160/200\n",
      " - 5s - loss: 0.0293 - acc: 0.9907\n",
      "Epoch 161/200\n",
      " - 5s - loss: 0.0125 - acc: 0.9957\n",
      "Epoch 162/200\n",
      " - 5s - loss: 0.1548 - acc: 0.9601\n",
      "Epoch 163/200\n",
      " - 5s - loss: 0.0417 - acc: 0.9900\n",
      "Epoch 164/200\n",
      " - 5s - loss: 0.0088 - acc: 0.9972\n",
      "Epoch 165/200\n",
      " - 5s - loss: 0.1032 - acc: 0.9751\n",
      "Epoch 166/200\n",
      " - 4s - loss: 0.0153 - acc: 0.9972\n",
      "Epoch 167/200\n",
      " - 5s - loss: 0.0117 - acc: 0.9957\n",
      "Epoch 168/200\n",
      " - 5s - loss: 0.0079 - acc: 0.9986\n",
      "Epoch 169/200\n",
      " - 5s - loss: 0.1043 - acc: 0.9722\n",
      "Epoch 170/200\n",
      " - 5s - loss: 0.0443 - acc: 0.9907\n",
      "Epoch 171/200\n",
      " - 5s - loss: 0.0069 - acc: 0.9986\n",
      "Epoch 172/200\n",
      " - 5s - loss: 0.0065 - acc: 0.9986\n",
      "Epoch 173/200\n",
      " - 5s - loss: 0.1471 - acc: 0.9786\n",
      "Epoch 174/200\n",
      " - 5s - loss: 0.0188 - acc: 0.9964\n",
      "Epoch 175/200\n",
      " - 5s - loss: 0.0115 - acc: 0.9964\n",
      "Epoch 176/200\n",
      " - 5s - loss: 0.4044 - acc: 0.9473\n",
      "Epoch 177/200\n",
      " - 5s - loss: 0.1988 - acc: 0.9651\n",
      "Epoch 178/200\n",
      " - 5s - loss: 0.0684 - acc: 0.9858\n",
      "Epoch 179/200\n",
      " - 5s - loss: 0.0094 - acc: 0.9979\n",
      "Epoch 180/200\n",
      " - 5s - loss: 0.0088 - acc: 0.9979\n",
      "Epoch 181/200\n",
      " - 5s - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 182/200\n",
      " - 5s - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 183/200\n",
      " - 5s - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 184/200\n",
      " - 5s - loss: 0.0587 - acc: 0.9922\n",
      "Epoch 185/200\n",
      " - 5s - loss: 0.0046 - acc: 0.9993\n",
      "Epoch 186/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 5s - loss: 0.0072 - acc: 0.9979\n",
      "Epoch 187/200\n",
      " - 4s - loss: 0.0069 - acc: 0.9972\n",
      "Epoch 188/200\n",
      " - 4s - loss: 0.0031 - acc: 0.9986\n",
      "Epoch 189/200\n",
      " - 5s - loss: 0.0199 - acc: 0.9936\n",
      "Epoch 190/200\n",
      " - 5s - loss: 0.0030 - acc: 0.9986\n",
      "Epoch 191/200\n",
      " - 5s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 192/200\n",
      " - 4s - loss: 0.0018 - acc: 0.9993\n",
      "Epoch 193/200\n",
      " - 5s - loss: 0.0019 - acc: 0.9993\n",
      "Epoch 194/200\n",
      " - 5s - loss: 0.0036 - acc: 0.9979\n",
      "Epoch 195/200\n",
      " - 5s - loss: 0.0019 - acc: 0.9986\n",
      "Epoch 196/200\n",
      " - 5s - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 197/200\n",
      " - 5s - loss: 0.0016 - acc: 0.9993\n",
      "Epoch 198/200\n",
      " - 4s - loss: 0.0037 - acc: 0.9986\n",
      "Epoch 199/200\n",
      " - 5s - loss: 0.0012 - acc: 0.9993\n",
      "Epoch 200/200\n",
      " - 4s - loss: 4.4934e-04 - acc: 1.0000\n",
      "[[250   3   0   0   1   0]\n",
      " [  2 163   0   1   6   0]\n",
      " [  0   1 157   0   0   0]\n",
      " [  0   0   0  20   1   0]\n",
      " [  0   2   0   0  63   3]\n",
      " [  1   0   0   0   9   9]]\n",
      "\n",
      "\n",
      "<class 'keras.engine.sequential.Sequential'>\n",
      "||||| Accuracy : 0.9070867143818648 |||||\n",
      "\n",
      "\n",
      "Best actual accuracy : 0.9116562251885808\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_98 (Dense)             (None, 64)                3496384   \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 1500)              97500     \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 1500)              0         \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 1500)              2251500   \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 1500)              0         \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 1500)              2251500   \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 1500)              0         \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 1500)              2251500   \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 1500)              0         \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 1500)              2251500   \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 1500)              0         \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 6)                 9006      \n",
      "=================================================================\n",
      "Total params: 12,608,890\n",
      "Trainable params: 12,608,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training...\n",
      "Epoch 1/200\n",
      " - 9s - loss: 1.7927 - acc: 0.1880\n",
      "Epoch 2/200\n",
      " - 8s - loss: 1.7916 - acc: 0.1610\n",
      "Epoch 3/200\n",
      " - 8s - loss: 1.7752 - acc: 0.1724\n",
      "Epoch 4/200\n",
      " - 8s - loss: 1.6747 - acc: 0.3056\n",
      "Epoch 5/200\n",
      " - 8s - loss: 1.4620 - acc: 0.3875\n",
      "Epoch 6/200\n",
      " - 8s - loss: 1.3119 - acc: 0.4480\n",
      "Epoch 7/200\n",
      " - 8s - loss: 1.3334 - acc: 0.4480\n",
      "Epoch 8/200\n",
      " - 8s - loss: 1.0889 - acc: 0.5926\n",
      "Epoch 9/200\n",
      " - 8s - loss: 1.0198 - acc: 0.6731\n",
      "Epoch 10/200\n",
      " - 8s - loss: 0.9528 - acc: 0.7058\n",
      "Epoch 11/200\n",
      " - 9s - loss: 0.9424 - acc: 0.7201\n",
      "Epoch 12/200\n",
      " - 8s - loss: 0.8483 - acc: 0.7514\n",
      "Epoch 13/200\n",
      " - 8s - loss: 0.9050 - acc: 0.7507\n",
      "Epoch 14/200\n",
      " - 8s - loss: 0.9809 - acc: 0.6880\n",
      "Epoch 15/200\n",
      " - 8s - loss: 0.8053 - acc: 0.7813\n",
      "Epoch 16/200\n",
      " - 8s - loss: 0.7606 - acc: 0.8141\n",
      "Epoch 17/200\n",
      " - 8s - loss: 0.7228 - acc: 0.8497\n",
      "Epoch 18/200\n",
      " - 9s - loss: 0.7464 - acc: 0.8405\n",
      "Epoch 19/200\n",
      " - 8s - loss: 0.7288 - acc: 0.8219\n",
      "Epoch 20/200\n",
      " - 8s - loss: 0.7621 - acc: 0.8155\n",
      "Epoch 21/200\n",
      " - 8s - loss: 0.7163 - acc: 0.8241\n",
      "Epoch 22/200\n",
      " - 8s - loss: 0.7073 - acc: 0.8519\n",
      "Epoch 23/200\n",
      " - 8s - loss: 0.6626 - acc: 0.8433\n",
      "Epoch 24/200\n",
      " - 8s - loss: 0.7931 - acc: 0.7692\n",
      "Epoch 25/200\n",
      " - 8s - loss: 0.7460 - acc: 0.8027\n",
      "Epoch 26/200\n",
      " - 8s - loss: 0.6497 - acc: 0.8348\n",
      "Epoch 27/200\n",
      " - 8s - loss: 0.6572 - acc: 0.8469\n",
      "Epoch 28/200\n",
      " - 8s - loss: 0.6957 - acc: 0.8262\n",
      "Epoch 29/200\n",
      " - 8s - loss: 0.7104 - acc: 0.8162\n",
      "Epoch 30/200\n",
      " - 8s - loss: 0.6842 - acc: 0.8255\n",
      "Epoch 31/200\n",
      " - 8s - loss: 0.6694 - acc: 0.8390\n",
      "Epoch 32/200\n",
      " - 8s - loss: 0.5733 - acc: 0.8611\n",
      "Epoch 33/200\n",
      " - 9s - loss: 0.6311 - acc: 0.8440\n",
      "Epoch 34/200\n",
      " - 8s - loss: 0.6478 - acc: 0.8447\n",
      "Epoch 35/200\n",
      " - 8s - loss: 0.6331 - acc: 0.8554\n",
      "Epoch 36/200\n",
      " - 8s - loss: 0.6093 - acc: 0.8604\n",
      "Epoch 37/200\n",
      " - 8s - loss: 0.5997 - acc: 0.8647\n",
      "Epoch 38/200\n",
      " - 8s - loss: 0.6045 - acc: 0.8689\n",
      "Epoch 39/200\n",
      " - 8s - loss: 0.5554 - acc: 0.8803\n",
      "Epoch 40/200\n",
      " - 8s - loss: 0.6463 - acc: 0.8326\n",
      "Epoch 41/200\n",
      " - 8s - loss: 0.5364 - acc: 0.8768\n",
      "Epoch 42/200\n",
      " - 8s - loss: 0.6083 - acc: 0.8519\n",
      "Epoch 43/200\n",
      " - 8s - loss: 0.5388 - acc: 0.8775\n",
      "Epoch 44/200\n",
      " - 8s - loss: 0.5186 - acc: 0.8818\n",
      "Epoch 45/200\n",
      " - 8s - loss: 0.4982 - acc: 0.9003\n",
      "Epoch 46/200\n",
      " - 8s - loss: 0.4683 - acc: 0.8925\n",
      "Epoch 47/200\n",
      " - 8s - loss: 0.4909 - acc: 0.8811\n",
      "Epoch 48/200\n",
      " - 8s - loss: 0.4524 - acc: 0.8932\n",
      "Epoch 49/200\n",
      " - 8s - loss: 0.6016 - acc: 0.8511\n",
      "Epoch 50/200\n",
      " - 8s - loss: 0.3787 - acc: 0.9110\n",
      "Epoch 51/200\n",
      " - 8s - loss: 0.4386 - acc: 0.8946\n",
      "Epoch 52/200\n",
      " - 8s - loss: 0.4157 - acc: 0.9046\n",
      "Epoch 53/200\n",
      " - 8s - loss: 0.3375 - acc: 0.9117\n",
      "Epoch 54/200\n",
      " - 8s - loss: 0.3602 - acc: 0.9209\n",
      "Epoch 55/200\n",
      " - 8s - loss: 0.3471 - acc: 0.9046\n",
      "Epoch 56/200\n",
      " - 8s - loss: 0.4109 - acc: 0.9074\n",
      "Epoch 57/200\n",
      " - 8s - loss: 0.3822 - acc: 0.9003\n",
      "Epoch 58/200\n",
      " - 8s - loss: 0.4083 - acc: 0.8917\n",
      "Epoch 59/200\n",
      " - 8s - loss: 0.7870 - acc: 0.8027\n",
      "Epoch 60/200\n",
      " - 8s - loss: 0.4733 - acc: 0.8732\n",
      "Epoch 61/200\n",
      " - 8s - loss: 0.3450 - acc: 0.9017\n",
      "Epoch 62/200\n",
      " - 8s - loss: 0.3519 - acc: 0.9195\n",
      "Epoch 63/200\n",
      " - 8s - loss: 0.2874 - acc: 0.9295\n",
      "Epoch 64/200\n",
      " - 8s - loss: 0.2640 - acc: 0.9330\n",
      "Epoch 65/200\n",
      " - 8s - loss: 0.3807 - acc: 0.9238\n",
      "Epoch 66/200\n",
      " - 8s - loss: 0.2589 - acc: 0.9380\n",
      "Epoch 67/200\n",
      " - 8s - loss: 0.2659 - acc: 0.9316\n",
      "Epoch 68/200\n",
      " - 8s - loss: 0.3361 - acc: 0.9110\n",
      "Epoch 69/200\n",
      " - 8s - loss: 0.2534 - acc: 0.9359\n",
      "Epoch 70/200\n",
      " - 8s - loss: 0.2887 - acc: 0.9380\n",
      "Epoch 71/200\n",
      " - 8s - loss: 0.2171 - acc: 0.9430\n",
      "Epoch 72/200\n",
      " - 8s - loss: 0.2701 - acc: 0.9430\n",
      "Epoch 73/200\n",
      " - 8s - loss: 0.1991 - acc: 0.9473\n",
      "Epoch 74/200\n",
      " - 8s - loss: 0.2540 - acc: 0.9395\n",
      "Epoch 75/200\n",
      " - 8s - loss: 0.2451 - acc: 0.9452\n",
      "Epoch 76/200\n",
      " - 8s - loss: 0.2109 - acc: 0.9473\n",
      "Epoch 77/200\n",
      " - 8s - loss: 0.3962 - acc: 0.9088\n",
      "Epoch 78/200\n",
      " - 8s - loss: 0.2291 - acc: 0.9416\n",
      "Epoch 79/200\n",
      " - 8s - loss: 0.1958 - acc: 0.9480\n",
      "Epoch 80/200\n",
      " - 8s - loss: 0.1972 - acc: 0.9473\n",
      "Epoch 81/200\n",
      " - 8s - loss: 0.2246 - acc: 0.9487\n",
      "Epoch 82/200\n",
      " - 8s - loss: 0.2448 - acc: 0.9202\n",
      "Epoch 83/200\n",
      " - 8s - loss: 0.4057 - acc: 0.8932\n",
      "Epoch 84/200\n",
      " - 8s - loss: 0.2194 - acc: 0.9416\n",
      "Epoch 85/200\n",
      " - 8s - loss: 0.3990 - acc: 0.9081\n",
      "Epoch 86/200\n",
      " - 8s - loss: 0.1981 - acc: 0.9530\n",
      "Epoch 87/200\n",
      " - 8s - loss: 0.2062 - acc: 0.9523\n",
      "Epoch 88/200\n",
      " - 8s - loss: 0.1311 - acc: 0.9580\n",
      "Epoch 89/200\n",
      " - 8s - loss: 0.2412 - acc: 0.9373\n",
      "Epoch 90/200\n",
      " - 8s - loss: 0.1943 - acc: 0.9537\n",
      "Epoch 91/200\n",
      " - 8s - loss: 0.1706 - acc: 0.9623\n",
      "Epoch 92/200\n",
      " - 8s - loss: 0.2192 - acc: 0.9366\n",
      "Epoch 93/200\n",
      " - 8s - loss: 0.1627 - acc: 0.9594\n",
      "Epoch 94/200\n",
      " - 8s - loss: 0.1214 - acc: 0.9715\n",
      "Epoch 95/200\n",
      " - 8s - loss: 0.2361 - acc: 0.9530\n",
      "Epoch 96/200\n",
      " - 8s - loss: 0.1028 - acc: 0.9679\n",
      "Epoch 97/200\n",
      " - 8s - loss: 0.1195 - acc: 0.9694\n",
      "Epoch 98/200\n",
      " - 8s - loss: 0.1773 - acc: 0.9601\n",
      "Epoch 99/200\n",
      " - 8s - loss: 0.2473 - acc: 0.9366\n",
      "Epoch 100/200\n",
      " - 8s - loss: 0.0473 - acc: 0.9829\n",
      "Epoch 101/200\n",
      " - 8s - loss: 0.1688 - acc: 0.9658\n",
      "Epoch 102/200\n",
      " - 8s - loss: 0.1561 - acc: 0.9679\n",
      "Epoch 103/200\n",
      " - 8s - loss: 0.4180 - acc: 0.9003\n",
      "Epoch 104/200\n",
      " - 8s - loss: 0.1079 - acc: 0.9715\n",
      "Epoch 105/200\n",
      " - 8s - loss: 0.0990 - acc: 0.9701\n",
      "Epoch 106/200\n",
      " - 8s - loss: 0.1702 - acc: 0.9537\n",
      "Epoch 107/200\n",
      " - 8s - loss: 0.1651 - acc: 0.9665\n",
      "Epoch 108/200\n",
      " - 8s - loss: 0.1322 - acc: 0.9722\n",
      "Epoch 109/200\n",
      " - 8s - loss: 0.1328 - acc: 0.9665\n",
      "Epoch 110/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 8s - loss: 0.1360 - acc: 0.9615\n",
      "Epoch 111/200\n",
      " - 8s - loss: 0.0855 - acc: 0.9744\n",
      "Epoch 112/200\n",
      " - 8s - loss: 0.1707 - acc: 0.9637\n",
      "Epoch 113/200\n",
      " - 8s - loss: 0.1089 - acc: 0.9722\n",
      "Epoch 114/200\n",
      " - 8s - loss: 0.2621 - acc: 0.9366\n",
      "Epoch 115/200\n",
      " - 8s - loss: 0.4426 - acc: 0.9131\n",
      "Epoch 116/200\n",
      " - 8s - loss: 0.1726 - acc: 0.9630\n",
      "Epoch 117/200\n",
      " - 8s - loss: 0.0755 - acc: 0.9815\n",
      "Epoch 118/200\n",
      " - 8s - loss: 0.1162 - acc: 0.9679\n",
      "Epoch 119/200\n",
      " - 8s - loss: 0.0544 - acc: 0.9829\n",
      "Epoch 120/200\n",
      " - 8s - loss: 0.0617 - acc: 0.9843\n",
      "Epoch 121/200\n",
      " - 8s - loss: 0.0946 - acc: 0.9801\n",
      "Epoch 122/200\n",
      " - 8s - loss: 0.0825 - acc: 0.9829\n",
      "Epoch 123/200\n",
      " - 8s - loss: 0.0179 - acc: 0.9957\n",
      "Epoch 124/200\n",
      " - 8s - loss: 0.0441 - acc: 0.9872\n",
      "Epoch 125/200\n",
      " - 8s - loss: 0.1229 - acc: 0.9715\n",
      "Epoch 126/200\n",
      " - 8s - loss: 0.0711 - acc: 0.9822\n",
      "Epoch 127/200\n",
      " - 8s - loss: 0.0212 - acc: 0.9943\n",
      "Epoch 128/200\n",
      " - 8s - loss: 0.0727 - acc: 0.9865\n",
      "Epoch 129/200\n",
      " - 8s - loss: 0.1105 - acc: 0.9758\n",
      "Epoch 130/200\n",
      " - 8s - loss: 0.2897 - acc: 0.9281\n",
      "Epoch 131/200\n",
      " - 8s - loss: 0.0566 - acc: 0.9858\n",
      "Epoch 132/200\n",
      " - 8s - loss: 0.0815 - acc: 0.9829\n",
      "Epoch 133/200\n",
      " - 8s - loss: 0.1134 - acc: 0.9715\n",
      "Epoch 134/200\n",
      " - 8s - loss: 0.0909 - acc: 0.9736\n",
      "Epoch 135/200\n",
      " - 8s - loss: 0.0437 - acc: 0.9943\n",
      "Epoch 136/200\n",
      " - 8s - loss: 0.1249 - acc: 0.9758\n",
      "Epoch 137/200\n",
      " - 8s - loss: 0.0539 - acc: 0.9843\n",
      "Epoch 138/200\n",
      " - 8s - loss: 0.0151 - acc: 0.9950\n",
      "Epoch 139/200\n",
      " - 8s - loss: 0.0239 - acc: 0.9943\n",
      "Epoch 140/200\n",
      " - 8s - loss: 0.0099 - acc: 0.9957\n",
      "Epoch 141/200\n",
      " - 7s - loss: 0.0049 - acc: 0.9972\n",
      "Epoch 142/200\n",
      " - 7s - loss: 0.0311 - acc: 0.9915\n",
      "Epoch 143/200\n",
      " - 8s - loss: 0.0099 - acc: 0.9964\n",
      "Epoch 144/200\n",
      " - 8s - loss: 0.0099 - acc: 0.9950\n",
      "Epoch 145/200\n",
      " - 8s - loss: 0.0041 - acc: 0.9979\n",
      "Epoch 146/200\n",
      " - 8s - loss: 0.1637 - acc: 0.9594\n",
      "Epoch 147/200\n",
      " - 8s - loss: 0.1020 - acc: 0.9687\n",
      "Epoch 148/200\n",
      " - 8s - loss: 0.0080 - acc: 0.9979\n",
      "Epoch 149/200\n",
      " - 8s - loss: 0.1948 - acc: 0.9694\n",
      "Epoch 150/200\n",
      " - 7s - loss: 0.1498 - acc: 0.9623\n",
      "Epoch 151/200\n",
      " - 7s - loss: 0.1967 - acc: 0.9444\n",
      "Epoch 152/200\n",
      " - 7s - loss: 0.2468 - acc: 0.9252\n",
      "Epoch 153/200\n",
      " - 7s - loss: 0.1871 - acc: 0.9551\n",
      "Epoch 154/200\n",
      " - 7s - loss: 0.0237 - acc: 0.9915\n",
      "Epoch 155/200\n",
      " - 8s - loss: 0.1326 - acc: 0.9694\n",
      "Epoch 156/200\n",
      " - 8s - loss: 0.1519 - acc: 0.9701\n",
      "Epoch 157/200\n",
      " - 9s - loss: 0.0278 - acc: 0.9929\n",
      "Epoch 158/200\n",
      " - 8s - loss: 0.0738 - acc: 0.9858\n",
      "Epoch 159/200\n",
      " - 8s - loss: 0.0159 - acc: 0.9943\n",
      "Epoch 160/200\n",
      " - 8s - loss: 0.0089 - acc: 0.9957\n",
      "Epoch 161/200\n",
      " - 8s - loss: 0.0079 - acc: 0.9964\n",
      "Epoch 162/200\n",
      " - 8s - loss: 0.0143 - acc: 0.9957\n",
      "Epoch 163/200\n",
      " - 7s - loss: 0.0029 - acc: 0.9993\n",
      "Epoch 164/200\n",
      " - 7s - loss: 0.0041 - acc: 0.9979\n",
      "Epoch 165/200\n",
      " - 7s - loss: 0.0045 - acc: 0.9979\n",
      "Epoch 166/200\n",
      " - 7s - loss: 0.0267 - acc: 0.9929\n",
      "Epoch 167/200\n",
      " - 8s - loss: 0.0757 - acc: 0.9850\n",
      "Epoch 168/200\n",
      " - 8s - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 169/200\n",
      " - 8s - loss: 0.1599 - acc: 0.9658\n",
      "Epoch 170/200\n",
      " - 7s - loss: 0.0176 - acc: 0.9979\n",
      "Epoch 171/200\n",
      " - 7s - loss: 0.0067 - acc: 0.9972\n",
      "Epoch 172/200\n",
      " - 7s - loss: 0.0051 - acc: 0.9979\n",
      "Epoch 173/200\n",
      " - 7s - loss: 0.0039 - acc: 0.9986\n",
      "Epoch 174/200\n",
      " - 7s - loss: 0.0016 - acc: 0.9993\n",
      "Epoch 175/200\n",
      " - 7s - loss: 0.0036 - acc: 0.9979\n",
      "Epoch 176/200\n",
      " - 7s - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 177/200\n",
      " - 7s - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 178/200\n",
      " - 8s - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 179/200\n",
      " - 8s - loss: 0.0021 - acc: 0.9993\n",
      "Epoch 180/200\n",
      " - 9s - loss: 8.0764e-04 - acc: 1.0000\n",
      "Epoch 181/200\n",
      " - 8s - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 182/200\n",
      " - 8s - loss: 0.1703 - acc: 0.9658\n",
      "Epoch 183/200\n",
      " - 8s - loss: 0.0316 - acc: 0.9900\n",
      "Epoch 184/200\n",
      " - 8s - loss: 0.0927 - acc: 0.9829\n",
      "Epoch 185/200\n",
      " - 8s - loss: 0.0049 - acc: 0.9993\n",
      "Epoch 186/200\n",
      " - 9s - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 187/200\n",
      " - 8s - loss: 0.0030 - acc: 0.9993\n",
      "Epoch 188/200\n",
      " - 8s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 189/200\n",
      " - 7s - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 190/200\n",
      " - 7s - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 191/200\n",
      " - 8s - loss: 0.0017 - acc: 0.9993\n",
      "Epoch 192/200\n",
      " - 7s - loss: 6.7986e-04 - acc: 1.0000\n",
      "Epoch 193/200\n",
      " - 7s - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 194/200\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import precision_score\n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "from keras.layers import Dropout\n",
    "config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 56} ) \n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "def train_fit_test(model, train_x, train_y, test_x, test_y, classWeight):\n",
    "    opt = optimizers.SGD(lr=0.01)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "    model.fit(train_x, train_y, epochs=200, verbose=2, batch_size=16, class_weight=classWeight)\n",
    "    y_pred = model.predict(test_x)\n",
    "    y_pred_formated = numpy.argmax(y_pred, axis=1)\n",
    "    test_y_formated = numpy.argmax(test_y, axis=1)\n",
    "    precision = precision_score(test_y_formated, y_pred_formated, average=\"macro\")  \n",
    "    conf = confusion_matrix(test_y_formated, y_pred_formated)\n",
    "    print(str(conf))\n",
    "    return precision, conf\n",
    "\n",
    "def create_model(num_layers, num_neurons):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=54630))\n",
    "    for i in range(num_layers):\n",
    "        model.add(Dense(units=num_neurons, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=6, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "def hamming_score(y_true, y_pred, normalize=True, sample_weight=None):\n",
    "    import numpy as np\n",
    "\n",
    "    acc_list = []\n",
    "    for i in range(y_true.shape[0]):\n",
    "        set_true = set( np.where(y_true[i])[0] )\n",
    "        set_pred = set( np.where(y_pred[i])[0] )\n",
    "        tmp_a = None\n",
    "        if len(set_true) == 0 and len(set_pred) == 0:\n",
    "            tmp_a = 1\n",
    "        else:\n",
    "            tmp_a = len(set_true.intersection(set_pred))/\\\n",
    "                    float( len(set_true.union(set_pred)) )\n",
    "        #print('tmp_a: {0}'.format(tmp_a))\n",
    "        acc_list.append(tmp_a)\n",
    "    return np.mean(acc_list)\n",
    "\n",
    "\n",
    "import pickle\n",
    "with open('train_x.pickle', 'rb') as handle:\n",
    "    train_x = pickle.load(handle)\n",
    "with open('train_y.pickle', 'rb') as handle2:\n",
    "    train_y = pickle.load(handle2)\n",
    "with open('test_x.pickle', 'rb') as handle3:\n",
    "    test_x = pickle.load(handle3)\n",
    "with open('test_y.pickle', 'rb') as handle4:\n",
    "    test_y = pickle.load(handle4)\n",
    "best_mean = -999999\n",
    "best_model = []\n",
    "layers = [50, 100, 1000, 1500, 2000]\n",
    "\n",
    "\n",
    "labels = [numpy.where(r==1)[0][0] for r in train_y]\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "classWeight = compute_class_weight('balanced', [0,1,2,3,4,5], labels) \n",
    "classWeight = dict(enumerate(classWeight))\n",
    "\n",
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "for x in range(5): # Number of Retrain\n",
    "  for i in  range(3, 7): # Maximum number of hidden layers\n",
    "      for j in layers: # Maximum number of neurons per layer\n",
    "        model = create_model(i, j)\n",
    "        model.summary()\n",
    "        print(\"Training...\")\n",
    "        precision, confusion = train_fit_test(model, train_x, train_y, test_x, test_y, classWeight)\n",
    "        print(\"\\n\")\n",
    "        print(type(model))\n",
    "        print(\"||||| Accuracy : \"+str(precision)+\" |||||\")\n",
    "        print(\"\\n\")\n",
    "        with open(\"infos.txt\",'a+') as fh:\n",
    "          model.summary(print_fn=lambda x: fh.write(x + '\\n'))\n",
    "          fh.write(str(confusion)+\"\\n\")\n",
    "          fh.write(\"\\n Precision : \"+str(precision)+\"\\n\")\n",
    "          fh.close()\n",
    "        try:\n",
    "          v = open(\"best_mod.txt\",\"r\")\n",
    "          best_mean = float(v.read())\n",
    "          print(\"Best actual accuracy : \"+str(best_mean))\n",
    "          v.close()\n",
    "        except:\n",
    "          v = open(\"best_mod.txt\",\"w\")\n",
    "          v.write(str(precision))\n",
    "          v.close()\n",
    "        if (precision > best_mean):\n",
    "          print(\"\\n\\n\")\n",
    "          print(\" BEST MODEL ! \")\n",
    "          print(\"Saving... \")\n",
    "          print(\"\\n\\n\")\n",
    "          v = open(\"best_mod.txt\",\"w\")\n",
    "          v.write(str(precision))\n",
    "          v.close()\n",
    "          model.save('model.h5')\n",
    "          best_mean = precision\n",
    "          best_model = model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
